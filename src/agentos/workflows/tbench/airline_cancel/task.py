import ray
import json
import time
from agentos.scheduler import gpu, io, cpu
import os
import gc
import sys
import re
from agentos.utils.tbench_tools.airline.cancel_reservation import CancelReservation
from agentos.utils.tbench_tools.airline.get_user_details import GetUserDetails
from agentos.utils.tbench_tools.airline.get_reservation_details import GetReservationDetails
from agentos.utils.tbench_tools.airline.search_direct_flight import SearchDirectFlight
from agentos.utils.tbench_tools.airline.book_reservation import BookReservation
from typing import List, Dict
# --- å…¬å…±æ¨¡å—å’Œå·¥å…·å¯¼å…¥ ---
def estimate_tokens(text):
    """
    ä¸€ä¸ªæ›´ç²¾ç¡®çš„ã€ç”¨äºä¼°ç®—ä¸­è‹±æ··åˆæ–‡æœ¬tokenæ•°çš„å‡½æ•°ã€‚
    å®ƒåˆ†åˆ«è®¡ç®—CJKå­—ç¬¦å’ŒéCJKå•è¯ï¼Œå¹¶é¿å…äº†é‡å¤è®¡ç®—ã€‚
    """
    # 1. ç²¾ç¡®è®¡ç®—CJKå­—ç¬¦æ•°
    cjk_chars = sum(1 for char in text if '\u4E00' <= char <= '\u9FFF')
    # 2. ä»æ–‡æœ¬ä¸­ç§»é™¤æ‰€æœ‰CJKå­—ç¬¦å’Œæ¢è¡Œç¬¦ï¼Œä»¥ä¾¿ç»Ÿè®¡å…¶ä»–è¯­è¨€çš„å•è¯
    # æˆ‘ä»¬ç”¨æ­£åˆ™è¡¨è¾¾å¼å°†CJKå­—ç¬¦æ›¿æ¢ä¸ºç©ºæ ¼ï¼Œä»¥ç¡®ä¿å•è¯èƒ½è¢«æ­£ç¡®åˆ†å‰²
    non_cjk_text = re.sub(r'[\u4E00-\u9FFF]', ' ', text)
    non_cjk_text = non_cjk_text.replace("\n", " ")
    # 3. è®¡ç®—éCJKå•è¯æ•°ï¼Œä¹˜ä»¥ç»éªŒç³»æ•°
    # ä½¿ç”¨split()å¯ä»¥æœ‰æ•ˆåœ°æŒ‰ç©ºæ ¼åˆ†å‰²å‡ºå•è¯
    non_cjk_words_count = len(non_cjk_text.split())
    # 4. å°†ä¸¤éƒ¨åˆ†åŠ æ€»
    # è¿™é‡Œçš„1.3æ˜¯è‹±æ–‡å•è¯åˆ°tokençš„ç»éªŒç³»æ•°ï¼Œå¯ä»¥å¾®è°ƒ
    estimated_tokens = cjk_chars + int(non_cjk_words_count * 1.3)
    return estimated_tokens

def query_vllm_model(api_url: str, model_alias: str, messages: List, temperature: float= 0.6, max_token: int= 1024, top_p: float= 0.9, repetition_penalty: float= 1.1) -> tuple[dict, str]:
    """
    é€šè¿‡HTTPè¯·æ±‚æŸ¥è¯¢æœ¬åœ°vLLMæœåŠ¡ã€‚
    
    :param api_url: vLLMæœåŠ¡çš„æ ¹URL (ä¾‹å¦‚ http://127.0.0.1:8000)
    :param model_alias: åœ¨vLLMä¸­æœåŠ¡çš„æ¨¡å‹åˆ«å (ä¾‹å¦‚ qwen3-32b)
    :param messages: OpenAIæ ¼å¼çš„æ¶ˆæ¯åˆ—è¡¨
    :param temperature: æ¸©åº¦å‚æ•°
    :param max_token: æœ€å¤§ç”Ÿæˆtokenæ•°
    :param top_p: Top-pé‡‡æ ·å‚æ•°
    :param repetition_penalty: é‡å¤æƒ©ç½šå‚æ•°
    :return: ä¸€ä¸ªåŒ…å«æ€§èƒ½ç‰¹å¾å’Œæ¨¡å‹å“åº”æ–‡æœ¬çš„å…ƒç»„
    """
    import requests
    from rich.console import Console
    console = Console()
    # vLLMçš„èŠå¤©æ¥å£è·¯å¾„
    chat_url = f"{api_url.strip('/')}/v1/chat/completions"
    headers = {
        "Content-Type": "application/json"
    }
    # æ„å»ºä¸OpenAIå…¼å®¹çš„è¯·æ±‚ä½“
    payload = {
        "model": model_alias,
        "messages": messages,
        "temperature": temperature,
        "max_tokens": max_token,
        "top_p": top_p,
        "repetition_penalty": repetition_penalty,
    }
    # ä¸ºäº†è®¡ç®—ç‰¹å¾ï¼Œå…ˆå°†æ¶ˆæ¯æ‹¼æ¥èµ·æ¥
    conversation = ""
    for message in messages:
        conversation += f"{message['role']}: {message['content']}"
    try:
        response = requests.post(chat_url, json=payload, headers=headers, timeout=3600)
        response.raise_for_status()  # å¦‚æœè¯·æ±‚å¤±è´¥åˆ™æŠ›å‡ºå¼‚å¸¸
        
        response_data = response.json()
        content = response_data['choices'][0]['message']['content'].lstrip()
        
        # è¿”å›ä¸å…¶å®ƒqueryå‡½æ•°æ ¼å¼ä¸€è‡´çš„ç»“æœ
        features = {"text_length": len(conversation), "token_count": estimate_tokens(conversation)}
        return features, content

    except requests.exceptions.RequestException as e:
        error_msg = f"vLLM request failed: {str(e)}"
        console.print(f"[bold red]{error_msg}")
        features = {"text_length": len(conversation), "token_count": estimate_tokens(conversation)}
        return features, f"[bold red]{error_msg}"

def query_llm(model:str, model_folder: str, messages:List, temperature= 0.6, max_token= 1024, top_p= 0.9, repetition_penalty= 1.1):
    from transformers import AutoTokenizer, AutoModelForCausalLM
    import torch
    # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹å’Œåˆ†è¯å™¨
    tokenizer_path= os.path.join(model_folder, "Qwen/Qwen3-32B")
    tokenizer = AutoTokenizer.from_pretrained(tokenizer_path, device_map= "auto")
    local_model = AutoModelForCausalLM.from_pretrained(
        os.path.join(model_folder, model),
        torch_dtype="float16",
        low_cpu_mem_usage=True,
        device_map= "auto"
        )

    # å°†messagesè½¬æ¢æˆå­—ç¬¦ä¸²æ ¼å¼
    conversation = ""
    for message in messages:
        conversation += f"{message['role']}: {message['content']}"

    # ç¼–ç è¾“å…¥
    input_ids = tokenizer.encode(conversation + tokenizer.eos_token, return_tensors='pt').to("cuda")

    # ç”Ÿæˆå›å¤
    output = local_model.generate(
        input_ids, 
        pad_token_id=tokenizer.eos_token_id,
        max_new_tokens= max_token,
        temperature= temperature, 
        top_p= top_p,
        repetition_penalty= repetition_penalty
    )
    response = tokenizer.decode(output[:, input_ids.shape[-1]:][0], skip_special_tokens=True)

    del local_model
    del tokenizer
    torch.cuda.empty_cache()
    gc.collect()
    return {"text_length": len(conversation), "token_count": estimate_tokens(conversation)}, response

def query_llm_online(api_url, api_key, payload: Dict[str, str], tokenizer_path: str)-> str:
    """Call SiliconFlow API to get LLM response"""
    import requests
    from rich.console import Console
    # å°†messagesè½¬æ¢æˆå­—ç¬¦ä¸²æ ¼å¼
    conversation= ""
    for message in payload["messages"]:
        conversation+= f"{message['role']}: {message['content']}"
        
    console= Console()
    headers= {
        "Authorization": api_key,
        "Content-Type": "application/json"
    }
    try:
        response= requests.post(
            api_url,
            json= payload,
            headers= headers,
            timeout= 600
        )
        response.raise_for_status()
        return {"text_length": len(conversation), "token_count": estimate_tokens(conversation)}, response.json()['choices'][0]['message']['content'].lstrip()
    except Exception as e:
        console.print(f"[bold red]API request failed: {str(e)}")
        return {"text_length": len(conversation), "token_count": estimate_tokens(conversation)}, f"[bold red]API request failed: {str(e)}"

def _extract_json_from_llm_output(llm_output: str) -> str:
    """
    ä»LLMè¾“å‡ºä¸­æå–JSONå­—ç¬¦ä¸²ã€‚
    æ”¯æŒå¤šç§æ ¼å¼ï¼šçº¯JSONã€ä»£ç å—ä¸­çš„JSONã€å¸¦è¯´æ˜çš„JSONç­‰ã€‚
    """
    import re
    
    # å°è¯•ç›´æ¥è§£æä¸ºJSON
    try:
        json.loads(llm_output.strip())
        return llm_output.strip()
    except:
        pass
    
    # å°è¯•ä»ä»£ç å—ä¸­æå–JSON
    json_block_pattern = r'```(?:json)?\s*(\{.*?\})\s*```'
    match = re.search(json_block_pattern, llm_output, re.DOTALL)
    if match:
        try:
            json.loads(match.group(1))
            return match.group(1)
        except:
            pass
    
    # å°è¯•æå–JSONå¯¹è±¡
    json_pattern = r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}'
    matches = re.findall(json_pattern, llm_output, re.DOTALL)
    for match in matches:
        try:
            json.loads(match)
            return match
        except:
            continue
    
    # å¦‚æœéƒ½å¤±è´¥äº†ï¼Œè¿”å›åŸå§‹è¾“å‡º
    return llm_output.strip()

# --- å·¥ä½œæµä»»åŠ¡å®šä¹‰ ---

@io(mem=1024)
def task0_init(context):
    """
    å·¥ä½œæµçš„ç¬¬0æ­¥ï¼šåˆå§‹åŒ–ç¯å¢ƒå’Œä¸Šä¸‹æ–‡ã€‚
    1.åŠ è½½æ‰€æœ‰å¿…éœ€çš„åç«¯æ•°æ®ï¼ˆèˆªç­ã€ç”¨æˆ·ã€é¢„è®¢è®°å½•ï¼‰ã€‚
    2.å°†ç”¨æˆ·æœ€åŸå§‹çš„æŒ‡ä»¤å’ŒIDå­˜å…¥ä¸Šä¸‹æ–‡ã€‚
    """
    start_time= time.time()
    print("--- å¼€å§‹æ‰§è¡Œ Task 0: åˆå§‹åŒ–ç¯å¢ƒ ---")
    try:
        dag_id = ray.get(context.get.remote("dag_id"))
        instruction = ray.get(context.get.remote("question"))
        
        # æ·»åŠ è°ƒè¯•ä¿¡æ¯
        print(f"DAG ID: {dag_id}")
        print(f"Question field: {instruction}")
        print(f"Question field type: {type(instruction)}")
        print(f"Question field length: {len(instruction) if instruction else 0}")
        if not instruction:
            print("âš ï¸ è­¦å‘Š: questionå­—æ®µä¸ºç©ºï¼")
            raise ValueError(f"ä»»åŠ¡ {dag_id} çš„ question å­—æ®µä¸ºç©º")

        print(f"æ¥æ”¶åˆ°æŒ‡ä»¤: {instruction}")


        # åŠ è½½tau-benchçš„æ•°æ®åº“json
        try:
            supplementary_files = ray.get(context.get.remote("supplementary_files"))
            flights_data, users_data, reservations_data= json.loads(supplementary_files['flights.json']), json.loads(supplementary_files['users.json']), json.loads(supplementary_files['reservations.json'])
            backend_data = {
                "flights": flights_data,
                "users": users_data,
                "reservations": reservations_data
            }
            context.put.remote("backend_data", backend_data)
            context.put.remote("instruction", instruction)
            print("--- Task 0 æ‰§è¡Œå®Œæ¯•: ç¯å¢ƒåˆå§‹åŒ–æˆåŠŸ ---")

            prompt = f"""
            You are a professional flight booking assistant. Please carefully read the user's flight booking instructions below and extract the key information.  
            You need to return the extracted information in a strict JSON format, without any additional explanations or text.  

            The fields to be extracted are as follows:  
            - "user_id": User ID (e.g., "mia_jackson_2156").  
            - "origin": Origin airport code (3 letters, e.g., "JFK", "SFO").  
            - "destination": Destination airport code (3 letters, e.g., "SEA", "LAX").  
            - "date": Departure date (format: "YYYY-MM-DD", default year is 2024).  
            - "cabin": Cabin class (must be one of "basic_economy", "economy", "business").  
            - "baggages": Number of baggage items (integer).  
            - "insurance": Whether insurance is needed ("yes" or "no").  
            - "constraints": A list of strings containing all other constraints and preferences.  

            User instructions:  
            "{instruction}"  

            JSON output:  
            """
            llm_process_feat= {"text_length": len(prompt), "token_count": estimate_tokens(prompt)}

            return json.dumps({
                "succ_task_feat": {
                    "task1_llm_process1": {"text_length": llm_process_feat["text_length"], "token_count": llm_process_feat["token_count"], "reason": 0}
                },
                "dag_id": dag_id,
                "curr_task_feat": None,
                "start_time": start_time,
                "end_time": time.time()
            })
        except FileNotFoundError as e:
            print(f"é”™è¯¯:æ•°æ®æ–‡ä»¶æ²¡æ‰¾åˆ°{e}")
            raise
    except Exception as e:
        print(f"task0_init å‘ç”Ÿé”™è¯¯: {str(e)}")
        return json.dumps({
            "dag_id": dag_id,
            "status": "failed",
            "start_time": start_time,
            "end_time": time.time(),            
            "result": f"task0_init å‘ç”Ÿé”™è¯¯: {str(e)}"
        })

@gpu(gpu_mem= 70000, model_name= "qwen3-32b", backend="huggingface")
def task1_llm_process1(context):
    """
    å·¥ä½œæµçš„ç¬¬1æ­¥ï¼š[LLM] æå–æ ¸å¿ƒè®¢ç¥¨ä¿¡æ¯ã€‚
    é‡‡ç”¨ä¸file/task.pyç›¸åŒçš„å¤§æ¨¡å‹æ¨ç†æ¨¡å¼ã€‚
    """
    print("--- å¼€å§‹æ‰§è¡Œ Task 1: LLMæå–æ ¸å¿ƒè®¢ç¥¨ä¿¡æ¯ ---")
    try:
        backend= task1_llm_process1._task_decorator["backend"]
        print(f"âœ… LLMæœºç¥¨é¢„è®¢ä¿¡æ¯æå–å¼€å§‹....")
        start_time= time.time()

        # ä»ä¸Šä¸‹æ–‡ä¸­è·å–å¿…è¦ä¿¡æ¯
        dag_id = ray.get(context.get.remote("dag_id"))
        instruction = ray.get(context.get.remote("instruction"))
        api_url = ray.get(context.get.remote("api_url"))
        api_key = ray.get(context.get.remote("api_key"))

        use_online_model= ray.get(context.get.remote("use_online_model"))
        model_folder= ray.get(context.get.remote("model_folder"))
        tokenizer_path= os.path.join(model_folder, "Qwen/Qwen3-32B")
        temperature, max_token, repetition_penalty, top_p= None, None, None, None
        if not use_online_model:
            temperature= ray.get(context.get.remote("temperature"))
            max_token= ray.get(context.get.remote("max_tokens"))
            top_p= ray.get(context.get.remote("top_p"))
            repetition_penalty= ray.get(context.get.remote("repetition_penalty"))

        # æ„å»ºæç¤º
        prompt = f"""
        You are a professional flight booking assistant. Please carefully read the user's instructions below and extract the key information.
        You must return the extracted information in strict JSON format without any additional explanations or text.

        Required fields to extract:
        - "user_id": User ID (e.g., "mia_kim_4397")
        - "cancel_reservation_id": Reservation ID to be canceled
        - "origin": New booking origin airport code (3-letter, e.g., "JFK", "EWR")
        - "destination": New booking destination airport code (3-letter, e.g., "SEA", "LAX")
        - "departure_date": Departure date (format: "YYYY-MM-DD", default year is 2024)
        - "return_date": Return date (format: "YYYY-MM-DD")
        - "cabin": Cabin class (must be one of: "basic_economy", "economy", "business")
        - "baggages": Number of baggage items (integer)
        - "insurance": Whether insurance is needed ("yes" or "no")
        - "payment_preference": Payment preference (e.g., "use_smaller_gift_card_first")
        - "constraints": A list of strings containing all other constraints and preferences

        User instructions:
        "{instruction}"

        JSON output:
        """
        print(f"ğŸš«DEBUG LLM prompt: {prompt}")
        # æ„å»ºAPIè¯·æ±‚payload
        payload = {
            "model": "Qwen/Qwen3-32B",
            "messages": [{"role": "user", "content": prompt}],
            "temperature": temperature,
            "max_tokens": max_token,
            "enable_thinking": False,
            "response_format": {"type": "text"}               
        }
        inference_features, answer= None, None
        if use_online_model:
            inference_features, answer= query_llm_online(
                api_url= api_url, 
                api_key= api_key, 
                payload= payload,
                tokenizer_path= tokenizer_path)
        elif backend == "vllm":
            inference_features, answer= query_vllm_model(
                api_url= ray.get(context.get.remote(f"task1_llm_process1_request_api_url")),
                model_alias= "qwen3-32b",
                messages= payload["messages"],
                temperature= temperature,
                max_token= max_token,
                top_p= top_p,
                repetition_penalty= repetition_penalty
            )
        else:
            inference_features, answer= query_llm(model_folder= model_folder, model= "Qwen/Qwen3-32B", messages= [{"role": "user", "content": prompt}], temperature= temperature, max_token= max_token, top_p= top_p, repetition_penalty= repetition_penalty)

        # print(f"LLMåŸå§‹è¾“å‡º: {answer}")

        # æå–JSON
        json_str = _extract_json_from_llm_output(answer)
        extracted_info= {}
        if not json_str:
            print("LLMæœªèƒ½ä»å…¶è¾“å‡ºä¸­æå–æœ‰æ•ˆçš„JSONã€‚")
        else:
            try:
                extracted_info = json.loads(json_str)
            except Exception as e:
                print(f"LLMæœªèƒ½ä»å…¶è¾“å‡ºä¸­æå–æœ‰æ•ˆçš„JSONã€‚")
        print(f"LLMæå–çš„extracted_info: {extracted_info}")
        # å°†æå–çš„ä¿¡æ¯å­˜å…¥ä¸Šä¸‹æ–‡
        context.put.remote("extracted_info", extracted_info)
        user_id = extracted_info["user_id"]
        context.put.remote("user_id", user_id)
        print(f"æå–ä¿¡æ¯æˆåŠŸ: {json.dumps(extracted_info, indent=2, ensure_ascii=False)}")
        
        return json.dumps({
            "dag_id": dag_id,
            "curr_task_feat": inference_features,
            "status": "æœºç¥¨é¢„è®¢ä¿¡æ¯æå–æˆåŠŸ",
            "start_time": start_time,
            "end_time": time.time(),
        })
    except Exception as e:
        print(f"task1_llm_process å‘ç”Ÿé”™è¯¯: {str(e)}")
        return json.dumps({
            "dag_id": dag_id,
            "status": "failed",
            "result": f"task1_llm_process å‘ç”Ÿé”™è¯¯: {str(e)}",
            "start_time": start_time,
            "end_time": time.time()
        })

@cpu(cpu_num= 1, mem= 1024)
def task2_get_user_and_reservation_details(context):
    """
    å·¥ä½œæµçš„ç¬¬2æ­¥ï¼š[Tool] è·å–ç”¨æˆ·å’Œé¢„è®¢è¯¦æƒ…ã€‚
    1. è·å–ç”¨æˆ·è¯¦ç»†ä¿¡æ¯
    2. è·å–éœ€è¦å–æ¶ˆçš„é¢„è®¢è¯¦æƒ…
    """

    print("--- å¼€å§‹æ‰§è¡Œ Task 2: è·å–ç”¨æˆ·å’Œé¢„è®¢è¯¦æƒ… ---")
    try:
        start_time= time.time()
        dag_id= ray.get(context.get.remote("dag_id"))
        backend_data = ray.get(context.get.remote("backend_data"))
        extracted_info = ray.get(context.get.remote("extracted_info"))
        user_id = ray.get(context.get.remote("user_id"))
        print(f"æ­£åœ¨è·å–ç”¨æˆ·ID: {user_id} çš„è¯¦æƒ…...")
        # è·å–ç”¨æˆ·è¯¦æƒ…
        user_details_str = GetUserDetails.invoke(backend_data, user_id)
        print(f"GetUserDetailsè¿”å›: {user_details_str}")
        
        if not user_details_str or user_details_str.strip() == "":
            raise ValueError("GetUserDetailsè¿”å›äº†ç©ºå­—ç¬¦ä¸²")
        
        if "Error" in user_details_str:
            raise ValueError(f"è·å–ç”¨æˆ·è¯¦æƒ…å¤±è´¥: {user_details_str}")
        
        try:
            user_details = json.loads(user_details_str)
        except json.JSONDecodeError as e:
            print(f"JSONè§£æé”™è¯¯ï¼ŒåŸå§‹å­—ç¬¦ä¸²: '{user_details_str}'")
            raise ValueError(f"æ— æ³•è§£æç”¨æˆ·è¯¦æƒ…JSON: {e}")
        
        context.put.remote("user_details", user_details)
        print(f"æˆåŠŸè·å–ç”¨æˆ·è¯¦æƒ…: {user_details.get('name', 'Unknown')}")
        
        # è·å–é¢„è®¢è¯¦æƒ…
        reservation_id = extracted_info.get("cancel_reservation_id")
        if reservation_id:
            print(f"æ­£åœ¨è·å–é¢„è®¢ID: {reservation_id} çš„è¯¦æƒ…...")
            reservation_details_str = GetReservationDetails.invoke(backend_data, reservation_id)
            print(f"GetReservationDetailsè¿”å›: {reservation_details_str}")
            
            if not reservation_details_str or reservation_details_str.strip() == "":
                raise ValueError("GetReservationDetailsè¿”å›äº†ç©ºå­—ç¬¦ä¸²")
            
            if "Error" in reservation_details_str:
                raise ValueError(f"è·å–é¢„è®¢è¯¦æƒ…å¤±è´¥: {reservation_details_str}")
            
            try:
                reservation_details = json.loads(reservation_details_str)
            except json.JSONDecodeError as e:
                print(f"JSONè§£æé”™è¯¯ï¼ŒåŸå§‹å­—ç¬¦ä¸²: '{reservation_details_str}'")
                raise ValueError(f"æ— æ³•è§£æé¢„è®¢è¯¦æƒ…JSON: {e}")
            
            context.put.remote("reservation_details", reservation_details)
            print(f"æˆåŠŸè·å–é¢„è®¢è¯¦æƒ…: {reservation_details.get('reservation_id', 'Unknown')}")
        else:
            print("æ²¡æœ‰éœ€è¦è·å–çš„é¢„è®¢ID")
        
        print("--- Task 2 æ‰§è¡Œå®Œæ¯• ---")
        return json.dumps({
            "dag_id": dag_id,
            "status": "è·å–ç”¨æˆ·å’Œé¢„è®¢è¯¦æƒ…æˆåŠŸ",
            "start_time": start_time,
            "end_time": time.time(),
        })
    except Exception as e:
        print(f"task2_get_user_and_reservation_details å‘ç”Ÿé”™è¯¯: {str(e)}")
        return json.dumps({
            "dag_id": dag_id,
            "status": "failed",
            "result": f"task2_get_user_and_reservation_details å‘ç”Ÿé”™è¯¯: {str(e)}",
            "start_time": start_time,
            "end_time": time.time()
        })

@io(mem= 1024)
def task3_cancel_reservation(context):
    """
    å·¥ä½œæµçš„ç¬¬3æ­¥ï¼š[Tool] å–æ¶ˆé¢„è®¢ã€‚
    è°ƒç”¨å–æ¶ˆé¢„è®¢å·¥å…·æ‰§è¡Œå–æ¶ˆæ“ä½œã€‚
    """
    print("--- å¼€å§‹æ‰§è¡Œ Task 3: å–æ¶ˆé¢„è®¢ ---")
    try:
        start_time= time.time()
        dag_id= ray.get(context.get.remote("dag_id"))
        backend_data = ray.get(context.get.remote("backend_data"))
        extracted_info = ray.get(context.get.remote("extracted_info"))
        reservation_id = extracted_info.get("cancel_reservation_id")
        if not reservation_id:
            print("æ²¡æœ‰éœ€è¦å–æ¶ˆçš„é¢„è®¢ID")
            context.put.remote("cancel_result", "æ— éœ€å–æ¶ˆé¢„è®¢")
            return json.dumps({
                "status": "æ— éœ€å–æ¶ˆé¢„è®¢",
                "dag_id": dag_id,
                "start_time": start_time,
                "end_time": time.time()
                })
        
        # è°ƒç”¨å·¥å…·
        result = CancelReservation.invoke(backend_data, reservation_id)
        context.put.remote("cancel_result", result)
        print(f"å–æ¶ˆé¢„è®¢ç»“æœ: {result}")
        print("--- Task 3 æ‰§è¡Œå®Œæ¯• ---")
        return json.dumps({
            "status": "å–æ¶ˆé¢„è®¢æˆåŠŸ",
            "dag_id": dag_id,
            "start_time": start_time,
            "end_time": time.time()
        })
    except Exception as e:
        print(f"task3_cancel_reservation å‘ç”Ÿé”™è¯¯: {str(e)}")
        return json.dumps({
            "dag_id": dag_id,
            "status": "failed",
            "result": f"task3_cancel_reservation å‘ç”Ÿé”™è¯¯: {str(e)}",
            "start_time": start_time,
            "end_time": time.time()
        })

@cpu(cpu_num= 1, mem= 1024)
def task4_search_new_flights(context):
    """
    å·¥ä½œæµçš„ç¬¬4æ­¥ï¼š[Tool] æœç´¢æ–°èˆªç­ã€‚
    æ ¹æ®ç”¨æˆ·è¦æ±‚æœç´¢æ–°çš„èˆªç­ã€‚
    """

    print("--- å¼€å§‹æ‰§è¡Œ Task 4: æœç´¢æ–°èˆªç­ ---")
    try:
        start_time= time.time()
        dag_id= ray.get(context.get.remote("dag_id"))
        backend_data = ray.get(context.get.remote("backend_data"))
        extracted_info = ray.get(context.get.remote("extracted_info"))
        origin = extracted_info.get("origin")
        destination = extracted_info.get("destination")
        departure_date = extracted_info.get("departure_date")
        return_date = extracted_info.get("return_date")
        
        print(f"æœç´¢æ¡ä»¶: ä» {origin} åˆ° {destination}, å‡ºå‘æ—¥æœŸ: {departure_date}, è¿”å›æ—¥æœŸ: {return_date}")
        
        # ä½¿ç”¨ SearchDirectFlight å·¥å…·æœç´¢èˆªç­
        outbound_flights = []
        return_flights = []
        
        # æœç´¢å»ç¨‹èˆªç­
        outbound_flights_str = SearchDirectFlight.invoke(backend_data, origin, destination, departure_date)
        outbound_flights = json.loads(outbound_flights_str)
        if not outbound_flights:
            print(f"WARNING:æœªæ‰¾åˆ°ä» {origin}åˆ°{destination}çš„èˆªç­")
        else:
            print(f"æ‰¾åˆ° {len(outbound_flights)} ä¸ªå»ç¨‹èˆªç­")
            for flight in outbound_flights:
                print(f"èˆªç­å·: {flight['flight_number']}, ä»·æ ¼: {flight['prices']}")
        
        # æœç´¢è¿”ç¨‹èˆªç­
        if return_date:
            return_flights_str = SearchDirectFlight.invoke(backend_data, destination, origin, return_date)
            return_flights = json.loads(return_flights_str)
            if not return_flights:
                print(f"WARNING: æœªæ‰¾åˆ°ä» {destination} åˆ° {origin} çš„èˆªç­")
            else:
                print(f"æ‰¾åˆ° {len(return_flights)} ä¸ªè¿”ç¨‹èˆªç­")
                for flight in return_flights:
                    print(f"èˆªç­å·: {flight['flight_number']}, ä»·æ ¼: {flight['prices']}")
        
        context.put.remote("outbound_flights", outbound_flights)
        if return_date:
            context.put.remote("return_flights", return_flights)
        
        print(f"æ‰¾åˆ° {len(outbound_flights)} ä¸ªå»ç¨‹èˆªç­å’Œ {len(return_flights) if return_date else 0} ä¸ªè¿”ç¨‹èˆªç­")
        print("--- Task 4 æ‰§è¡Œå®Œæ¯• ---")
        prompt = f"""
        You are a professional flight booking decision assistant.
        Your task is to select the most suitable flights from the candidate options based on user preferences.

        # User Preferences
        {json.dumps(extracted_info, indent=2)}

        # Candidate Flights
        Outbound Flights:
        {json.dumps(outbound_flights, indent=2)}

        Return Flights:
        {json.dumps(return_flights, indent=2)}

        # Your Task
        1. Carefully read and understand each of the user's requirements
        2. Select the most appropriate flight combination from the candidates
        3. Return the chosen flight numbers in strict JSON format as follows:
        {{
            "outbound_flight_number": "xxx",
            "return_flight_number": "xxx"
        }}

        Notes:
        - If no suitable flight is found, the corresponding value can be null.
        - Ensure the returned JSON format is correct.
        """
        llm_process_feat= {"text_length": len(prompt), "token_count": estimate_tokens(prompt)}

        return json.dumps({
            "dag_id": dag_id,
            "succ_task_feat": {
                "task5_llm_process2": {"text_length": llm_process_feat["text_length"], "token_count": llm_process_feat["token_count"], "reason": 0}
            },
            "curr_task_feat": None,
            "status": "æœç´¢æ–°èˆªç­æˆåŠŸ",
            "start_time": start_time,
            "end_time": time.time(),
        })
    except Exception as e:
        print(f"task4_search_new_flights å‘ç”Ÿé”™è¯¯: {str(e)}")
        return json.dumps({
            "dag_id": dag_id,
            "status": "failed",
            "result": f"task4_search_new_flights å‘ç”Ÿé”™è¯¯: {str(e)}",
            "start_time": start_time,
            "end_time": time.time(),
        })


@gpu(gpu_mem= 70000, model_name= "qwen3-32b", backend="huggingface")
def task5_llm_process2(context):
    """
    å·¥ä½œæµçš„ç¬¬5æ­¥ï¼š[LLM] é€‰æ‹©èˆªç­ã€‚
    ä½¿ç”¨LLMæ ¹æ®ç”¨æˆ·åå¥½ä»å€™é€‰èˆªç­ä¸­é€‰æ‹©æœ€åˆé€‚çš„èˆªç­ã€‚
    é‡‡ç”¨ä¸file/task.pyç›¸åŒçš„å¤§æ¨¡å‹æ¨ç†æ¨¡å¼ã€‚
    """
    print("--- å¼€å§‹æ‰§è¡Œ Task 5: LLMé€‰æ‹©èˆªç­ ---")
    try:
        backend = task5_llm_process2._task_decorator["backend"]
        print(f"âœ… LLMèˆªç­é€‰æ‹©å¼€å§‹....")
        start_time = time.time()  # è®°å½•å¼€å§‹æ—¶é—´ 
        dag_id = ray.get(context.get.remote("dag_id"))
        instruction = ray.get(context.get.remote("instruction"))
        api_url = ray.get(context.get.remote("api_url"))
        api_key = ray.get(context.get.remote("api_key"))

        use_online_model= ray.get(context.get.remote("use_online_model"))
        model_folder= ray.get(context.get.remote("model_folder"))
        tokenizer_path= os.path.join(model_folder, "Qwen/Qwen3-32B")
        temperature, max_token, repetition_penalty, top_p= None, None, None, None
        if not use_online_model:
            temperature= ray.get(context.get.remote("temperature"))
            max_token= ray.get(context.get.remote("max_tokens"))
            top_p= ray.get(context.get.remote("top_p"))
            repetition_penalty= ray.get(context.get.remote("repetition_penalty"))
        # ä»ä¸Šä¸‹æ–‡ä¸­è·å–å¿…è¦ä¿¡æ¯
        if not instruction:
            raise ValueError(f"ä»»åŠ¡ {dag_id} ç¼ºå°‘ instruction")

        extracted_info = ray.get(context.get.remote("extracted_info"))
        outbound_flights = ray.get(context.get.remote("outbound_flights"))
        
        # å®‰å…¨åœ°è·å–return_flightsï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä½¿ç”¨ç©ºåˆ—è¡¨
        try:
            return_flights = ray.get(context.get.remote("return_flights"))
        except:
            return_flights = []
        
        if not outbound_flights:
            return json.dumps({
                "dag_id": dag_id,
                "status": "æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„å»ç¨‹èˆªç­",
                "start_time": start_time,
                "end_time": time.time()
            })
        
        # æ„å»ºæç¤º
        prompt = f"""
        You are a professional flight booking decision assistant.
        Your task is to select the most suitable flights from the candidate options based on user preferences.

        # User Preferences
        {json.dumps(extracted_info, indent=2)}

        # Candidate Flights
        Outbound Flights:
        {json.dumps(outbound_flights, indent=2)}

        Return Flights:
        {json.dumps(return_flights, indent=2)}

        # Your Task
        1. Carefully read and understand each of the user's requirements
        2. Select the most appropriate flight combination from the candidates
        3. Return the chosen flight numbers in strict JSON format as follows:
        {{
            "outbound_flight_number": "xxx",
            "return_flight_number": "xxx"
        }}

        Notes:
        - If no suitable flight is found, the corresponding value can be null.
        - Ensure the returned JSON format is correct.
        """
        
        # æ„å»ºAPIè¯·æ±‚payload
        payload = {
            "model": "Qwen/Qwen3-32B",
            "messages": [{"role": "user", "content": prompt}],
            "temperature": temperature,
            "max_tokens": max_token,
            "enable_thinking": False,
            "response_format": {"type": "text"}               
        }
        inference_features, llm_output= None, None
        if use_online_model:
            inference_features, llm_output= query_llm_online(
                api_url= api_url, 
                api_key= api_key, 
                payload= payload,
                tokenizer_path= tokenizer_path)
        elif backend == "vllm":
            inference_features, llm_output= query_vllm_model(
                api_url= ray.get(context.get.remote(f"task5_llm_process2_request_api_url")),
                model_alias= "qwen3-32b",
                messages= payload["messages"],
                temperature= temperature,
                max_token= max_token,
                top_p= top_p,
                repetition_penalty= repetition_penalty
            )
        else:
            inference_features, llm_output= query_llm(model_folder= model_folder, model= "Qwen/Qwen3-32B", messages= [{"role": "user", "content": prompt}], temperature= temperature, max_token= max_token, top_p= top_p, repetition_penalty= repetition_penalty)

        print(f"LLMåŸå§‹è¾“å‡º: {llm_output}")

        # æå–JSON
        selected_flights = None
        json_str = _extract_json_from_llm_output(llm_output)
        if json_str:
            try:
                selected_flights = json.loads(json_str)
            except json.JSONDecodeError:
                print(f"âŒ JSONè§£æå¤±è´¥ï¼æ— æ³•è§£æçš„å­—ç¬¦ä¸²æ˜¯: '{json_str}'")
        # åœ¨è¿™é‡Œä½ å¯ä»¥å†³å®šæ˜¯æŠ›å‡ºå¼‚å¸¸ï¼Œè¿˜æ˜¯ç»™ä¸€ä¸ªé»˜è®¤å€¼ç»§ç»­è¿è¡Œ
        context.put.remote("selected_flights", selected_flights)
        print(f"LLMé€‰æ‹©çš„èˆªç­: {json.dumps(selected_flights, indent=2, ensure_ascii=False)}")
        
        return json.dumps({
            "dag_id": dag_id,
            "curr_task_feat": inference_features,
            "status": "èˆªç­é€‰æ‹©æˆåŠŸ",
            "start_time": start_time,
            "end_time": time.time(),
        })
    except Exception as e:
        print(f"task5_llm_process2 å‘ç”Ÿé”™è¯¯: {str(e)}")
        return json.dumps({
            "dag_id": dag_id,
            "status": "failed",
            "result": f"task5_llm_process2 å‘ç”Ÿé”™è¯¯: {str(e)}",
            "start_time": start_time,
            "end_time": time.time(),
        })

@cpu(cpu_num= 1, mem= 1024)
def task6_book_new_reservation(context):
    """
    å·¥ä½œæµçš„ç¬¬6æ­¥ï¼š[Tool] æ‰§è¡Œæ–°é¢„è®¢ã€‚
    ä½¿ç”¨é€‰æ‹©å¥½çš„èˆªç­ä¿¡æ¯æ‰§è¡Œæ–°çš„é¢„è®¢ã€‚
    """

    print("--- å¼€å§‹æ‰§è¡Œ Task 6: æ‰§è¡Œæ–°é¢„è®¢ ---")
    try:
        start_time= time.time()
        dag_id= ray.get(context.get.remote("dag_id"))
        backend_data = ray.get(context.get.remote("backend_data"))
        extracted_info = ray.get(context.get.remote("extracted_info"))
        user_details = ray.get(context.get.remote("user_details"))
        outbound_flights = ray.get(context.get.remote("outbound_flights"))
        try:
            selected_flights = ray.get(context.get.remote("selected_flights"))
        except:
            return json.dumps({
                "dag_id": dag_id,
                "start_time": start_time,
                "end_time": time.time(),
                "status": "æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„å»ç¨‹èˆªç­"
            })

        # å®‰å…¨åœ°è·å–return_flightsï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä½¿ç”¨ç©ºåˆ—è¡¨
        try:
            return_flights = ray.get(context.get.remote("return_flights"))
        except:
            return_flights = []
        
        outbound_flight_num = selected_flights.get("outbound_flight_number")
        return_flight_num = selected_flights.get("return_flight_number")
        
        if not isinstance(selected_flights, dict):
            return json.dumps({"status": "æ–°é¢„è®¢å®Œæˆ", "dag_id": dag_id, "start_time": start_time, "end_time": time.time(), "result": "é€‰æ‹©çš„èˆªç­ä¿¡æ¯æ ¼å¼ä¸æ­£ç¡®"})            
            # raise ValueError("é€‰æ‹©çš„èˆªç­ä¿¡æ¯æ ¼å¼ä¸æ­£ç¡®")

        if not outbound_flight_num:
            return json.dumps({"status": "æ–°é¢„è®¢å®Œæˆ", "dag_id": dag_id, "start_time": start_time, "end_time": time.time(), "result": "LLMæœªèƒ½é€‰æ‹©æœ‰æ•ˆçš„å»ç¨‹èˆªç­"})            
            # raise ValueError("LLMæœªèƒ½é€‰æ‹©æœ‰æ•ˆçš„å»ç¨‹èˆªç­")

        # æ ¹æ®èˆªç­å·ä»å€™é€‰èˆªç­ä¸­æ‰¾åˆ°å®Œæ•´çš„èˆªç­ä¿¡æ¯ä»¥è·å–ä»·æ ¼
        selected_outbound_flight = next((f for f in outbound_flights if f.get("flight_number") == outbound_flight_num), None)
        
        selected_return_flight = None
        if return_flight_num:
            selected_return_flight = next((f for f in return_flights if f.get("flight_number") == return_flight_num), None)

        if not selected_outbound_flight:
            return json.dumps({"status": "æ–°é¢„è®¢å®Œæˆ", "start_time": start_time, "end_time": time.time(), "result": f"æ— æ³•åœ¨å€™é€‰èˆªç­ä¸­æ‰¾åˆ°å»ç¨‹èˆªç­ {outbound_flight_num}"})
            # raise ValueError(f"æ— æ³•åœ¨å€™é€‰èˆªç­ä¸­æ‰¾åˆ°å»ç¨‹èˆªç­ {outbound_flight_num}")
        if return_flight_num and not selected_return_flight:
            return json.dumps({"status": "æ–°é¢„è®¢å®Œæˆ", "start_time": start_time, "end_time": time.time(), "result": f"æ— æ³•åœ¨å€™é€‰èˆªç­ä¸­æ‰¾åˆ°è¿”ç¨‹èˆªç­ {return_flight_num}"})
            # raise ValueError(f"æ— æ³•åœ¨å€™é€‰èˆªç­ä¸­æ‰¾åˆ°è¿”ç¨‹èˆªç­ {return_flight_num}")
        
        # å‡†å¤‡ä¹˜å®¢ä¿¡æ¯ - æ”¯æŒå¤šä¹˜å®¢
        passengers = []
        # ä»ç”¨æˆ·æŒ‡ä»¤ä¸­æå–ä¹˜å®¢æ•°é‡ï¼Œå¦‚æœæ²¡æœ‰æŒ‡å®šåˆ™é»˜è®¤ä¸º1
        num_passengers = extracted_info.get("num_passengers", 1)
        
        # å¦‚æœç”¨æˆ·æä¾›äº†å…¶ä»–ä¹˜å®¢ä¿¡æ¯ï¼Œåˆ™ä½¿ç”¨æä¾›çš„ä¿¡æ¯
        if "passengers" in extracted_info:
            passengers = extracted_info["passengers"]
        else:
            # å¦åˆ™ä½¿ç”¨ç”¨æˆ·ä¿¡æ¯ä½œä¸ºé»˜è®¤ä¹˜å®¢
            for _ in range(num_passengers):
                passengers.append({
                    "first_name": user_details["name"]["first_name"],
                    "last_name": user_details["name"]["last_name"],
                    "dob": user_details["dob"]
                })

        # è®¡ç®—æ€»ä»·
        cabin = extracted_info.get("cabin", "basic_economy")
        total_price = 0
        if selected_outbound_flight:
            total_price += selected_outbound_flight.get("prices", {}).get(cabin, 0)
        if selected_return_flight:
            total_price += selected_return_flight.get("prices", {}).get(cabin, 0)
        
        total_price *= len(passengers)
        total_baggages = extracted_info.get("baggages", 0)
        # è¡Œæè´¹è®¡ç®—
        nonfree_baggages = total_baggages - len(passengers) if total_baggages > len(passengers) else 0
        total_price += 50 * nonfree_baggages  # æ¯ä»¶éå…è´¹è¡Œæ$50

        if extracted_info.get("insurance") == "yes":
            total_price += 30 * len(passengers)

        # æ”¯ä»˜é€»è¾‘
        payment_methods_for_booking = []
        remaining_balance = total_price

        user_payment_methods = user_details.get("payment_methods", {})
        # ä¼˜å…ˆä½¿ç”¨è¯ä¹¦
        certificates = sorted(
            [pm for pm in user_payment_methods.values() if isinstance(pm, dict) and pm.get("source") == "certificate"],
            key=lambda x: x.get("amount", 0)
        )
        for pm in certificates:
            if remaining_balance > 0:
                amount_to_use = min(remaining_balance, pm.get("amount", 0))
                payment_methods_for_booking.append({"payment_id": pm.get("id"), "amount": amount_to_use})
                remaining_balance -= amount_to_use
        
        # ç„¶åä½¿ç”¨ç¤¼å“å¡
        gift_cards = sorted(
            [pm for pm in user_payment_methods.values() if isinstance(pm, dict) and pm.get("source") == "gift_card"],
            key=lambda x: x.get("amount", 0)
        )
        if extracted_info.get("payment_preference") == "use_larger_gift_card_first":
            gift_cards.reverse()
        
        for pm in gift_cards:
            if remaining_balance > 0:
                amount_to_use = min(remaining_balance, pm.get("amount", 0))
                payment_methods_for_booking.append({"payment_id": pm.get("id"), "amount": amount_to_use})
                remaining_balance -= amount_to_use

        # æœ€åä½¿ç”¨ä¿¡ç”¨å¡æ”¯ä»˜å‰©ä½™éƒ¨åˆ†
        if remaining_balance > 0.01:
            credit_card = next((pm for pm in user_payment_methods.values() if isinstance(pm, dict) and pm.get("source") == "credit_card"), None)
            if credit_card:
                payment_methods_for_booking.append({"payment_id": credit_card.get("id"), "amount": round(remaining_balance, 2)})
                remaining_balance = 0
        
        if remaining_balance > 0.01:
            return json.dumps({"status": "æ”¯ä»˜å¤±è´¥", "start_time": start_time, "end_time": time.time(), "result": f"æ”¯ä»˜å¤±è´¥ï¼šç”¨æˆ·æ²¡æœ‰è¶³å¤Ÿçš„æ”¯ä»˜æ–¹å¼æˆ–ä½™é¢æ¥å®Œæˆæ”¯ä»˜ã€‚å‰©ä½™é‡‘é¢: {remaining_balance}"})

        # å‡†å¤‡ç”¨äºé¢„è®¢çš„èˆªç­ä¿¡æ¯ï¼ˆåŒ…å«æ­£ç¡®çš„æ—¥æœŸï¼‰
        flights_for_booking_simple = []
        if outbound_flight_num:
            flights_for_booking_simple.append({
                "flight_number": outbound_flight_num,
                "date": extracted_info.get("departure_date")
            })
        if return_flight_num:
            flights_for_booking_simple.append({
                "flight_number": return_flight_num,
                "date": extracted_info.get("return_date")
            })

        # ç»„è£…é¢„è®¢å‚æ•°
        booking_args = {
            "user_id": ray.get(context.get.remote("user_id")),
            "origin": extracted_info.get("origin"),
            "destination": extracted_info.get("destination"),
            "flight_type": "round_trip" if return_flight_num else "one_way",
            "cabin": cabin,
            "flights": flights_for_booking_simple,
            "passengers": passengers,
            "payment_methods": payment_methods_for_booking,
            "total_baggages": total_baggages,
            "nonfree_baggages": nonfree_baggages,
            "insurance": extracted_info.get("insurance", "no")
        }
        
        # æ‰§è¡Œé¢„è®¢
        result = BookReservation.invoke(backend_data, **booking_args)
        context.put.remote("booking_result", result)
        
        print("--- Task 6 æ‰§è¡Œå®Œæ¯• ---")
        return json.dumps({
            "status": "æ–°é¢„è®¢å®Œæˆ",
            "dag_id": dag_id,
            "result": result,
            "start_time": start_time,
            "end_time": time.time(),
        })
    except Exception as e:
        print(f"task6_book_new_reservation å‘ç”Ÿé”™è¯¯: {str(e)}")
        return json.dumps({
            "dag_id": dag_id,
            "status": "failed",
            "result": f"task6_book_new_reservation å‘ç”Ÿé”™è¯¯: {str(e)}",
            "start_time": start_time,
            "end_time": time.time(),
        })