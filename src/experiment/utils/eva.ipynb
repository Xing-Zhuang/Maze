{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import warnings\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import matplotlib.font_manager as font_manager\n",
    "from matplotlib.font_manager import FontProperties\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams.update({\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": [\"Times New Roman\"]})\n",
    "# --- æ•°æ®å’Œè®¾ç½® ---\n",
    "categories = ['$C1$', '$C2$', '$C3$']\n",
    "bar_width = 0.2\n",
    "index = np.arange(len(categories))\n",
    "\n",
    "# ç¬¬ä¸€ä¸ªå›¾çš„æ•°æ®\n",
    "values1_plot1 = [6.33, 3.12, 2.71]\n",
    "values2_plot1 = [6.806, 6.315, 6.486]\n",
    "values3_plot1 = [9.7325, 9.2154, 9.7853]\n",
    "\n",
    "# ç¬¬äºŒä¸ªå›¾çš„æ•°æ®\n",
    "values1_plot2 = [73.06, 78.76, 81.35]\n",
    "values2_plot2 = [20.034, 21.85, 24.15]\n",
    "values3_plot2 = [21.85, 22.375, 23.15]\n",
    "\n",
    "# --- åˆ›å»ºåŒ…å«ä¸¤ä¸ªå­å›¾çš„å›¾çª— ---\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(13.4, 4))\n",
    "\n",
    "# --- ç»˜åˆ¶ç¬¬ä¸€ä¸ªå­å›¾ (å·¦ä¾§) ---\n",
    "ax1.bar(index - bar_width, values1_plot1, bar_width, color='sandybrown', edgecolor='white', label='EDAgent', hatch='x')\n",
    "ax1.bar(index, values2_plot1, bar_width, color='#3e75b0', edgecolor='white', label='Static', hatch='\\\\')\n",
    "ax1.bar(index + bar_width, values3_plot1, bar_width, color='green', edgecolor='white', label='Serial', hatch='--')\n",
    "\n",
    "ax1.set_xticks(index)\n",
    "ax1.set_ylim(0, 20)\n",
    "ax1.set_xticklabels(categories)\n",
    "ax1.set_ylabel('Avg. completion \\n time per task (s)', fontsize=26)\n",
    "ax1.grid(True, axis='y', linestyle='--', color='gray', alpha=0.9)\n",
    "ax1.tick_params(labelsize=26)\n",
    "\n",
    "# --- ç»˜åˆ¶ç¬¬äºŒä¸ªå­å›¾ (å³ä¾§) ---\n",
    "ax2.bar(index - bar_width, values1_plot2, bar_width, color='sandybrown', edgecolor='white', label='EDAgent', hatch='x')\n",
    "ax2.bar(index, values2_plot2, bar_width, color='#3e75b0', edgecolor='white', label='Static', hatch='\\\\')\n",
    "ax2.bar(index + bar_width, values3_plot2, bar_width, color='green', edgecolor='white', label='Serial', hatch='--')\n",
    "\n",
    "ax2.set_xticks(index)\n",
    "ax2.set_ylim(0, 100)\n",
    "ax2.set_xticklabels(categories)\n",
    "ax2.set_ylabel('Avg. utilization \\n rate per agent (%)', fontsize=26)\n",
    "ax2.grid(True, axis='y', linestyle='--', color='gray', alpha=0.9)\n",
    "ax2.tick_params(labelsize=26)\n",
    "\n",
    "\n",
    "# ä»å­å›¾è·å–å›¾ä¾‹çš„å¥æŸ„å’Œæ ‡ç­¾\n",
    "handles, labels = ax1.get_legend_handles_labels()\n",
    "# åœ¨å›¾çª—çº§åˆ«æ·»åŠ ä¸€ä¸ªå±…ä¸­çš„å…±äº«å›¾ä¾‹\n",
    "fig.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.5, 1.12), numpoints=1, fontsize=26, ncol=3, frameon=True, edgecolor='black')\n",
    "\n",
    "\n",
    "# è°ƒæ•´å­å›¾å¸ƒå±€\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95]) \n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "# ä¿å­˜åçš„å›¾åƒ\n",
    "plt.savefig('./Fig1.pdf', format=\"pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "# æ˜¾ç¤ºå›¾åƒ\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # install TNR\n",
    "# !cp /usr/share/fonts/truetype/msttcorefonts/Times_New_Roman.ttf .\n",
    "# !cp /usr/share/fonts/truetype/msttcorefonts/Con.ttf .\n",
    "# os.system('cp /usr/share/fonts/truetype/msttcorefonts/Times_New_Roman.ttf .')\n",
    "# current_dir = os.path.abspath('.')\n",
    "# font_manager.fontManager.addfont(os.path.join(current_dir, 'Times_New_Roman.ttf'))\n",
    "# mpl.rcParams['font.family'] = 'serif'\n",
    "# mpl.rcParams['font.serif'] = ['Times New Roman']\n",
    "# print(\"å¯ç”¨å­—ä½“:\", [f.name for f in font_manager.fontManager.ttflist if 'Times' in f.name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font_dir = os.path.expanduser(\"./fonts/\")\n",
    "for font_file in os.listdir(font_dir):\n",
    "    if font_file.endswith('.ttf'):\n",
    "        font_manager.fontManager.addfont(os.path.join(font_dir, font_file))\n",
    "print(\"å·²åŠ è½½çš„ Arial å­—ä½“å˜ä½“:\", \n",
    "      [f.name for f in font_manager.fontManager.ttflist if 'Arial' in f.name])\n",
    "# è®¾ç½®ä¸º Arial æˆ– Helvetica\n",
    "plt.rcParams.update({\n",
    "    'font.family': 'sans-serif',        # ä½¿ç”¨æ— è¡¬çº¿å­—ä½“æ—\n",
    "    'font.sans-serif': ['Arial', 'Helvetica',  'Times New Roman'],  # ä¼˜å…ˆå°è¯• Arialï¼Œå¤±è´¥åå›é€€åˆ° Helvetica\n",
    "    # 'font.weight': 'bold',\n",
    "    'axes.labelsize': 26,\n",
    "    # 'axes.labelweight': 'bold',\n",
    "    'xtick.labelsize': 26,\n",
    "    'ytick.labelsize': 26,\n",
    "    'legend.fontsize': 20,\n",
    "    # 'legend.edgecolor': 'black',\n",
    "    'legend.frameon': True,\n",
    "})\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "# éªŒè¯å­—ä½“æ˜¯å¦ç”Ÿæ•ˆ\n",
    "print(\"å½“å‰ä½¿ç”¨çš„å­—ä½“:\", plt.rcParams['font.sans-serif'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.rcParams.update({\n",
    "#     'font.family': 'Times New Roman',\n",
    "#     'font.serif': ['Times New Roman'],\n",
    "#     'font.weight': 'bold',\n",
    "#     'axes.labelweight': 'bold',      # åæ ‡è½´æ ‡ç­¾åŠ ç²—\n",
    "#     'axes.titleweight': 'bold',      # æ ‡é¢˜åŠ ç²—\n",
    "#     'axes.edgecolor': 'black',       # åæ ‡è½´è¾¹æ¡†ä½¿ç”¨çº¯é»‘è‰²\n",
    "#     'axes.labelcolor': 'black',      # åæ ‡è½´æ ‡ç­¾æ–‡æœ¬ä½¿ç”¨çº¯é»‘è‰²\n",
    "#     'xtick.color': 'black',          # Xè½´åˆ»åº¦æ–‡æœ¬ä½¿ç”¨çº¯é»‘è‰²\n",
    "#     'ytick.color': 'black',          # Yè½´åˆ»åº¦æ–‡æœ¬ä½¿ç”¨çº¯é»‘è‰²\n",
    "#     'legend.edgecolor': 'black',     # å›¾ä¾‹è¾¹æ¡†ä½¿ç”¨çº¯é»‘è‰²\n",
    "#     'text.color': 'black',           # æ‰€æœ‰å…¶ä»–æ–‡æœ¬å…ƒç´ ä½¿ç”¨çº¯é»‘è‰²\n",
    "#     'axes.labelsize': 16,\n",
    "#     'xtick.labelsize': 16,\n",
    "#     'ytick.labelsize': 16,\n",
    "#     'legend.fontsize': 16,\n",
    "#     'figure.dpi': 300,\n",
    "# })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exp 1 agent framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### continuous arrival experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALGORITHMS_TO_PLOT = ['Maze', 'AutoGen', 'AgentScope', 'Maze(vLLM)', 'vLLM'] \n",
    "# æ•°æ®åˆ†æçš„æ—¶é—´çª—å£å¤§å°ï¼ˆç§’ï¼‰\n",
    "WINDOW_SIZE_SEC = 120\n",
    "# æ ¡å‡†å‡ºçš„å•ä¸ªQueryå¹³å‡å®Œæˆæ—¶é—´ï¼ˆç§’ï¼‰\n",
    "AVG_DAG_COMPLETE_TIME = 45\n",
    "\n",
    "# æ ¸å¿ƒä¿®æ­£ #1: ä½¿ç”¨ä½ æœ€æ–°çš„è´Ÿè½½å‰–é¢\n",
    "LOAD_PROFILE = [\n",
    "    (600, (0.5 / AVG_DAG_COMPLETE_TIME)),\n",
    "    (600, (0.75 / AVG_DAG_COMPLETE_TIME)),\n",
    "    (600, (1.0 / AVG_DAG_COMPLETE_TIME)),\n",
    "    (600, (1.25 / AVG_DAG_COMPLETE_TIME)),\n",
    "    (600, (0.5 / AVG_DAG_COMPLETE_TIME)),\n",
    "]\n",
    "\n",
    "RESOURCE_PLOT_INTERVAL = (1800, 2400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_plot_styles(algorithms):\n",
    "    \"\"\"ä¸ºä¸åŒç®—æ³•ç”Ÿæˆç»Ÿä¸€çš„é¢œè‰²ã€çº¿å‹å’Œæ ‡è®°æ ·å¼\"\"\"\n",
    "    # ä¸ºæˆ‘ä»¬çš„æ¡†æ¶ä½¿ç”¨é†’ç›®çš„é¢œè‰²\n",
    "    color_map = {\n",
    "        'Maze': \"#d52627\", \n",
    "        'Maze(vLLM)': \"#1E76B3\", \n",
    "        'Maze(vLLM-10)': \"#FE7E0D\", \n",
    "        'AutoGen': \"#2B9F2B\", \n",
    "        'AgentScope': \"#9366BD\", \n",
    "        'vLLM': \"#8B554A\", \n",
    "    }\n",
    "    # å¢åŠ æ›´å¤šå¤‡ç”¨é¢œè‰²\n",
    "    default_colors = sns.color_palette('deep', n_colors=len(algorithms))\n",
    "    \n",
    "    linestyles = ['-', '--', ':', '-.'] # <--- å¢åŠ äº†ä¸€ç§çº¿å‹\n",
    "    markers = ['o', 's', '^', 'X', 'D'] # <--- å¢åŠ äº†ä¸¤ç§æ ‡è®°\n",
    "    styles = {}\n",
    "    for i, algo in enumerate(algorithms):\n",
    "        styles[algo] = {\n",
    "            'color': color_map.get(algo, default_colors[i % len(default_colors)]),\n",
    "            'linestyle': linestyles[i % len(linestyles)],\n",
    "            'marker': markers[i % len(markers)],\n",
    "            'linewidth': 5,\n",
    "            'markersize': 20,\n",
    "        }\n",
    "    return styles\n",
    "PLOT_STYLES = generate_plot_styles(ALGORITHMS_TO_PLOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_process_performance_data(filepath, algorithm_name):\n",
    "    \"\"\"\n",
    "    åŠ è½½å¹¶å¤„ç†æ€§èƒ½æ•°æ®(task_exec_time.csv)ã€‚\n",
    "    æ ¸å¿ƒä¿®æ­£ #2: åŒæ—¶å¤„ç† JCT å’Œ Response Timeã€‚\n",
    "    \"\"\"\n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"  âŒ è­¦å‘Š: æ€§èƒ½æ–‡ä»¶æœªæ‰¾åˆ°: {filepath}\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(filepath)\n",
    "        # ç»Ÿä¸€å°† 'uuid' åˆ—é‡å‘½åä¸º 'run_id' ä»¥ä¾¿å¤„ç†\n",
    "        if 'uuid' in df.columns:\n",
    "            df.rename(columns={'uuid': 'run_id'}, inplace=True)\n",
    "\n",
    "        # ç¡®ä¿æ‰€æœ‰å¿…éœ€çš„åˆ—éƒ½å­˜åœ¨\n",
    "        required_cols = ['run_id', 'arrival_time', 'finish_exec_time', 'response_time']\n",
    "        if not all(col in df.columns for col in required_cols):\n",
    "            print(f\"  âŒ é”™è¯¯: æ–‡ä»¶ {filepath} ç¼ºå°‘å¿…éœ€çš„åˆ—ã€‚\")\n",
    "            return None\n",
    "\n",
    "        # æŒ‰run_idèšåˆï¼Œè®¡ç®—æ¯ä¸ªDAGçš„æŒ‡æ ‡\n",
    "        dag_runs = df.groupby('run_id').agg(\n",
    "            dag_arrival_time=('arrival_time', 'min'),\n",
    "            dag_finish_time=('finish_exec_time', 'max'),\n",
    "            # DAGçš„Response Timeæ˜¯å…¶æ‰€æœ‰ä»»åŠ¡ä¸­æœ€å¤§çš„Response Time\n",
    "            dag_response_time=('response_time', 'max') \n",
    "        ).reset_index()\n",
    "\n",
    "        # è½¬æ¢ä¸ºæ•°å€¼ç±»å‹å¹¶å¤„ç†é”™è¯¯\n",
    "        for col in ['dag_arrival_time', 'dag_finish_time', 'dag_response_time']:\n",
    "            dag_runs[col] = pd.to_numeric(dag_runs[col], errors='coerce')\n",
    "        dag_runs.dropna(inplace=True)\n",
    "\n",
    "        # è®¡ç®—JCT\n",
    "        dag_runs['dct'] = dag_runs['dag_finish_time'] - dag_runs['dag_arrival_time']\n",
    "        \n",
    "        # è¿‡æ»¤æ‰å¼‚å¸¸æ•°æ®\n",
    "        dag_runs = dag_runs[(dag_runs['dct'] >= 0) & (dag_runs['dag_response_time'] >= 0)]\n",
    "        \n",
    "        print(f\"  âœ… æˆåŠŸåŠ è½½å¹¶å¤„ç†äº† {len(dag_runs)} ä¸ªDAGçš„æ€§èƒ½æ•°æ®ã€‚\")\n",
    "        return dag_runs\n",
    "    except Exception as e:\n",
    "        print(f\"  âŒ é”™è¯¯: å¤„ç†æ–‡ä»¶ {filepath} æ—¶å‡ºé”™: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_process_resource_data(directory_path):\n",
    "    \"\"\"åŠ è½½å¹¶å¤„ç†æŒ‡å®šç›®å½•ä¸‹æ‰€æœ‰çš„èµ„æºç›‘æ§æ•°æ®\"\"\"\n",
    "    resource_files = glob.glob(os.path.join(directory_path, 'resource_stats*.csv'))\n",
    "    if not resource_files:\n",
    "        print(f\"  âŒ è­¦å‘Š: åœ¨ {directory_path} ä¸­æœªæ‰¾åˆ°èµ„æºæ–‡ä»¶ã€‚\")\n",
    "        return None\n",
    "    \n",
    "    all_res_dfs = []\n",
    "    for f in resource_files:\n",
    "        try:\n",
    "            node_df = pd.read_csv(f, parse_dates=['timestamp']).set_index('timestamp')\n",
    "            all_res_dfs.append(node_df)\n",
    "        except Exception as e:\n",
    "            print(f\"  âŒ è­¦å‘Š: è¯»å–èµ„æºæ–‡ä»¶ {f} å¤±è´¥: {e}\")\n",
    "    \n",
    "    if not all_res_dfs: return None\n",
    "    \n",
    "    # å°†æ‰€æœ‰èŠ‚ç‚¹çš„æ•°æ®åˆå¹¶ï¼Œå¹¶æŒ‰æ—¶é—´æˆ³å–å¹³å‡å€¼ï¼Œå¾—åˆ°é›†ç¾¤çš„å¹³å‡èµ„æºåˆ©ç”¨ç‡\n",
    "    combined_df = pd.concat(all_res_dfs)\n",
    "    cluster_avg_df = combined_df.groupby(level=0).mean()\n",
    "    print(f\"  âœ… æˆåŠŸåŠ è½½å¹¶åˆå¹¶äº† {len(resource_files)} ä¸ªèŠ‚ç‚¹çš„èµ„æºæ•°æ®ã€‚\")\n",
    "    return cluster_avg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_timeseries_metrics(all_perf_df, all_resource_df, window_size_sec):\n",
    "    \"\"\"\n",
    "    å°†ç¦»æ•£çš„DAGå®Œæˆäº‹ä»¶å’Œè¿ç»­çš„èµ„æºæ•°æ®ï¼Œèšåˆåˆ°ç»Ÿä¸€çš„æ—¶é—´çª—å£ä¸­ã€‚\n",
    "    æ ¸å¿ƒä¿®æ­£: \n",
    "    - å¢åŠ  p95_response_time è®¡ç®—\n",
    "    - å¢åŠ  dag_arrival_rate è®¡ç®—\n",
    "    - ç§»é™¤ active_dags è®¡ç®—\n",
    "    \"\"\"\n",
    "    all_results = {}\n",
    "    for algo, perf_df in all_perf_df.items():\n",
    "        if perf_df is None or perf_df.empty: continue\n",
    "            \n",
    "        algo_start_time = perf_df['dag_arrival_time'].min()\n",
    "        algo_end_time = perf_df['dag_finish_time'].max()\n",
    "        relative_duration = algo_end_time - algo_start_time\n",
    "\n",
    "        # åˆ›å»ºç›¸å¯¹æ—¶é—´åˆ—\n",
    "        perf_df['relative_arrival'] = perf_df['dag_arrival_time'] - algo_start_time\n",
    "        perf_df['relative_finish'] = perf_df['dag_finish_time'] - algo_start_time\n",
    "\n",
    "        # åˆ›å»ºæ—¶é—´åˆ†ç®±\n",
    "        time_bins = np.arange(0, relative_duration + window_size_sec, window_size_sec)\n",
    "        bin_centers = (time_bins[:-1] + time_bins[1:]) / 2\n",
    "\n",
    "        # --- è®¡ç®—æ€§èƒ½æŒ‡æ ‡ ---\n",
    "        # 1. æŒ‰å®Œæˆæ—¶é—´åˆ†ç®±ï¼Œè®¡ç®—JCTå’ŒResponse Time\n",
    "        perf_df['finish_bin'] = pd.cut(perf_df['relative_finish'], bins=time_bins, labels=bin_centers, right=False)\n",
    "        grouped_by_finish = perf_df.groupby('finish_bin', observed=False)\n",
    "        avg_dct = grouped_by_finish['dct'].mean()\n",
    "        p95_response_time = grouped_by_finish['dag_response_time'].quantile(0.95)\n",
    "\n",
    "        # 2. æŒ‰åˆ°è¾¾æ—¶é—´åˆ†ç®±ï¼Œè®¡ç®—åˆ°è¾¾ç‡\n",
    "        perf_df['arrival_bin'] = pd.cut(perf_df['relative_arrival'], bins=time_bins, labels=bin_centers, right=False)\n",
    "        arrivals_per_bin = perf_df.groupby('arrival_bin', observed=False).size()\n",
    "        dag_arrival_rate = arrivals_per_bin / window_size_sec # åˆ°è¾¾æ•°/çª—å£æ—¶é•¿ = åˆ°è¾¾ç‡\n",
    "\n",
    "        # --- åˆå¹¶æ€§èƒ½æŒ‡æ ‡ ---\n",
    "        results_df = pd.DataFrame(index=bin_centers)\n",
    "        results_df.index.name = 'relative_time_sec'\n",
    "        results_df['avg_dct'] = avg_dct\n",
    "        results_df['p95_response_time'] = p95_response_time\n",
    "        results_df['dag_arrival_rate'] = dag_arrival_rate\n",
    "        \n",
    "        # --- åˆå¹¶èµ„æºæŒ‡æ ‡ ---\n",
    "        resource_df = all_resource_df.get(algo)\n",
    "        if resource_df is not None and not resource_df.empty:\n",
    "            resource_df_resampled = resource_df.resample(f'{window_size_sec}s').mean()\n",
    "            algo_resource_start_time = resource_df.index.min()\n",
    "            resource_df_resampled['relative_time_sec'] = (resource_df_resampled.index - algo_resource_start_time).total_seconds()\n",
    "            \n",
    "            results_df.reset_index(inplace=True)\n",
    "            resource_df_resampled.reset_index(inplace=True)\n",
    "            \n",
    "            merged_df = pd.merge_asof(\n",
    "                results_df.sort_values('relative_time_sec'),\n",
    "                resource_df_resampled.sort_values('relative_time_sec'),\n",
    "                on='relative_time_sec',\n",
    "                direction='nearest'\n",
    "            )\n",
    "            results_df = merged_df.set_index('relative_time_sec')\n",
    "\n",
    "        # --- æ•°æ®æ¸…æ´— ---\n",
    "        results_df.interpolate(method='linear', limit_direction='both', inplace=True)\n",
    "        results_df.fillna(0, inplace=True)\n",
    "        \n",
    "        all_results[algo] = results_df\n",
    "        \n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_ax_style(ax, xlim, xlabel, ylabel, y_is_percent=False, y_max_override=None, grid_axis= 'both'):\n",
    "    \"\"\"ç»Ÿä¸€è®¾ç½®å­å›¾æ ·å¼çš„è¾…åŠ©å‡½æ•°\"\"\"\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.grid(True, which= 'both', axis=grid_axis, linestyle='--', linewidth= 1, alpha= 0.9)\n",
    "    ax.tick_params(axis='both', which='major')\n",
    "    ax.set_xlim(0, xlim)\n",
    "    \n",
    "    for spine in ['bottom', 'left', 'top', 'right']:\n",
    "        ax.spines[spine].set_visible(True)\n",
    "        ax.spines[spine].set_color('black') \n",
    "\n",
    "    if y_max_override:\n",
    "        ax.set_ylim(-5, y_max_override)\n",
    "    \n",
    "    if y_is_percent:\n",
    "        # å¦‚æœæœ‰è¦†ç›–å€¼ï¼Œåˆ™ä½¿ç”¨å®ƒï¼Œå¦åˆ™é»˜è®¤105\n",
    "        max_val = y_max_override if y_max_override else 105\n",
    "        ax.set_ylim(-5, max_val)\n",
    "        ax.yaxis.set_major_formatter(mticker.PercentFormatter(xmax=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_performance_timeseries(all_results_data, load_profile):\n",
    "    \"\"\"\n",
    "    ç»˜åˆ¶æ‰€æœ‰ä¸æ€§èƒ½ç›¸å…³çš„æ—¶é—´åºåˆ—å›¾ (Input Load, Arrival Rate, DCT, P95 Response Time)\n",
    "    \"\"\"\n",
    "    print(\"\\n--- æ­£åœ¨ç”Ÿæˆæ€§èƒ½ç›¸å…³çš„ç‹¬ç«‹SVGå­å›¾ ---\")\n",
    "    total_duration = sum(p[0] for p in load_profile)\n",
    "    \n",
    "    # æ ¸å¿ƒä¿®æ­£ #4: æ–°å¢ dag_arrival_rate å›¾\n",
    "    # æ ¸å¿ƒä¿®æ­£ #2: å°† p95_jct æ”¹ä¸º p95_response_time\n",
    "    panel_info = {\n",
    "        'exp1_cluster_load_profile': {'ylabel': 'Input Load (%)', 'is_percent': True},\n",
    "        'b_dag_arrival_rate': {'metric': 'dag_arrival_rate', 'ylabel': 'DAG Arrival Rate (req/s)'},\n",
    "        'c_avg_dct': {'metric': 'avg_dct', 'ylabel': 'Average DCT (s)'},\n",
    "        'exp1_response_time_p95': {'metric': 'p95_response_time', 'ylabel': 'P95 Response Time (s)'},\n",
    "    }\n",
    "\n",
    "    for filename, info in panel_info.items():\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        \n",
    "        if filename == 'exp1_cluster_load_profile':\n",
    "            # æ ¸å¿ƒä¿®æ­£ #1: åŠ¨æ€è®¡ç®—Yè½´æœ€å¤§å€¼ä»¥æ˜¾ç¤ºè¶…è½½\n",
    "            max_load_factor = max(p[1] for p in load_profile) * AVG_DAG_COMPLETE_TIME\n",
    "            y_max = (max_load_factor * 100) * 1.1 # å¢åŠ 10%çš„è¾¹è·\n",
    "            \n",
    "            x_coords, y_coords = [0], [(load_profile[0][1] * AVG_DAG_COMPLETE_TIME) * 100]\n",
    "            current_t = 0\n",
    "            for i, (duration, lambda_rate) in enumerate(load_profile):\n",
    "                load_percent = (lambda_rate * AVG_DAG_COMPLETE_TIME) * 100\n",
    "                x_coords.append(current_t + duration)\n",
    "                y_coords.append(load_percent)\n",
    "                if i + 1 < len(load_profile):\n",
    "                    next_load_percent = (load_profile[i+1][1] * AVG_DAG_COMPLETE_TIME) * 100\n",
    "                    x_coords.append(current_t + duration)\n",
    "                    y_coords.append(next_load_percent)\n",
    "                # åœ¨æ¯ä¸ªé˜¶æ®µçš„ä¸­é—´ä½ç½®æ·»åŠ æ–‡å­—æ ‡ç­¾\n",
    "                text_x = current_t + duration / 2\n",
    "                text_y = load_percent + 4  # å°†æ–‡å­—æ ‡ç­¾ç¨å¾®æ”¾åœ¨çº¿ä¸Šæ–¹\n",
    "                ax.text(text_x, text_y, f'{load_percent}%', ha='center', va='bottom', fontsize= 26, color='#333333')\n",
    "                current_t += duration\n",
    "            ax.plot(x_coords, y_coords, 'go--', color='black', linewidth= 5)\n",
    "            setup_ax_style(ax, total_duration, 'Time (seconds)', info['ylabel'], \n",
    "                           y_is_percent=True, y_max_override=y_max, grid_axis= 'y')\n",
    "            # ax.grid(axis= 'y', linestyle= '--', linewidth= 1, alpha= 0.9)\n",
    "        else:\n",
    "            for algo, df in all_results_data.items():\n",
    "                if not df.empty and info['metric'] in df.columns:\n",
    "                    style = PLOT_STYLES.get(algo, {})\n",
    "                    ax.plot(df.index, df[info['metric']], label=algo.upper(), **style)\n",
    "            setup_ax_style(ax, total_duration, 'Time (seconds)', info['ylabel'])\n",
    "            if filename == 'exp1_response_time_p95':\n",
    "                ax.legend(loc='upper left')\n",
    "            else:\n",
    "                ax.legend(loc='best')\n",
    "        plt.savefig(f'{filename}.pdf', format='pdf', bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "        print(f\"âœ… {filename}.pdf å·²ä¿å­˜ã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_resource_utilization(all_results_data, interval, load_profile):\n",
    "    \"\"\"\n",
    "    ç»˜åˆ¶æŒ‡å®šæ—¶é—´åŒºé—´çš„èµ„æºåˆ©ç”¨ç‡å›¾ï¼Œå¹¶è‡ªé€‚åº”è°ƒæ•´Yè½´ã€‚\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- æ­£åœ¨ç”ŸæˆæŒ‡å®šåŒºé—´ {interval}s çš„èµ„æºåˆ©ç”¨ç‡PDFå­å›¾ ---\")\n",
    "    start_sec, end_sec = interval\n",
    "    \n",
    "    resource_metrics = {\n",
    "        'exp1_cpu_util': {'metric': 'cpu_percent', 'ylabel': 'CPU Utilization (%)', 'is_percent': True},\n",
    "        'f_gpu_util': {'metric': 'gpu_avg_util_percent', 'ylabel': 'GPU Utilization (%)', 'is_percent': True},\n",
    "        'exp1_gpu_mem': {'metric': 'gpu_avg_mem_percent', 'ylabel': 'GPU Memory Util. (%)', 'is_percent': True},\n",
    "        'h_disk_io': {'metric': 'disk_total_MBps', 'ylabel': 'Disk I/O (MB/s)'},\n",
    "        'i_net_io': {'metric': 'net_total_MBps', 'ylabel': 'Network I/O (MB/s)'}\n",
    "    }\n",
    "\n",
    "    for filename, info in resource_metrics.items():\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        \n",
    "        max_y_val = 0\n",
    "        \n",
    "        for algo, df in all_results_data.items():\n",
    "            if not df.empty and info['metric'] in df.columns:\n",
    "                df_interval = df[(df.index >= start_sec) & (df.index <= end_sec)]\n",
    "                if not df_interval.empty:\n",
    "                    style = PLOT_STYLES.get(algo, {})\n",
    "                    ax.plot(df_interval.index, df_interval[info['metric']], label=algo.upper(), **style)\n",
    "                    \n",
    "                    current_max = df_interval[info['metric']].max()\n",
    "                    if current_max > max_y_val:\n",
    "                        max_y_val = current_max\n",
    "        \n",
    "        # --- æ ¸å¿ƒä¿®æ”¹ï¼šè°ƒæ•´ä»£ç æ‰§è¡Œé¡ºåº ---\n",
    "        \n",
    "        # 1. å…ˆè°ƒç”¨é€šç”¨çš„æ ·å¼è®¾ç½®å‡½æ•°\n",
    "        setup_ax_style(ax, end_sec, 'Time (seconds)', info['ylabel'], y_is_percent=info.get('is_percent', False))\n",
    "        \n",
    "        # 2. ç„¶åç”¨æˆ‘ä»¬åŠ¨æ€è®¡ç®—çš„èŒƒå›´å»è¦†ç›–Yè½´\n",
    "        if info.get('is_percent', False):\n",
    "            y_upper_limit = min(100, max_y_val * 1.5)\n",
    "        else:\n",
    "            y_upper_limit = max_y_val * 1.5\n",
    "        \n",
    "        if y_upper_limit == 0:\n",
    "            y_upper_limit = 1.0 \n",
    "\n",
    "        ax.set_ylim(0, y_upper_limit) # <--- è¿™è¡Œä»£ç ç°åœ¨æ˜¯æœ€ååº”ç”¨\n",
    "\n",
    "        ax.set_xlim(start_sec, end_sec)\n",
    "        ax.legend(loc='upper right', ncol=2)\n",
    "        \n",
    "        plt.savefig(f'{filename}.pdf', format='pdf', bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "        print(f\"âœ… {filename}.pdf å·²ä¿å­˜ã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. åŠ è½½æ‰€æœ‰æ•°æ® ---\n",
    "BASE_DATA_PATH = '../data/exp1/'\n",
    "all_perf_data = {}\n",
    "all_resource_data = {}\n",
    "\n",
    "print(\"--- å¼€å§‹åŠ è½½æ‰€æœ‰ç®—æ³•çš„å®éªŒæ•°æ® ---\")\n",
    "for algo_name in ALGORITHMS_TO_PLOT:\n",
    "    print(f\"\\nå¤„ç†ç®—æ³•: {algo_name.upper()}\")\n",
    "    # å‡è®¾æ¯ä¸ªç®—æ³•çš„æ•°æ®éƒ½åœ¨ä¸€ä¸ªåŒåå­æ–‡ä»¶å¤¹ä¸‹\n",
    "    algo_dir = os.path.join(BASE_DATA_PATH, algo_name)\n",
    "    perf_file_path = os.path.join(algo_dir, \"task_exec_time.csv\")\n",
    "    \n",
    "    all_perf_data[algo_name] = load_and_process_performance_data(perf_file_path, algo_name)\n",
    "    all_resource_data[algo_name] = load_and_process_resource_data(algo_dir)\n",
    "\n",
    "# --- 2. è®¡ç®—æ—¶é—´åºåˆ—æŒ‡æ ‡ ---\n",
    "print(\"\\n--- å¼€å§‹è®¡ç®—æ‰€æœ‰ç®—æ³•çš„æ—¶é—´åºåˆ—æŒ‡æ ‡ ---\")\n",
    "all_final_results = calculate_timeseries_metrics(all_perf_data, all_resource_data, WINDOW_SIZE_SEC)\n",
    "\n",
    "# --- 3. ç”Ÿæˆå›¾è¡¨ ---\n",
    "print(\"\\n--- å¼€å§‹ç”Ÿæˆæœ€ç»ˆç‰ˆå›¾è¡¨ ---\")\n",
    "if all_final_results:\n",
    "    # ç»˜åˆ¶æ€§èƒ½å›¾ (æ•´ä¸ªæ—¶é—´åŒºé—´)\n",
    "    plot_performance_timeseries(all_final_results, LOAD_PROFILE)\n",
    "    # ç»˜åˆ¶èµ„æºå›¾ (ä»…æŒ‡å®šçš„é«˜è´Ÿè½½åŒºé—´)\n",
    "    plot_resource_utilization(all_final_results, RESOURCE_PLOT_INTERVAL, LOAD_PROFILE)\n",
    "else:\n",
    "    print(\"âŒ æœªèƒ½è®¡ç®—ä»»ä½•ç»“æœï¼Œæ— æ³•ç”Ÿæˆå›¾è¡¨ã€‚\")\n",
    "\n",
    "print(\"\\nğŸ‰ æ‰€æœ‰ç®—æ³•åˆ†æå®Œæ¯•ï¼\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### compute metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Configuration ---\n",
    "# è¯·å°†æ­¤è·¯å¾„ä¿®æ”¹ä¸ºä½ çš„è¿ç»­åˆ°è¾¾å®éªŒæ•°æ®æ‰€åœ¨çš„ç›®å½•\n",
    "DATA_DIR = '../data/exp1 agent framework/continuous arrival experiment'\n",
    "# å®šä¹‰éœ€è¦åˆ†æçš„ç®—æ³•ï¼ˆæ–‡ä»¶å¤¹åç§°ï¼‰\n",
    "ALGORITHMS_TO_PROCESS = ['Maze', 'AutoGen', 'AgentScope', 'Maze(vLLM)', 'ModelLevel(vLLM)']\n",
    "# å®šä¹‰å®éªŒåˆ†æçš„æ—¶é—´çª—å£ï¼ˆç§’ï¼‰\n",
    "EXPERIMENT_DURATION_SEC = 3000\n",
    "RESOURCE_TIMESTAMP_TIMEZONE = 'Asia/Shanghai'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_performance_data(directory_path, unified_start_time, duration_sec):\n",
    "    \"\"\"\n",
    "    åŠ è½½ã€æˆªæ–­å¹¶å¤„ç†æ€§èƒ½æ•°æ® (task_exec_time.csv)ï¼Œä½¿ç”¨ç»Ÿä¸€çš„å¼€å§‹æ—¶é—´ã€‚\n",
    "    \"\"\"\n",
    "    filepath = os.path.join(directory_path, 'task_exec_time.csv')\n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"  âŒ è­¦å‘Š: æ€§èƒ½æ–‡ä»¶æœªæ‰¾åˆ°: {filepath}\")\n",
    "        return None, None\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(filepath)\n",
    "        if 'uuid' in df.columns:\n",
    "            df.rename(columns={'uuid': 'run_id'}, inplace=True)\n",
    "\n",
    "        required_cols = ['run_id', 'arrival_time', 'finish_exec_time']\n",
    "        if not all(col in df.columns for col in required_cols):\n",
    "            print(f\"  âŒ é”™è¯¯: æ–‡ä»¶ {filepath} ç¼ºå°‘å¿…éœ€çš„åˆ—ã€‚\")\n",
    "            return None, None\n",
    "            \n",
    "        # --- æ—¶é—´æˆªæ–­ (ä½¿ç”¨ç»Ÿä¸€å¼€å§‹æ—¶é—´) ---\n",
    "        abs_end_time_cutoff = unified_start_time + duration_sec\n",
    "        \n",
    "        dag_arrivals = df.groupby('run_id')['arrival_time'].min().reset_index()\n",
    "        dags_in_window = dag_arrivals[dag_arrivals['arrival_time'] < abs_end_time_cutoff]\n",
    "        valid_run_ids = dags_in_window['run_id']\n",
    "        \n",
    "        df_filtered = df[df['run_id'].isin(valid_run_ids)].copy()\n",
    "        \n",
    "        if df_filtered.empty:\n",
    "            print(\"  âœ… æ²¡æœ‰åœ¨æŒ‡å®šæ—¶é—´çª—å£å†…å¼€å§‹çš„DAGã€‚\")\n",
    "            return 0, 0\n",
    "            \n",
    "        # --- æŒ‡æ ‡è®¡ç®— ---\n",
    "        dag_runs = df_filtered.groupby('run_id').agg(\n",
    "            dag_arrival_time=('arrival_time', 'min'),\n",
    "            dag_finish_time=('finish_exec_time', 'max')\n",
    "        ).reset_index()\n",
    "\n",
    "        for col in ['dag_arrival_time', 'dag_finish_time']:\n",
    "            dag_runs[col] = pd.to_numeric(dag_runs[col], errors='coerce')\n",
    "        dag_runs.dropna(inplace=True)\n",
    "\n",
    "        dag_runs['dct'] = dag_runs['dag_finish_time'] - dag_runs['dag_arrival_time']\n",
    "        dag_runs = dag_runs[dag_runs['dct'] >= 0]\n",
    "        \n",
    "        avg_dct = dag_runs['dct'].mean()\n",
    "        completed_dags = len(dag_runs)\n",
    "        \n",
    "        print(f\"  âœ… æˆåŠŸå¤„ç†äº† {completed_dags} ä¸ªDAGçš„æ€§èƒ½æ•°æ®ã€‚\")\n",
    "        return avg_dct, completed_dags\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  âŒ é”™è¯¯: å¤„ç†æ–‡ä»¶ {filepath} æ—¶å‡ºé”™: {e}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_resource_data(directory_path, unified_start_time, duration_sec):\n",
    "    \"\"\"\n",
    "    åŠ è½½ã€æˆªæ–­å¹¶å¤„ç†æ‰€æœ‰èŠ‚ç‚¹çš„èµ„æºæ•°æ®ï¼Œé€šè¿‡æ­£ç¡®çš„æ—¶åŒºè½¬æ¢æ¥ç»Ÿä¸€æ—¶é—´æ ‡å‡†ã€‚\n",
    "    \"\"\"\n",
    "    resource_files = glob.glob(os.path.join(directory_path, 'resource_stats*.csv'))\n",
    "    if not resource_files:\n",
    "        print(f\"  âŒ è­¦å‘Š: åœ¨ {directory_path} ä¸­æœªæ‰¾åˆ°èµ„æºæ–‡ä»¶ã€‚\")\n",
    "        return {}\n",
    "\n",
    "    all_res_dfs = []\n",
    "    for f in resource_files:\n",
    "        try:\n",
    "            node_df = pd.read_csv(f, parse_dates=['timestamp'])\n",
    "            all_res_dfs.append(node_df)\n",
    "        except Exception as e:\n",
    "            print(f\"  âŒ è­¦å‘Š: è¯»å–èµ„æºæ–‡ä»¶ {f} å¤±è´¥: {e}\")\n",
    "    \n",
    "    if not all_res_dfs: return {}\n",
    "    \n",
    "    combined_df = pd.concat(all_res_dfs, ignore_index=True).set_index('timestamp').sort_index()\n",
    "    \n",
    "    # --- æ ¸å¿ƒä¿®æ­£: æ­£ç¡®å¤„ç†æ—¶åŒº ---\n",
    "    try:\n",
    "        # 1. å°†èµ„æºæ–‡ä»¶ä¸­çš„â€œæ— æ—¶åŒºâ€æ—¶é—´æˆ³ï¼Œæ­£ç¡®åœ°æ ‡è®°ä¸ºå®ƒæ‰€åœ¨çš„æœ¬åœ°æ—¶åŒº\n",
    "        if combined_df.index.tz is None:\n",
    "            combined_df = combined_df.tz_localize(RESOURCE_TIMESTAMP_TIMEZONE)\n",
    "        \n",
    "        # 2. ç„¶åï¼Œå°†è¿™ä¸ªâ€œæœ¬åœ°æ—¶åŒºâ€æ—¶é—´ç»Ÿä¸€è½¬æ¢ä¸º UTC æ ‡å‡†æ—¶é—´\n",
    "        combined_df = combined_df.tz_convert('UTC')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  âŒ é”™è¯¯: æ—¶åŒºè½¬æ¢å¤±è´¥: {e}. è¯·æ£€æŸ¥ `RESOURCE_TIMESTAMP_TIMEZONE` è®¾ç½®æ˜¯å¦æ­£ç¡®ã€‚\")\n",
    "        return {}\n",
    "\n",
    "    # 3. å°†ç»Ÿä¸€çš„å¼€å§‹æ—¶é—´ï¼ˆunix timestampï¼‰ä¹Ÿè½¬æ¢ä¸ºå¸¦UTCæ—¶åŒºçš„æ—¶é—´æˆ³\n",
    "    start_ts = pd.to_datetime(unified_start_time, unit='s', utc=True)\n",
    "    end_ts_cutoff = start_ts + pd.to_timedelta(duration_sec, unit='s')\n",
    "    \n",
    "    print(f\"  -> æ£€æŸ¥èµ„æºæ—¶é—´çª—å£ (UTC): {start_ts.strftime('%Y-%m-%d %H:%M:%S')} to {end_ts_cutoff.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    \n",
    "    # 4. åœ¨ç»Ÿä¸€çš„UTCæ ‡å‡†ä¸‹è¿›è¡Œç­›é€‰\n",
    "    df_filtered = combined_df[(combined_df.index >= start_ts) & (combined_df.index < end_ts_cutoff)]\n",
    "\n",
    "    if df_filtered.empty:\n",
    "        print(\"  âš ï¸ è­¦å‘Š: åœ¨æŒ‡å®šçš„UTCæ—¶é—´çª—å£å†…æœªæ‰¾åˆ°ä»»ä½•èµ„æºæ•°æ®ã€‚è¯·å†æ¬¡æ£€æŸ¥æ—¶é—´æˆ³æ˜¯å¦åŒ¹é…ã€‚\")\n",
    "        return {}\n",
    "\n",
    "    # --- æŒ‡æ ‡è®¡ç®— ---\n",
    "    avg_resources = {\n",
    "        'Avg CPU Util (%)': df_filtered['cpu_percent'].mean(),\n",
    "        'Avg GPU Mem Util (%)': df_filtered['gpu_avg_mem_percent'].mean(),\n",
    "        'Avg Disk I/O (MB/s)': df_filtered['disk_total_MBps'].mean()\n",
    "    }\n",
    "    \n",
    "    print(f\"  âœ… æˆåŠŸå¤„ç†äº† {len(resource_files)} ä¸ªèŠ‚ç‚¹çš„èµ„æºæ•°æ®ã€‚\")\n",
    "    return avg_resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_data = []\n",
    "\n",
    "print(f\"å¼€å§‹å¤„ç†å®éªŒæ•°æ®ï¼Œæ€»æ—¶é•¿: {EXPERIMENT_DURATION_SEC} ç§’\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for algo in ALGORITHMS_TO_PROCESS:\n",
    "    print(f\"æ­£åœ¨å¤„ç†ç®—æ³•: {algo}\")\n",
    "    algo_path = os.path.join(DATA_DIR, algo)\n",
    "    \n",
    "    if not os.path.isdir(algo_path):\n",
    "        print(f\"  âŒ é”™è¯¯: æ‰¾ä¸åˆ°ç®—æ³•ç›®å½• {algo_path}ï¼Œè·³è¿‡ã€‚\")\n",
    "        continue\n",
    "        \n",
    "\n",
    "    # --- ç¡®å®šç»Ÿä¸€çš„å¼€å§‹æ—¶é—´ ---\n",
    "    perf_filepath = os.path.join(algo_path, 'task_exec_time.csv')\n",
    "    if not os.path.exists(perf_filepath):\n",
    "        print(f\"  âŒ é”™è¯¯: æ€§èƒ½æ–‡ä»¶ {perf_filepath} ä¸å­˜åœ¨ï¼Œæ— æ³•ç¡®å®šå¼€å§‹æ—¶é—´ï¼Œè·³è¿‡ã€‚\")\n",
    "        print(\"-\" * 50)\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        temp_perf_df = pd.read_csv(perf_filepath)\n",
    "        if 'uuid' in temp_perf_df.columns:\n",
    "            temp_perf_df.rename(columns={'uuid': 'run_id'}, inplace=True)\n",
    "        unified_start_time = temp_perf_df['arrival_time'].min()\n",
    "        print(f\"  -> ç¡®å®šç»Ÿä¸€å¼€å§‹æ—¶é—´: {pd.to_datetime(unified_start_time, unit='s', utc=True).strftime('%Y-%m-%d %H:%M:%S')} UTC\")\n",
    "    except Exception as e:\n",
    "        print(f\"  âŒ é”™è¯¯: è¯»å–æ€§èƒ½æ–‡ä»¶ä»¥ç¡®å®šå¼€å§‹æ—¶é—´æ—¶å¤±è´¥: {e}\")\n",
    "        print(\"-\" * 50)\n",
    "        continue\n",
    "\n",
    "    # --- ä½¿ç”¨ç»Ÿä¸€å¼€å§‹æ—¶é—´è®¡ç®—æŒ‡æ ‡ ---\n",
    "    avg_dct, completed_dags = process_performance_data(algo_path, unified_start_time, EXPERIMENT_DURATION_SEC)\n",
    "    avg_resources = process_resource_data(algo_path, unified_start_time, EXPERIMENT_DURATION_SEC)\n",
    "    \n",
    "    if avg_dct is not None and completed_dags is not None:\n",
    "        result_row = {\n",
    "            'Algorithm': algo,\n",
    "            'Avg DCT (s)': avg_dct,\n",
    "            'Completed DAGs': completed_dags,\n",
    "            **avg_resources\n",
    "        }\n",
    "        summary_data.append(result_row)\n",
    "    \n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# --- 4. Display Results ---\n",
    "if summary_data:\n",
    "    summary_df = pd.DataFrame(summary_data).set_index('Algorithm')\n",
    "    \n",
    "    # Fill NaN values with 0 before formatting, in case resource data was missing for some runs\n",
    "    summary_df.fillna(0, inplace=True)\n",
    "\n",
    "    formatted_df = summary_df.copy()\n",
    "    for col in formatted_df.columns:\n",
    "        if col == 'Completed DAGs':\n",
    "            formatted_df[col] = formatted_df[col].map('{:.0f}'.format)\n",
    "        else:\n",
    "            formatted_df[col] = formatted_df[col].map('{:.2f}'.format)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"å®éªŒç»“æœæ±‡æ€»è¡¨ (åŸºäºç»Ÿä¸€å¼€å§‹æ—¶é—´çš„ {EXPERIMENT_DURATION_SEC} ç§’çª—å£)\")\n",
    "    print(\"=\"*60)\n",
    "    print(formatted_df.to_string())\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    print(\"\\nMarkdown æ ¼å¼çš„è¡¨æ ¼:\\n\")\n",
    "    print(formatted_df.to_markdown())\n",
    "\n",
    "else:\n",
    "    print(\"æœªèƒ½ç”Ÿæˆä»»ä½•ç»“æœï¼Œè¯·æ£€æŸ¥æ•°æ®è·¯å¾„å’Œæ–‡ä»¶ã€‚\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### heterogeneity rate experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### heterogeneity rate analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import json\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_path= \"/root/workspace/d23oa7cp420c73acue30/AgentOS/data\"\n",
    "dataset_heterogenity_dict= {\n",
    "    \"gaia\": {\n",
    "        \"file\": {\"cpu\": 1, \"gpu\": 3, \"io\": 0},\n",
    "        \"reason\": {\"cpu\": 0, \"gpu\": 3, \"io\": 1},\n",
    "        \"speech\": {\"cpu\": 1, \"gpu\": 4, \"io\": 0},\n",
    "        \"vision\": {\"cpu\": 1, \"gpu\": 1, \"io\": 1},\n",
    "    },\n",
    "    \"openagi\": {\n",
    "        \"document_qa\": {\"cpu\": 4, \"gpu\": 4, \"io\": 4},\n",
    "        \"image_captioning_complex\": {\"cpu\": 3, \"gpu\": 6, \"io\": 2},\n",
    "        \"multimodal_vqa_complex\": {\"cpu\": 2, \"gpu\": 4, \"io\": 3},\n",
    "        \"text_processing_multilingual\": {\"cpu\": 2, \"gpu\": 6, \"io\": 4},\n",
    "    },\n",
    "    \"tbench\": {\n",
    "        \"airline_book\": {\"cpu\": 5, \"gpu\": 2, \"io\": 0},\n",
    "        \"airline_cancel\": {\"cpu\": 3, \"gpu\": 2, \"io\": 2},\n",
    "        \"retail_cancel\": {\"cpu\": 1, \"gpu\": 2, \"io\": 2},\n",
    "        \"retail_cancel_modify\": {\"cpu\": 3, \"gpu\": 1, \"io\": 2},\n",
    "        \"retail_modify\": {\"cpu\": 3, \"gpu\": 1, \"io\": 2},\n",
    "        \"retail_return\": {\"cpu\": 3, \"gpu\": 1, \"io\": 2}\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_shannon_entropy(task_counts: dict) -> float:\n",
    "    \"\"\"æ ¹æ®ç»™å®šçš„ä»»åŠ¡æ€»æ•°å­—å…¸ï¼Œè®¡ç®—é¦™å†œç†µã€‚\"\"\"\n",
    "    counts = [count for count in task_counts.values() if count > 0]\n",
    "    total_tasks = sum(counts)\n",
    "    if total_tasks == 0 or len(counts) <= 1:\n",
    "        return 0.0\n",
    "    entropy = 0.0\n",
    "    for count in counts:\n",
    "        probability = count / total_tasks\n",
    "        entropy -= probability * math.log2(probability)\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query_counts(jsonl_path: str, type_key: str = \"dag_type\") -> Counter:\n",
    "    \"\"\"è¯»å– JSONL æ–‡ä»¶å¹¶ç»Ÿè®¡æ¯ç§ç±»å‹çš„æŸ¥è¯¢æ•°é‡ã€‚\"\"\"\n",
    "    counts = Counter()\n",
    "    try:\n",
    "        with open(jsonl_path, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                try:\n",
    "                    data = json.loads(line)\n",
    "                    if type_key in data:\n",
    "                        counts[data[type_key]] += 1\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"Warning: Skipping invalid JSON line in {jsonl_path}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Query file not found at {jsonl_path}. Please check the path.\")\n",
    "        return None\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_dataset_workload(dataset_name: str, base_path: str, atomic_compositions: dict):\n",
    "    \"\"\"\n",
    "    å¯¹æ•°æ®é›†è¿›è¡Œå…¨é¢çš„å·¥ä½œè´Ÿè½½åˆ†æï¼Œè®¡ç®—ï¼š\n",
    "    1. å¹³å‡æŸ¥è¯¢çš„èµ„æºæ„æˆç™¾åˆ†æ¯” (CPU %, GPU %, IO %)\n",
    "    2. æ•´ä½“æ•°æ®é›†çš„å¼‚è´¨æ€§å¾—åˆ† (Entropy)\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Analyzing Dataset: {dataset_name.upper()} ---\")\n",
    "    \n",
    "    query_file_name = f\"{dataset_name}_query.jsonl\"\n",
    "    query_file_path = os.path.join(base_path, dataset_name, query_file_name)\n",
    "    json_type_key = \"dag_type\"\n",
    "\n",
    "    # æ­¥éª¤ 1: è·å–æ¯ç§ query çš„å®é™…æ•°é‡\n",
    "    query_counts = get_query_counts(query_file_path, json_type_key)\n",
    "    if not query_counts:\n",
    "        print(f\"Could not analyze {dataset_name} due to missing data.\")\n",
    "        return None\n",
    "    total_queries = sum(query_counts.values())\n",
    "    print(f\"  - Found {total_queries} total queries. Counts: {dict(query_counts)}\")\n",
    "\n",
    "    # æ­¥éª¤ 2: è®¡ç®—æ•´ä¸ªæ•°æ®é›†ä¸­ cpu, gpu, io çš„ä»»åŠ¡æ€»æ•°\n",
    "    total_dataset_tasks = Counter()\n",
    "    dataset_atomic_compositions = atomic_compositions.get(dataset_name, {})\n",
    "    for query_type, count in query_counts.items():\n",
    "        if query_type in dataset_atomic_compositions:\n",
    "            atomic_comp = dataset_atomic_compositions[query_type]\n",
    "            total_dataset_tasks['cpu'] += count * atomic_comp.get('cpu', 0)\n",
    "            total_dataset_tasks['gpu'] += count * atomic_comp.get('gpu', 0)\n",
    "            total_dataset_tasks['io'] += count * atomic_comp.get('io', 0)\n",
    "    print(f\"  - Total task composition across all queries: {dict(total_dataset_tasks)}\")\n",
    "\n",
    "    # æ­¥éª¤ 3: è®¡ç®—å¹³å‡æ¯ä¸ªæŸ¥è¯¢çš„èµ„æºæ„æˆç™¾åˆ†æ¯”\n",
    "    total_tasks_sum = sum(total_dataset_tasks.values())\n",
    "    composition_percentages = {}\n",
    "    if total_tasks_sum > 0:\n",
    "        composition_percentages['cpu'] = (total_dataset_tasks['cpu'] / total_tasks_sum) * 100\n",
    "        composition_percentages['gpu'] = (total_dataset_tasks['gpu'] / total_tasks_sum) * 100\n",
    "        composition_percentages['io'] = (total_dataset_tasks['io'] / total_tasks_sum) * 100\n",
    "        print(f\"  - Average Per-Query Composition: \"\n",
    "              f\"CPU {composition_percentages['cpu']:.2f}%, \"\n",
    "              f\"GPU {composition_percentages['gpu']:.2f}%, \"\n",
    "              f\"IO {composition_percentages['io']:.2f}%\")\n",
    "    else:\n",
    "        print(\"  - Average Per-Query Composition: No tasks found.\")\n",
    "\n",
    "    # æ­¥éª¤ 4: è®¡ç®—æ•´ä½“å¼‚è´¨æ€§å¾—åˆ† (Entropy)\n",
    "    heterogeneity_score = calculate_shannon_entropy(total_dataset_tasks)\n",
    "    print(f\"  - Overall Heterogeneity Score (Entropy): {heterogeneity_score:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        \"composition\": composition_percentages,\n",
    "        \"heterogeneity\": heterogeneity_score\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_path = \"/root/workspace/d23oa7cp420c73acue30/AgentOS/data\"\n",
    "final_scores = {}\n",
    "datasets_to_process = [\"gaia\", \"openagi\", \"tbench\"]\n",
    "\n",
    "final_results = {}\n",
    "for dataset in datasets_to_process:\n",
    "    result = analyze_dataset_workload(\n",
    "        dataset_name=dataset,\n",
    "        base_path=proj_path,\n",
    "        atomic_compositions= dataset_heterogenity_dict\n",
    "    )\n",
    "    if result:\n",
    "        final_results[dataset] = result\n",
    "\n",
    "# --- æ‰“å°æœ€ç»ˆæ‘˜è¦ ---\n",
    "print(\"\\n\\n\" + \"=\"*70)\n",
    "print(\"Final Summary of Workload Characteristics\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'DATASET':<12} | {'CPU %':<10} | {'GPU %':<10} | {'IO %':<10} | {'HETEROGENEITY':<15}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "if final_results:\n",
    "    for name, res in final_results.items():\n",
    "        comp = res['composition']\n",
    "        cpu_p = f\"{comp.get('cpu', 0):.2f}\"\n",
    "        gpu_p = f\"{comp.get('gpu', 0):.2f}\"\n",
    "        io_p = f\"{comp.get('io', 0):.2f}\"\n",
    "        hetero = f\"{res['heterogeneity']:.4f}\"\n",
    "        print(f\"{name.upper():<12} {cpu_p:<10} {gpu_p:<10} {io_p:<10} {hetero:<15}\")\n",
    "else:\n",
    "    print(\"No results to display. Please check file paths and data.\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_batch(prototypes: dict, target_heterogeneity: float, batch_size: int = 40):\n",
    "    \"\"\"\n",
    "    ä½¿ç”¨è´ªå¿ƒç®—æ³•æ„é€ ä¸€ä¸ªæ¥è¿‘ç›®æ ‡å¼‚æ„æ€§çš„Queryæ‰¹æ¬¡ã€‚\n",
    "    \"\"\"\n",
    "    batch = []\n",
    "    current_composition = Counter()\n",
    "    \n",
    "    # éšæœºé€‰æ‹©ä¸€ä¸ªèµ·ç‚¹ï¼Œå¢åŠ å¤šæ ·æ€§\n",
    "    start_query = random.choice(list(prototypes.keys()))\n",
    "    batch.append(start_query)\n",
    "    current_composition.update(prototypes[start_query][\"composition\"])\n",
    "\n",
    "    while len(batch) < batch_size:\n",
    "        best_next_query = None\n",
    "        smallest_diff = float('inf')\n",
    "\n",
    "        # éå†æ‰€æœ‰åŸå‹ï¼Œæ‰¾åˆ°èƒ½è®©å½“å‰æ‰¹æ¬¡æœ€æ¥è¿‘ç›®æ ‡å¼‚æ„æ€§çš„é‚£ä¸€ä¸ª\n",
    "        for query_name, profile in prototypes.items():\n",
    "            # è¯•æ¢æ€§åœ°åŠ å…¥æ–°query\n",
    "            temp_composition = current_composition + Counter(profile[\"composition\"])\n",
    "            \n",
    "            # è®¡ç®—æ–°æ‰¹æ¬¡çš„å¼‚æ„æ€§\n",
    "            new_heterogeneity = calculate_shannon_entropy(temp_composition)\n",
    "            \n",
    "            # è®¡ç®—ä¸ç›®æ ‡çš„å·®è·\n",
    "            diff = abs(new_heterogeneity - target_heterogeneity)\n",
    "\n",
    "            if diff < smallest_diff:\n",
    "                smallest_diff = diff\n",
    "                best_next_query = query_name\n",
    "\n",
    "        # å°†æœ€ä½³é€‰æ‹©åŠ å…¥æ‰¹æ¬¡\n",
    "        batch.append(best_next_query)\n",
    "        current_composition.update(prototypes[best_next_query][\"composition\"])\n",
    "\n",
    "    final_heterogeneity = calculate_shannon_entropy(current_composition)\n",
    "    return batch, final_heterogeneity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_query_prototypes(compositions: dict) -> dict:\n",
    "    \"\"\"è®¡ç®—æ¯ä¸ªç‹¬ç«‹QueryåŸå‹çš„èµ„æºæ„æˆå’Œå¼‚æ„æ€§å¾—åˆ†ã€‚\"\"\"\n",
    "    prototype_profiles = {}\n",
    "    for dataset, queries in compositions.items():\n",
    "        for query_name, tasks in queries.items():\n",
    "            full_name = f\"{dataset}_{query_name}\"\n",
    "            heterogeneity = calculate_shannon_entropy(tasks)\n",
    "            prototype_profiles[full_name] = {\n",
    "                \"composition\": tasks,\n",
    "                \"heterogeneity\": heterogeneity\n",
    "            }\n",
    "    return prototype_profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_scores = [0.8, 1.2, 1.6] # æ ¹æ®å®é™…èŒƒå›´å¾®è°ƒç›®æ ‡\n",
    "final_batches = {}\n",
    "query_prototypes = analyze_query_prototypes(dataset_heterogenity_dict)\n",
    "print(\"\\nConstructing Target Batches with Diverse Method (Batch Size = 100):\")\n",
    "print(\"=\"*60)\n",
    "for target in target_scores:\n",
    "    best_batch_for_target = None\n",
    "    best_heterogeneity_achieved = -1\n",
    "    closest_diff = float('inf')\n",
    "\n",
    "    # å¤šæ¬¡å°è¯•ä»¥è·å¾—æœ€ä½³ç»“æœï¼Œå› ä¸ºç®—æ³•æœ‰éšæœºæ€§\n",
    "    for _ in range(20): # å¢åŠ å°è¯•æ¬¡æ•°\n",
    "        generated_batch, achieved_heterogeneity = construct_batch(query_prototypes, target, batch_size= 100)\n",
    "        diff = abs(achieved_heterogeneity - target)\n",
    "        if diff < closest_diff:\n",
    "            closest_diff = diff\n",
    "            best_batch_for_target = generated_batch\n",
    "            best_heterogeneity_achieved = achieved_heterogeneity\n",
    "\n",
    "    final_batches[target] = {\n",
    "        \"batch\": Counter(best_batch_for_target),\n",
    "        \"achieved_heterogeneity\": best_heterogeneity_achieved\n",
    "    }\n",
    "    print(f\"Target: {target:.2f} -> Achieved: {best_heterogeneity_achieved:.4f} (Composition: {len(final_batches[target]['batch'])} unique queries)\")\n",
    "    # æ‰“å°å‡ºæ‰¹æ¬¡ä¸­ä¸åŒqueryçš„æ•°é‡ï¼Œç›´è§‚æ„Ÿå—ä¸°å¯Œæ€§\n",
    "    print(f\"  {final_batches[target]['batch']}\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### heterogeneity rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob  # ä½¿ç”¨ glob æ›¿ä»£ os.listdir\n",
    "from collections import defaultdict\n",
    "import pytz # ç”¨äºå¤„ç†æ—¶åŒº"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. ç»“æœæ–‡ä»¶çš„æ ¹ç›®å½•\n",
    "BASE_RESULTS_DIR = os.path.join(\"..\", \"data\", \"exp1 agent framework\", \"heterogeneity rate experiment\")\n",
    "\n",
    "# 2. å®šä¹‰åˆ†æçš„æ¡†æ¶å’Œå¼‚è´¨ç‡\n",
    "FRAMEWORKS = {\n",
    "    'Maze': 'Maze',\n",
    "    'AutoGen': 'AutoGen',\n",
    "    'AgentScope': 'AgentScope',\n",
    "    'Maze(vLLM)': 'Maze(vLLM)',\n",
    "    'vLLM': 'vLLM'\n",
    "}\n",
    "HETEROGENEITY_RATES = [0.8, 1.2, 1.6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. å®šä¹‰å®éªŒåˆ†æçª—å£å’Œæ—¶åŒº (æ ¹æ®æ‚¨çš„ä»£ç æç¤ºæ–°å¢)\n",
    "#    å‡è®¾æˆ‘ä»¬çš„æœ‰æ•ˆå®éªŒæ—¶é•¿ä¸º1800ç§’ (30åˆ†é’Ÿ)\n",
    "EXPERIMENT_DURATION_SEC = 1800 \n",
    "#    å‡è®¾èµ„æºç›‘æ§CSVä¸­çš„æ—¶é—´æˆ³æ˜¯è‹é»ä¸–/æ¬§æ´²ä¸­éƒ¨æ—¶é—´ã€‚\n",
    "#    è¿™æ˜¯ä¸ªå…³é”®å‡è®¾ï¼Œå¦‚æœæ—¶é—´æˆ³æ˜¯UTCæˆ–å…¶ä»–æ—¶åŒºï¼Œè¯·ä¿®æ”¹è¿™é‡Œã€‚\n",
    "RESOURCE_TIMESTAMP_TIMEZONE = 'Asia/Shanghai'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_performance_data(directory_path, unified_start_time, duration_sec):\n",
    "    \"\"\"\n",
    "    åŠ è½½ã€æˆªæ–­å¹¶å¤„ç†æ€§èƒ½æ•°æ® (task_exec_time.csv)ï¼Œä½¿ç”¨ç»Ÿä¸€çš„å¼€å§‹æ—¶é—´ã€‚\n",
    "    \"\"\"\n",
    "    filepath = os.path.join(directory_path, 'task_exec_time.csv')\n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"   âŒ è­¦å‘Š: æ€§èƒ½æ–‡ä»¶æœªæ‰¾åˆ°: {filepath}\")\n",
    "        return None, None\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(filepath)\n",
    "        if 'uuid' in df.columns:\n",
    "            df.rename(columns={'uuid': 'run_id'}, inplace=True)\n",
    "\n",
    "        required_cols = ['run_id', 'arrival_time', 'finish_exec_time']\n",
    "        if not all(col in df.columns for col in required_cols):\n",
    "            print(f\"   âŒ é”™è¯¯: æ–‡ä»¶ {filepath} ç¼ºå°‘å¿…éœ€çš„åˆ—ã€‚\")\n",
    "            return None, None\n",
    "            \n",
    "        # --- æ—¶é—´æˆªæ–­ (ä½¿ç”¨ç»Ÿä¸€å¼€å§‹æ—¶é—´) ---\n",
    "        abs_end_time_cutoff = unified_start_time + duration_sec\n",
    "        \n",
    "        dag_arrivals = df.groupby('run_id')['arrival_time'].min().reset_index()\n",
    "        dags_in_window = dag_arrivals[dag_arrivals['arrival_time'] < abs_end_time_cutoff]\n",
    "        valid_run_ids = dags_in_window['run_id']\n",
    "        \n",
    "        df_filtered = df[df['run_id'].isin(valid_run_ids)].copy()\n",
    "        \n",
    "        if df_filtered.empty:\n",
    "            print(\"   âœ… æ²¡æœ‰åœ¨æŒ‡å®šæ—¶é—´çª—å£å†…å¼€å§‹çš„DAGã€‚\")\n",
    "            return 0, 0, [] # è¿”å›ç©ºåˆ—è¡¨\n",
    "            \n",
    "        # --- æŒ‡æ ‡è®¡ç®— ---\n",
    "        dag_runs = df_filtered.groupby('run_id').agg(\n",
    "            dag_arrival_time=('arrival_time', 'min'),\n",
    "            dag_finish_time=('finish_exec_time', 'max')\n",
    "        ).reset_index()\n",
    "\n",
    "        for col in ['dag_arrival_time', 'dag_finish_time']:\n",
    "            dag_runs[col] = pd.to_numeric(dag_runs[col], errors='coerce')\n",
    "        dag_runs.dropna(inplace=True)\n",
    "\n",
    "        dag_runs['dct'] = dag_runs['dag_finish_time'] - dag_runs['dag_arrival_time']\n",
    "        dag_runs = dag_runs[dag_runs['dct'] >= 0]\n",
    "        \n",
    "        avg_dct = dag_runs['dct'].mean() if not dag_runs.empty else 0\n",
    "        p95_dct = dag_runs['dct'].quantile(0.95) if not dag_runs.empty else 0\n",
    "        completed_dags = len(dag_runs)\n",
    "        \n",
    "        print(f\"   âœ… æˆåŠŸå¤„ç†äº† {completed_dags} ä¸ªDAGçš„æ€§èƒ½æ•°æ®ã€‚\")\n",
    "        return avg_dct, p95_dct, completed_dags\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ é”™è¯¯: å¤„ç†æ–‡ä»¶ {filepath} æ—¶å‡ºé”™: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "def process_resource_data(directory_path, unified_start_time, duration_sec):\n",
    "    \"\"\"\n",
    "    åŠ è½½ã€æˆªæ–­å¹¶å¤„ç†æ‰€æœ‰èŠ‚ç‚¹çš„èµ„æºæ•°æ®ï¼Œé€šè¿‡æ­£ç¡®çš„æ—¶åŒºè½¬æ¢æ¥ç»Ÿä¸€æ—¶é—´æ ‡å‡†ã€‚\n",
    "    \"\"\"\n",
    "    resource_files = glob.glob(os.path.join(directory_path, 'resource_stats*.csv'))\n",
    "    if not resource_files:\n",
    "        # print(f\"   âŒ è­¦å‘Š: åœ¨ {directory_path} ä¸­æœªæ‰¾åˆ°èµ„æºæ–‡ä»¶ã€‚\")\n",
    "        return {}\n",
    "\n",
    "    all_res_dfs = []\n",
    "    for f in resource_files:\n",
    "        try:\n",
    "            node_df = pd.read_csv(f, parse_dates=['timestamp'])\n",
    "            all_res_dfs.append(node_df)\n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ è­¦å‘Š: è¯»å–èµ„æºæ–‡ä»¶ {f} å¤±è´¥: {e}\")\n",
    "    \n",
    "    if not all_res_dfs: return {}\n",
    "    \n",
    "    combined_df = pd.concat(all_res_dfs, ignore_index=True).set_index('timestamp').sort_index()\n",
    "    \n",
    "    try:\n",
    "        if combined_df.index.tz is None:\n",
    "            combined_df = combined_df.tz_localize(RESOURCE_TIMESTAMP_TIMEZONE)\n",
    "        combined_df = combined_df.tz_convert('UTC')\n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ é”™è¯¯: æ—¶åŒºè½¬æ¢å¤±è´¥: {e}. è¯·æ£€æŸ¥ `RESOURCE_TIMESTAMP_TIMEZONE` è®¾ç½®æ˜¯å¦æ­£ç¡®ã€‚\")\n",
    "        return {}\n",
    "\n",
    "    start_ts = pd.to_datetime(unified_start_time, unit='s', utc=True)\n",
    "    end_ts_cutoff = start_ts + pd.to_timedelta(duration_sec, unit='s')\n",
    "    \n",
    "    df_filtered = combined_df[(combined_df.index >= start_ts) & (combined_df.index < end_ts_cutoff)]\n",
    "\n",
    "    if df_filtered.empty:\n",
    "        return {}\n",
    "\n",
    "    # --- æŒ‡æ ‡è®¡ç®— (ä½¿ç”¨æ‚¨ä»£ç ä¸­æä¾›çš„åˆ—å) ---\n",
    "    avg_resources = {\n",
    "        'avg_cpu_util': df_filtered['cpu_percent'].mean(),\n",
    "        'avg_gpu_mem_util': df_filtered['gpu_avg_mem_percent'].mean(),\n",
    "        'avg_disk_io_mbps': df_filtered['disk_total_MBps'].mean()\n",
    "    }\n",
    "    \n",
    "    return avg_resources\n",
    "    \n",
    "print(\"âœ… æ ¸å¿ƒæ•°æ®å¤„ç†å‡½æ•°å·²å®šä¹‰ã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_full_analysis(base_dir, frameworks, rates, duration_sec):\n",
    "    \"\"\"\n",
    "    éå†æ‰€æœ‰å®éªŒï¼Œæ‰¾åˆ°ç»Ÿä¸€çš„å¼€å§‹æ—¶é—´ï¼Œå¹¶è°ƒç”¨å¤„ç†å‡½æ•°ã€‚\n",
    "    \"\"\"\n",
    "    full_results = []\n",
    "    \n",
    "    for framework_code, framework_name in frameworks.items():\n",
    "        for rate in rates:\n",
    "            print(f\"\\n--- æ­£åœ¨å¤„ç†: Framework={framework_name}, Heterogeneity={rate} ---\")\n",
    "            exp_path = os.path.join(base_dir, framework_code, str(rate))\n",
    "            if not os.path.isdir(exp_path):\n",
    "                print(f\"   âŒ ç›®å½•ä¸å­˜åœ¨ï¼Œè·³è¿‡ã€‚\")\n",
    "                continue\n",
    "            \n",
    "            # æ‰¾åˆ°æœ¬æ¬¡è¿è¡Œçš„å¼€å§‹æ—¶é—´ (ä»¥æ€§èƒ½æ•°æ®ä¸ºå‡†)\n",
    "            perf_filepath = os.path.join(exp_path, 'task_exec_time.csv')\n",
    "            if not os.path.exists(perf_filepath):\n",
    "                print(f\"   âŒ æ€§èƒ½æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œæ— æ³•ç¡®å®šå¼€å§‹æ—¶é—´ï¼Œè·³è¿‡ã€‚\")\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                # ç¡®å®šæœ¬æ¬¡å®éªŒçš„ç»Ÿä¸€å¼€å§‹æ—¶é—´\n",
    "                temp_perf_df = pd.read_csv(perf_filepath)\n",
    "                if temp_perf_df.empty:\n",
    "                    print(\"   âŒ æ€§èƒ½æ–‡ä»¶ä¸ºç©ºï¼Œè·³è¿‡ã€‚\")\n",
    "                    continue\n",
    "                unified_start_time = temp_perf_df['arrival_time'].min()\n",
    "                print(f\"   -> ç¡®å®šç»Ÿä¸€å¼€å§‹æ—¶é—´ (Unix Timestamp): {unified_start_time}\")\n",
    "\n",
    "                # å¤„ç†æ€§èƒ½æ•°æ®\n",
    "                avg_dct, p95_dct, completed_dags = process_performance_data(exp_path, unified_start_time, duration_sec)\n",
    "                \n",
    "                # å¤„ç†èµ„æºæ•°æ®\n",
    "                resource_metrics = process_resource_data(exp_path, unified_start_time, duration_sec)\n",
    "\n",
    "                # è®¡ç®—ååé‡\n",
    "                throughput = (completed_dags / duration_sec) * 60 if duration_sec > 0 else 0\n",
    "\n",
    "                # æ•´åˆç»“æœ\n",
    "                result_row = {\n",
    "                    \"framework\": framework_name,\n",
    "                    \"heterogeneity\": rate,\n",
    "                    \"throughput\": throughput,\n",
    "                    \"avg_dct\": avg_dct,\n",
    "                    \"p95_dct\": p95_dct,\n",
    "                    \"completed_dags\": completed_dags,\n",
    "                    **resource_metrics # å°†èµ„æºå­—å…¸åˆå¹¶è¿›æ¥\n",
    "                }\n",
    "                full_results.append(result_row)\n",
    "                print(f\"   âœ… å®Œæˆå¤„ç†ã€‚ååé‡: {throughput:.2f} DAGs/min, å¹³å‡DCT: {avg_dct:.2f}s\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"   âŒ å¤„ç† {exp_path} æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}\")\n",
    "\n",
    "    return pd.DataFrame(full_results).fillna(0) # ç”¨0å¡«å……ç¼ºå¤±å€¼\n",
    "\n",
    "# --- æ‰§è¡Œåˆ†æ ---\n",
    "final_df = run_full_analysis(BASE_RESULTS_DIR, FRAMEWORKS, HETEROGENEITY_RATES, EXPERIMENT_DURATION_SEC)\n",
    "\n",
    "print(\"\\n\\n\" + \"=\"*50)\n",
    "print(\"           >>> åˆ†æå®Œæˆ <<<\")\n",
    "print(\"=\"*50)\n",
    "display(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "import pytz\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.ticker as mticker\n",
    "import matplotlib.font_manager as font_manager\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import warnings\n",
    "import random\n",
    "from matplotlib.patches import Patch\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font_dir = os.path.expanduser(\"./fonts/\")\n",
    "for font_file in os.listdir(font_dir):\n",
    "    if font_file.endswith('.ttf'):\n",
    "        font_manager.fontManager.addfont(os.path.join(font_dir, font_file))\n",
    "print(\"å·²åŠ è½½çš„ Arial å­—ä½“å˜ä½“:\", \n",
    "      [f.name for f in font_manager.fontManager.ttflist if 'Arial' in f.name])\n",
    "# è®¾ç½®ä¸º Arial æˆ– Helvetica\n",
    "plt.rcParams.update({\n",
    "    'font.family': 'sans-serif',        # ä½¿ç”¨æ— è¡¬çº¿å­—ä½“æ—\n",
    "    'font.sans-serif': ['Arial', 'Helvetica',  'Times New Roman'],  # ä¼˜å…ˆå°è¯• Arialï¼Œå¤±è´¥åå›é€€åˆ° Helvetica\n",
    "    # 'font.weight': 'bold',\n",
    "    'axes.labelsize': 26,\n",
    "    # 'axes.labelweight': 'bold',\n",
    "    'xtick.labelsize': 26,\n",
    "    'ytick.labelsize': 26,\n",
    "    'legend.fontsize': 20,\n",
    "    # 'legend.edgecolor': 'black',\n",
    "    'legend.frameon': True,\n",
    "})\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "# éªŒè¯å­—ä½“æ˜¯å¦ç”Ÿæ•ˆ\n",
    "print(\"å½“å‰ä½¿ç”¨çš„å­—ä½“:\", plt.rcParams['font.sans-serif'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================================\n",
    "# Part 1: æ•°æ®å¤„ç†ä»£ç  (æ— ä¿®æ”¹)\n",
    "# ==========================================================================\n",
    "BASE_RESULTS_DIR = os.path.join(\"..\", \"data\", \"exp1 agent framework\", \"heterogeneity rate experiment\")\n",
    "FRAMEWORKS = {\n",
    "    'Maze': 'Maze',\n",
    "    'AutoGen': 'AutoGen',\n",
    "    'AgentScope': 'AgentScope',\n",
    "    'Maze(vLLM)': 'Maze(vLLM)',\n",
    "    'vLLM': 'vLLM'\n",
    "}\n",
    "HETEROGENEITY_RATES = [0.8, 1.2, 1.6]\n",
    "EXPERIMENT_DURATION_SEC = 1800 \n",
    "RESOURCE_TIMESTAMP_TIMEZONE = 'Asia/Shanghai'\n",
    "\n",
    "def process_performance_data(directory_path, unified_start_time, duration_sec):\n",
    "    filepath = os.path.join(directory_path, 'task_exec_time.csv')\n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"   âŒ è­¦å‘Š: æ€§èƒ½æ–‡ä»¶æœªæ‰¾åˆ°: {filepath}\")\n",
    "        return None, None, None, None\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(filepath)\n",
    "        if 'uuid' in df.columns:\n",
    "            df.rename(columns={'uuid': 'run_id'}, inplace=True)\n",
    "\n",
    "        required_cols = ['run_id', 'arrival_time', 'finish_exec_time', 'sub_time', 'response_time']\n",
    "        if not all(col in df.columns for col in required_cols):\n",
    "            print(f\"   âŒ é”™è¯¯: æ–‡ä»¶ {filepath} ç¼ºå°‘å¿…éœ€çš„åˆ—ã€‚éœ€è¦: {required_cols}\")\n",
    "            return None, None, None, None\n",
    "            \n",
    "        abs_end_time_cutoff = unified_start_time + duration_sec\n",
    "        \n",
    "        dag_arrivals = df.groupby('run_id')['arrival_time'].min().reset_index()\n",
    "        dags_in_window = dag_arrivals[dag_arrivals['arrival_time'] < abs_end_time_cutoff]\n",
    "        valid_run_ids = dags_in_window['run_id']\n",
    "        \n",
    "        df_filtered = df[df['run_id'].isin(valid_run_ids)].copy()\n",
    "        \n",
    "        if df_filtered.empty:\n",
    "            print(\"   âœ… æ²¡æœ‰åœ¨æŒ‡å®šæ—¶é—´çª—å£å†…å¼€å§‹çš„DAGã€‚\")\n",
    "            return 0, 0, 0, 0\n",
    "            \n",
    "        dag_runs = df_filtered.groupby('run_id').agg(\n",
    "            dag_arrival_time=('arrival_time', 'min'),\n",
    "            dag_finish_time=('finish_exec_time', 'max'),\n",
    "            dag_response_time=('response_time', 'max') \n",
    "        ).reset_index()\n",
    "\n",
    "        for col in ['dag_arrival_time', 'dag_finish_time', 'dag_response_time']:\n",
    "            dag_runs[col] = pd.to_numeric(dag_runs[col], errors='coerce')\n",
    "        dag_runs.dropna(inplace=True)\n",
    "\n",
    "        dag_runs['dct'] = dag_runs['dag_finish_time'] - dag_runs['dag_arrival_time']\n",
    "        dag_runs = dag_runs[dag_runs['dct'] >= 0]\n",
    "        \n",
    "        avg_dct = dag_runs['dct'].mean() if not dag_runs.empty else 0\n",
    "        p95_dct = dag_runs['dct'].quantile(0.95) if not dag_runs.empty else 0\n",
    "        p95_response_time = dag_runs['dag_response_time'].quantile(0.95) if not dag_runs.empty else 0\n",
    "        completed_dags = len(dag_runs)\n",
    "        \n",
    "        print(f\"   âœ… æˆåŠŸå¤„ç†äº† {completed_dags} ä¸ªDAGçš„æ€§èƒ½æ•°æ®ã€‚\")\n",
    "        return avg_dct, p95_dct, p95_response_time, completed_dags\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ é”™è¯¯: å¤„ç†æ–‡ä»¶ {filepath} æ—¶å‡ºé”™: {e}\")\n",
    "        return None, None, None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_resource_data(directory_path, unified_start_time, duration_sec):\n",
    "    resource_files = glob.glob(os.path.join(directory_path, 'resource_stats*.csv'))\n",
    "    if not resource_files: return {}\n",
    "    all_res_dfs = []\n",
    "    for f in resource_files:\n",
    "        try:\n",
    "            node_df = pd.read_csv(f, parse_dates=['timestamp'])\n",
    "            all_res_dfs.append(node_df)\n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ è­¦å‘Š: è¯»å–èµ„æºæ–‡ä»¶ {f} å¤±è´¥: {e}\")\n",
    "    if not all_res_dfs: return {}\n",
    "    combined_df = pd.concat(all_res_dfs, ignore_index=True).set_index('timestamp').sort_index()\n",
    "    try:\n",
    "        if combined_df.index.tz is None:\n",
    "            combined_df = combined_df.tz_localize(RESOURCE_TIMESTAMP_TIMEZONE)\n",
    "        combined_df = combined_df.tz_convert('UTC')\n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ é”™è¯¯: æ—¶åŒºè½¬æ¢å¤±è´¥: {e}. è¯·æ£€æŸ¥ `RESOURCE_TIMESTAMP_TIMEZONE` è®¾ç½®æ˜¯å¦æ­£ç¡®ã€‚\")\n",
    "        return {}\n",
    "    start_ts = pd.to_datetime(unified_start_time, unit='s', utc=True)\n",
    "    end_ts_cutoff = start_ts + pd.to_timedelta(duration_sec, unit='s')\n",
    "    df_filtered = combined_df[(combined_df.index >= start_ts) & (combined_df.index < end_ts_cutoff)]\n",
    "    if df_filtered.empty: return {}\n",
    "    avg_resources = {\n",
    "        'avg_cpu_util': df_filtered['cpu_percent'].mean(),\n",
    "        'avg_gpu_mem_util': df_filtered['gpu_avg_mem_percent'].mean(),\n",
    "        'avg_disk_io_mbps': df_filtered['disk_total_MBps'].mean()\n",
    "    }\n",
    "    return avg_resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_full_analysis(base_dir, frameworks, rates, duration_sec):\n",
    "    full_results = []\n",
    "    for framework_code, framework_name in frameworks.items():\n",
    "        for rate in rates:\n",
    "            print(f\"\\n--- æ­£åœ¨å¤„ç†: Framework={framework_name}, Heterogeneity={rate} ---\")\n",
    "            exp_path = os.path.join(base_dir, framework_code, str(rate))\n",
    "            if not os.path.isdir(exp_path):\n",
    "                print(f\"   âŒ ç›®å½•ä¸å­˜åœ¨ï¼Œè·³è¿‡ã€‚\")\n",
    "                continue\n",
    "            perf_filepath = os.path.join(exp_path, 'task_exec_time.csv')\n",
    "            if not os.path.exists(perf_filepath):\n",
    "                print(f\"   âŒ æ€§èƒ½æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œæ— æ³•ç¡®å®šå¼€å§‹æ—¶é—´ï¼Œè·³è¿‡ã€‚\")\n",
    "                continue\n",
    "            try:\n",
    "                temp_perf_df = pd.read_csv(perf_filepath)\n",
    "                if temp_perf_df.empty:\n",
    "                    print(\"   âŒ æ€§èƒ½æ–‡ä»¶ä¸ºç©ºï¼Œè·³è¿‡ã€‚\")\n",
    "                    continue\n",
    "                unified_start_time = temp_perf_df['arrival_time'].min()\n",
    "                print(f\"   -> ç¡®å®šç»Ÿä¸€å¼€å§‹æ—¶é—´ (Unix Timestamp): {unified_start_time}\")\n",
    "                \n",
    "                avg_dct, p95_dct, p95_response_time, completed_dags = process_performance_data(exp_path, unified_start_time, duration_sec)\n",
    "                \n",
    "                if completed_dags is None:\n",
    "                    print(f\"   âŒ å› æ€§èƒ½æ•°æ®å¤„ç†å¤±è´¥ï¼Œè·³è¿‡æ­¤è½®åˆ†æã€‚\")\n",
    "                    continue\n",
    "\n",
    "                resource_metrics = process_resource_data(exp_path, unified_start_time, duration_sec)\n",
    "                throughput = (completed_dags / duration_sec) * 60 if duration_sec > 0 else 0\n",
    "                result_row = {\n",
    "                    \"framework\": framework_name, \"heterogeneity\": rate,\n",
    "                    \"throughput\": throughput, \"avg_dct\": avg_dct, \"p95_dct\": p95_dct,\n",
    "                    \"p95_response_time\": p95_response_time, \"completed_dags\": completed_dags,\n",
    "                    **resource_metrics\n",
    "                }\n",
    "                full_results.append(result_row)\n",
    "                print(f\"   âœ… å®Œæˆå¤„ç†ã€‚ååé‡: {throughput:.2f} DAGs/min, å¹³å‡DCT: {avg_dct:.2f}s\")\n",
    "            except Exception as e:\n",
    "                print(f\"   âŒ å¤„ç† {exp_path} æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}\")\n",
    "\n",
    "    return pd.DataFrame(full_results).fillna(0)\n",
    "\n",
    "# --- æ‰§è¡Œåˆ†æ ---\n",
    "final_df = run_full_analysis(BASE_RESULTS_DIR, FRAMEWORKS, HETEROGENEITY_RATES, EXPERIMENT_DURATION_SEC)\n",
    "print(\"\\n\\n\" + \"=\"*50)\n",
    "print(\"               >>> åˆ†æå®Œæˆ <<<\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_results_barchart(df, color_map, hatch_map):\n",
    "    hue_order = [f for f in color_map.keys() if f in df['framework'].unique()]\n",
    "\n",
    "    def style_bars_and_legend(ax, h_map, c_map, order):\n",
    "        num_locations = len(ax.get_xticks())\n",
    "        for i, patch in enumerate(ax.patches):\n",
    "            hue_index = i // num_locations\n",
    "            if hue_index < len(order):\n",
    "                framework_name = order[hue_index]\n",
    "                if framework_name in h_map:\n",
    "                    patch.set_hatch(h_map[framework_name])\n",
    "        \n",
    "        if ax.get_legend() is not None:\n",
    "            ax.get_legend().remove()\n",
    "\n",
    "        legend_handles = []\n",
    "        for framework in order:\n",
    "            if framework in c_map:\n",
    "                handle = Patch(\n",
    "                    facecolor=c_map[framework],\n",
    "                    edgecolor='white',\n",
    "                    hatch=h_map.get(framework, None),\n",
    "                    label=framework\n",
    "                )\n",
    "                legend_handles.append(handle)\n",
    "        \n",
    "        ax.legend(handles=legend_handles, loc= \"upper right\")\n",
    "\n",
    "    # --- ç»˜åˆ¶å››å¼ å›¾ ---\n",
    "    metrics_to_plot = {\n",
    "        'exp2_hete_tp.pdf': {'y': 'throughput', 'ylabel': 'System Throughput'},\n",
    "        'exp2_hete_p95_resp_time.pdf': {'y': 'p95_response_time', 'ylabel': 'P95 Response Time (s)'},\n",
    "        'exp2_hete_gpu_util.pdf': {'y': 'avg_gpu_mem_util', 'ylabel': 'GPU Memory Util. (%)'},\n",
    "        'exp2_hete_cpu_util.pdf': {'y': 'avg_cpu_util', 'ylabel': 'CPU Utilization (%)'}\n",
    "    }\n",
    "\n",
    "    for filename, plot_info in metrics_to_plot.items():\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        sns.barplot(data=df, x='heterogeneity', y=plot_info['y'], hue='framework', \n",
    "                    hue_order=hue_order, palette=color_map, ax=ax, edgecolor='white')\n",
    "        \n",
    "        style_bars_and_legend(ax, hatch_map, color_map, hue_order)\n",
    "        \n",
    "        ax.set_xlabel(\"Task Heterogeneity Score\")\n",
    "        ax.set_ylabel(plot_info['ylabel'])\n",
    "        ax.grid(True, which='both', axis='y', linestyle='--', linewidth= 1, alpha=0.9)\n",
    "\n",
    "        if 'gpu_mem_util' in filename:\n",
    "            ax.set_ylim(0, 100)\n",
    "        elif 'cpu_util' in filename and not df['avg_cpu_util'].empty:\n",
    "            ax.set_ylim(0, df['avg_cpu_util'].max() * 1.5)\n",
    "\n",
    "        plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "        print(f\"âœ… å›¾è¡¨å·²ä¿å­˜è‡³: {filename}\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- è°ƒç”¨ç»˜å›¾å‡½æ•° ---\n",
    "if not final_df.empty:\n",
    "    print(\"\\n\" + \"=\"*25 + \" DataFrame for Plotting \" + \"=\"*25)\n",
    "    print(final_df)\n",
    "    print(\"=\"*72)\n",
    "    \n",
    "    # <--- ä¿®æ”¹: é¢œè‰²æ˜ å°„ç°åœ¨ç›´æ¥ä¼ å…¥\n",
    "    color_map = {\n",
    "        'Maze': \"#d52627\", \n",
    "        'AutoGen': \"#2B9F2B\", \n",
    "        'AgentScope': \"#9366BD\", \n",
    "        'Maze(vLLM)': \"#1E76B3\",\n",
    "        'vLLM': \"#8B554A\", \n",
    "    }\n",
    "    # ä¼˜åŒ–åçš„hatch_map\n",
    "    hatch_map = {\n",
    "        'Maze': 'x',       # äº¤å‰ (ä¿æŒ)\n",
    "        'AutoGen': '//',    # <--- æ¨è: æ­£æ–œçº¿, ä¸'\\\\'å¯¹æ¯”æ¸…æ™°\n",
    "        'AgentScope': '--', # <--- æ¨è: ç‚¹çŠ¶, æ›´ç®€æ´\n",
    "        'Maze(vLLM)': '\\\\\\\\', # åæ–œçº¿ \n",
    "        'vLLM': '+',       # æ˜Ÿå· (ä¿æŒ)\n",
    "    }\n",
    "    plot_all_results_barchart(final_df, color_map, hatch_map)\n",
    "else:\n",
    "    print(\"\\nâŒ æ•°æ®åˆ†æç»“æœä¸ºç©ºï¼Œæ— æ³•ç”Ÿæˆå›¾è¡¨ã€‚\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batched arrival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.lines import Line2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../data/exp3/batched arrival'\n",
    "OUTPUT_PDF_FILE = 'exp3_dct_cdf.pdf'\n",
    "ALGORITHMS_TO_PLOT = ['DAPS', 'FCFS', 'PEFT', 'HEFT']\n",
    "# --- Optional: Prettier names and styles for the plot ---\n",
    "# For a more professional-looking plot, you can define display names, colors, and line styles.\n",
    "ALGORITHM_STYLES = {\n",
    "    # 'algorithm_folder_name': ('Display Name', 'color', 'linestyle')\n",
    "    'DAPS': ('DAPS', '#d52627', '-'),\n",
    "    'FCFS': ('FCFS', '#2B9F2B', '--'),\n",
    "    'PEFT': ('PEFT', '#9366BD', ':'),\n",
    "    'HEFT': ('HEFT', '#8B554A', '-.'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Data Loading and Processing Function (UPDATED LOGIC) ---\n",
    "def load_job_completion_times(base_dir, algorithms_to_load):\n",
    "    \"\"\"\n",
    "    Loads and calculates Job Completion Times (JCT) for specified algorithms.\n",
    "    JCT is calculated as: max(finish_exec_time) - min(arrival_time) for each DAG (run_id).\n",
    "\n",
    "    Args:\n",
    "        base_dir (str): The root directory containing algorithm data.\n",
    "        algorithms_to_load (list): A list of algorithm folder names to load.\n",
    "                                   If empty, loads all found algorithms.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where keys are algorithm names and values are lists of JCTs.\n",
    "    \"\"\"\n",
    "    print(f\"Searching for data in: {os.path.abspath(base_dir)}\")\n",
    "    jct_data = {}\n",
    "\n",
    "    if not os.path.exists(base_dir):\n",
    "        print(f\"âŒ Error: Data directory not found at '{base_dir}'\")\n",
    "        return jct_data\n",
    "\n",
    "    if not algorithms_to_load:\n",
    "        try:\n",
    "            algorithms_to_load = [d for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d))]\n",
    "            print(f\"Found algorithms: {algorithms_to_load}\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Could not list directories in '{base_dir}'. Please check the path.\")\n",
    "            return jct_data\n",
    "\n",
    "    for algo_name in algorithms_to_load:\n",
    "        algo_path = os.path.join(base_dir, algo_name)\n",
    "        if not os.path.isdir(algo_path):\n",
    "            print(f\"Warning: Directory for algorithm '{algo_name}' not found. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        all_jcts = []\n",
    "        seed_dirs = [d for d in os.listdir(algo_path) if os.path.isdir(os.path.join(algo_path, d))]\n",
    "        \n",
    "        if not seed_dirs:\n",
    "            print(f\"Warning: No seed directories found for algorithm '{algo_name}'. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nProcessing algorithm: {algo_name}\")\n",
    "        for seed in seed_dirs:\n",
    "            task_file = os.path.join(algo_path, seed, 'task_exec_time.csv')\n",
    "            if os.path.exists(task_file):\n",
    "                try:\n",
    "                    df = pd.read_csv(task_file)\n",
    "                    \n",
    "                    # Ensure required columns exist\n",
    "                    required_cols = ['run_id', 'arrival_time', 'finish_exec_time']\n",
    "                    if not all(col in df.columns for col in required_cols):\n",
    "                        print(f\"  - âŒ Error: File {task_file} is missing required columns. Skipping seed.\")\n",
    "                        continue\n",
    "                    \n",
    "                    # Group by run_id to calculate metrics for each DAG\n",
    "                    dag_runs = df.groupby('run_id').agg(\n",
    "                        dag_arrival_time=('arrival_time', 'min'),\n",
    "                        dag_finish_time=('finish_exec_time', 'max')\n",
    "                    ).reset_index()\n",
    "\n",
    "                    # Convert to numeric and handle potential errors\n",
    "                    dag_runs['dag_arrival_time'] = pd.to_numeric(dag_runs['dag_arrival_time'], errors='coerce')\n",
    "                    dag_runs['dag_finish_time'] = pd.to_numeric(dag_runs['dag_finish_time'], errors='coerce')\n",
    "                    dag_runs.dropna(inplace=True)\n",
    "\n",
    "                    # Calculate JCT (Job Completion Time)\n",
    "                    dag_runs['jct'] = dag_runs['dag_finish_time'] - dag_runs['dag_arrival_time']\n",
    "                    \n",
    "                    # Filter out invalid data (e.g., negative JCT)\n",
    "                    valid_jcts = dag_runs[dag_runs['jct'] >= 0]['jct']\n",
    "                    \n",
    "                    all_jcts.extend(valid_jcts.tolist())\n",
    "                    print(f\"  - âœ… Loaded and processed {len(valid_jcts)} jobs from seed '{seed}'.\")\n",
    "                except Exception as e:\n",
    "                    print(f\"  - âŒ Error reading or processing {task_file}: {e}\")\n",
    "            else:\n",
    "                print(f\"  - âš ï¸ Warning: 'task_exec_time.csv' not found in {os.path.join(algo_path, seed)}. Skipping.\")\n",
    "\n",
    "        if all_jcts:\n",
    "            jct_data[algo_name] = all_jcts\n",
    "            print(f\"-> Finished processing for {algo_name}. Total valid jobs: {len(all_jcts)}.\")\n",
    "\n",
    "    return jct_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Plotting Function (UPDATED TO SAVE PDF) ---\n",
    "def plot_cdf(data, styles, output_filename):\n",
    "    \"\"\"\n",
    "    Plots the Cumulative Distribution Function (CDF) and saves it to a PDF file.\n",
    "\n",
    "    Args:\n",
    "        data (dict): A dictionary of job completion times for each algorithm.\n",
    "        styles (dict): A dictionary defining the visual style for each algorithm.\n",
    "        output_filename (str): Path to save the output PDF file.\n",
    "    \"\"\"\n",
    "    if not data:\n",
    "        print(\"No data available to plot. Please check your data directory and configuration.\")\n",
    "        return\n",
    "\n",
    "    # plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # --- Plotting each algorithm's CDF ---\n",
    "    for algo_name, times in data.items():\n",
    "        display_name, color, linestyle = styles.get(algo_name, (algo_name, None, '-'))\n",
    "        sorted_times = np.sort(times)\n",
    "        cdf = np.arange(1, len(sorted_times) + 1) / len(sorted_times)\n",
    "        ax.plot(sorted_times, cdf, label=display_name, color=color, linestyle=linestyle, linewidth=5)\n",
    "\n",
    "    # --- Aesthetics and Labels ---\n",
    "    # ax.set_title('CDF of DAG Completion Time', fontsize=18, fontweight='bold')\n",
    "    ax.set_xlabel('DAG Completion Time (seconds)')\n",
    "    ax.set_ylabel('CDF')\n",
    "    ax.tick_params(axis='both', which='major')\n",
    "    ax.grid(True, which='both', linestyle='--', linewidth= 1)\n",
    "    ax.set_xlim(left= 0)\n",
    "    ax.set_ylim(bottom=0, top= 1.05)\n",
    "\n",
    "    # --- Legend ---\n",
    "    legend_handles = [Line2D([0], [0], color=s[1], lw= 5, linestyle=s[2], label=s[0]) \n",
    "                      for k, s in styles.items() if k in data]\n",
    "    ax.legend(handles=legend_handles, loc='lower right', ncol=2)\n",
    "\n",
    "    # --- \"Better\" Arrow Annotation ---\n",
    "    arrow_x_pos = np.percentile(np.concatenate(list(data.values())), 10) if data else 1\n",
    "    arrow_y_pos = 0.8\n",
    "    ax.annotate('Better', xy=(arrow_x_pos, arrow_y_pos), \n",
    "                xytext=(arrow_x_pos * 1.5, arrow_y_pos - 0.25),\n",
    "                arrowprops=dict(facecolor='black', shrink= 0.05, width= 3, headwidth= 8, connectionstyle=\"arc3,rad=-0.2\"),\n",
    "                ha='center', fontsize= 20)\n",
    "\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_edgecolor('black')\n",
    "        spine.set_visible(True)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    # --- Save the plot to a PDF file ---\n",
    "    try:\n",
    "        fig.savefig(output_filename, format='pdf', bbox_inches='tight')\n",
    "        print(f\"\\nâœ… Plot successfully saved to: {os.path.abspath(output_filename)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ Error saving plot to PDF: {e}\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data using the corrected JCT calculation\n",
    "completion_data = load_job_completion_times(DATA_DIR, ALGORITHMS_TO_PLOT)\n",
    "\n",
    "# Generate, display, and save the plot\n",
    "if completion_data:\n",
    "    plot_cdf(completion_data, ALGORITHM_STYLES, OUTPUT_PDF_FILE)\n",
    "else:\n",
    "    print(\"\\nSkipping plot generation due to lack of data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continous arrival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.lines import Line2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Configuration ---\n",
    "# æ•°æ®ç›®å½•ï¼šæŒ‡å‘ä½ çš„ \"continuous arrival mode\" å®éªŒæ•°æ®\n",
    "DATA_DIR = '../data/exp3/continuous arrival'\n",
    "# è¾“å‡ºPDFæ–‡ä»¶çš„åç§°\n",
    "OUTPUT_PDF_FILE = 'exp3_p95_cdf.pdf'\n",
    "\n",
    "# ä½ å¯ä»¥ä¿®æ”¹è¿™ä¸ªåˆ—è¡¨æ¥é€‰æ‹©è¦ç»˜åˆ¶çš„ç®—æ³•\n",
    "ALGORITHMS_TO_PLOT = ['DAPS', 'FCFS', 'PEFT', 'HEFT']\n",
    "\n",
    "# ç”¨äºè®¡ç®—P95å“åº”æ—¶é—´åºåˆ—çš„æ—¶é—´çª—å£å¤§å°ï¼ˆç§’ï¼‰\n",
    "# ä¾‹å¦‚ï¼Œ120ç§’ä»£è¡¨æ¯2åˆ†é’Ÿè®¡ç®—ä¸€æ¬¡P95å€¼\n",
    "WINDOW_SIZE_SEC = 120\n",
    "\n",
    "# ä¸ºç»˜å›¾å®šä¹‰æ˜¾ç¤ºåç§°ã€é¢œè‰²å’Œçº¿æ¡æ ·å¼\n",
    "ALGORITHM_STYLES = {\n",
    "    'DAPS': ('DAPS', '#d52627', '-'),\n",
    "    'FCFS': ('FCFS', '#2B9F2B', '--'),\n",
    "    'PEFT': ('PEFT', '#9366BD', ':'),\n",
    "    'HEFT': ('HEFT', '#8B554A', '-.'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Data Loading and Processing ---\n",
    "\n",
    "def load_p95_response_times(base_dir, algorithms_to_load, window_size):\n",
    "    \"\"\"\n",
    "    åŠ è½½æ•°æ®ï¼Œé€šè¿‡æ—¶é—´åˆ†ç®±è®¡ç®—P95å“åº”æ—¶é—´åºåˆ—ã€‚\n",
    "    \n",
    "    Returns:\n",
    "        dict: {'algo_name': [p95_window1, p95_window2, ...]}\n",
    "    \"\"\"\n",
    "    print(f\"Searching for data in: {os.path.abspath(base_dir)}\")\n",
    "    p95_data = {}\n",
    "\n",
    "    if not os.path.exists(base_dir):\n",
    "        print(f\"âŒ Error: Data directory not found at '{base_dir}'\")\n",
    "        return p95_data\n",
    "\n",
    "    if not algorithms_to_load:\n",
    "        algorithms_to_load = [d for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d))]\n",
    "\n",
    "    for algo_name in algorithms_to_load:\n",
    "        # å‡è®¾æ¯ä¸ªç®—æ³•ç›®å½•ä¸‹åªæœ‰ä¸€ä¸ªå®éªŒç»“æœå­ç›®å½•ï¼ˆæŒ‰seedæˆ–æ—¶é—´æˆ³å‘½åï¼‰\n",
    "        algo_path = os.path.join(base_dir, algo_name)\n",
    "        if not os.path.isdir(algo_path):\n",
    "            continue\n",
    "            \n",
    "        task_file = os.path.join(algo_path, 'task_exec_time.csv')\n",
    "        \n",
    "        print(f\"\\nProcessing algorithm: {algo_name}\")\n",
    "        if os.path.exists(task_file):\n",
    "            try:\n",
    "                df = pd.read_csv(task_file)\n",
    "                \n",
    "                required_cols = ['run_id', 'arrival_time', 'finish_exec_time', 'response_time']\n",
    "                if not all(col in df.columns for col in required_cols):\n",
    "                    print(f\"  - âŒ Error: File {task_file} is missing required columns. Skipping.\")\n",
    "                    continue\n",
    "                \n",
    "                # è®¡ç®—æ¯ä¸ªDAGçš„å®Œæˆæ—¶é—´å’Œå“åº”æ—¶é—´\n",
    "                dag_runs = df.groupby('run_id').agg(\n",
    "                    dag_finish_time=('finish_exec_time', 'max'),\n",
    "                    dag_response_time=('response_time', 'max')\n",
    "                ).reset_index()\n",
    "                \n",
    "                # ç¡®å®šå®éªŒçš„ç›¸å¯¹å¼€å§‹æ—¶é—´\n",
    "                exp_start_time = df['arrival_time'].min()\n",
    "                dag_runs['relative_finish'] = dag_runs['dag_finish_time'] - exp_start_time\n",
    "                \n",
    "                # åˆ›å»ºæ—¶é—´åˆ†ç®±\n",
    "                max_time = dag_runs['relative_finish'].max()\n",
    "                time_bins = np.arange(0, max_time + window_size, window_size)\n",
    "                \n",
    "                # æŒ‰å®Œæˆæ—¶é—´å¯¹DAGè¿›è¡Œåˆ†ç®±\n",
    "                dag_runs['finish_bin'] = pd.cut(dag_runs['relative_finish'], bins=time_bins, right=False)\n",
    "                \n",
    "                # è®¡ç®—æ¯ä¸ªæ—¶é—´çª—å£å†…çš„P95å“åº”æ—¶é—´\n",
    "                p95_series = dag_runs.groupby('finish_bin', observed=True)['dag_response_time'].quantile(0.95)\n",
    "                \n",
    "                # è¿‡æ»¤æ‰æ²¡æœ‰æ•°æ®çš„çª—å£ (NaN)\n",
    "                valid_p95_values = p95_series.dropna().tolist()\n",
    "                \n",
    "                if valid_p95_values:\n",
    "                    p95_data[algo_name] = valid_p95_values\n",
    "                    print(f\"  - âœ… Calculated {len(valid_p95_values)} P95 values over {window_size}s windows.\")\n",
    "                else:\n",
    "                    print(f\"  - âš ï¸ Warning: No valid P95 values found for {algo_name}.\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"  - âŒ Error processing {task_file}: {e}\")\n",
    "        else:\n",
    "            print(f\"  - âš ï¸ Warning: 'task_exec_time.csv' not found in {algo_path}. Skipping.\")\n",
    "            \n",
    "    return p95_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Plotting Function ---\n",
    "def plot_p95_cdf(data, styles, output_filename):\n",
    "    \"\"\"\n",
    "    ç»˜åˆ¶P95å“åº”æ—¶é—´åºåˆ—çš„CDFå›¾ã€‚\n",
    "    \"\"\"\n",
    "    if not data:\n",
    "        print(\"No data available to plot.\")\n",
    "        return\n",
    "\n",
    "    # plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    for algo_name, p95_values in data.items():\n",
    "        display_name, color, linestyle = styles.get(algo_name, (algo_name, None, '-'))\n",
    "        \n",
    "        sorted_p95 = np.sort(p95_values)\n",
    "        cdf = np.arange(1, len(sorted_p95) + 1) / len(sorted_p95)\n",
    "        \n",
    "        ax.plot(sorted_p95, cdf, label=display_name, color=color, linestyle=linestyle, linewidth=5)\n",
    "\n",
    "    # ç¾åŒ–å›¾è¡¨\n",
    "    # ax.set_title('CDF of P95 Response Time under Continuous Load (85%)', fontsize=16, fontweight='bold')\n",
    "    ax.set_xlabel('P95 Response Time (seconds)')\n",
    "    ax.set_ylabel('CDF')\n",
    "    ax.tick_params(axis='both', which='major')\n",
    "    ax.grid(True, which='both', linestyle='--', alpha=0.9, linewidth= 1)\n",
    "    ax.set_xlim(left=0)\n",
    "    ax.set_ylim(bottom=0, top=1.05)\n",
    "\n",
    "    # åˆ›å»ºå›¾ä¾‹\n",
    "    legend_handles = [Line2D([0], [0], color=s[1], lw=5, linestyle=s[2], label=s[0]) \n",
    "                      for k, s in styles.items() if k in data]\n",
    "    ax.legend(handles=legend_handles, fontsize= 20, loc='lower right', ncol= 2)\n",
    "\n",
    "    # æ·»åŠ  \"Better\" æ ‡æ³¨\n",
    "    arrow_x_pos = np.percentile(np.concatenate(list(data.values())), 10) if data else 1\n",
    "    ax.annotate('Better', xy=(arrow_x_pos, 0.8), \n",
    "                xytext=(arrow_x_pos * 1.5, 0.65),\n",
    "                arrowprops=dict(facecolor='black', shrink=0.05, width= 3, headwidth= 8, connectionstyle=\"arc3,rad=-0.2\"),\n",
    "                fontsize=20, ha='center')    \n",
    "    fig.tight_layout()\n",
    "\n",
    "    # ä¿å­˜å›¾è¡¨\n",
    "    try:\n",
    "        fig.savefig(output_filename, format='pdf', bbox_inches='tight')\n",
    "        print(f\"\\nâœ… Plot successfully saved to: {os.path.abspath(output_filename)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ Error saving plot to PDF: {e}\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. åŠ è½½å¹¶è®¡ç®—P95å“åº”æ—¶é—´åºåˆ—\n",
    "p95_response_data = load_p95_response_times(DATA_DIR, ALGORITHMS_TO_PLOT, WINDOW_SIZE_SEC)\n",
    "\n",
    "# 2. ç»˜åˆ¶CDFå›¾\n",
    "if p95_response_data:\n",
    "    plot_p95_cdf(p95_response_data, ALGORITHM_STYLES, OUTPUT_PDF_FILE)\n",
    "else:\n",
    "    print(\"\\nNo data was loaded. Skipping plotting.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment3-Ablation study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import seaborn as sns\n",
    "import glob\n",
    "from matplotlib import font_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. å®éªŒé…ç½® ---\n",
    "\n",
    "# éœ€è¦åˆ†æå’Œç»˜å›¾çš„çƒ§èš€å®éªŒé…ç½®åˆ—è¡¨ (å¿…é¡»ä¸æ–‡ä»¶å¤¹åå®Œå…¨ä¸€è‡´)\n",
    "ABLATION_CONFIGS = [\n",
    "    'Maze',\n",
    "    'Maze w.o. hete. queue',\n",
    "    'Maze w.o. time pred.',\n",
    "    'Maze w.o. sche. algo.'\n",
    "]\n",
    "\n",
    "BASE_DATA_PATH = '../data/exp4/'\n",
    "\n",
    "# --- ç»˜å›¾ä¸åˆ†æå‚æ•° ---\n",
    "\n",
    "# ç”¨äºå›¾ä¾‹çš„â€œç¾åŒ–â€åç§°\n",
    "PRETTY_NAMES = {\n",
    "    'Maze': 'Maze (Full)',\n",
    "    'Maze w.o. hete. queue': 'Maze w/o Heterogeneous Queue',\n",
    "    'Maze w.o. time pred.': 'Maze w/o Time Prediction',\n",
    "    'Maze w.o. sche. algo.': \"Maze w/o Scheduler Algorithm\"\n",
    "}\n",
    "\n",
    "# ç»˜å›¾æ—¶èšåˆæ•°æ®çš„æ—¶é—´çª—å£å¤§å°ï¼ˆç§’ï¼‰\n",
    "WINDOW_SIZE_SEC = 600\n",
    "# ç”¨äºè®¡ç®—è´Ÿè½½çš„å•ä¸ªDAGå¹³å‡å®Œæˆæ—¶é—´ï¼ˆç§’ï¼‰\n",
    "AVG_DAG_COMPLETE_TIME = 45\n",
    "# å®éªŒæ€»æ—¶é•¿ï¼ˆç§’ï¼‰ï¼Œç”¨äºæˆªæ–­DAGå’Œè®¡ç®—ååé‡\n",
    "EXPERIMENT_DURATION_SEC = 3000\n",
    "\n",
    "# 3000ç§’å®éªŒçš„5é˜¶æ®µåŠ¨æ€è´Ÿè½½é…ç½®\n",
    "LOAD_PROFILE = [\n",
    "    (600, (0.5 / AVG_DAG_COMPLETE_TIME)),\n",
    "    (600, (0.75 / AVG_DAG_COMPLETE_TIME)),\n",
    "    (600, (1.0 / AVG_DAG_COMPLETE_TIME)),\n",
    "    (600, (1.25 / AVG_DAG_COMPLETE_TIME)),\n",
    "    (600, (0.5 / AVG_DAG_COMPLETE_TIME)),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. å®éªŒé…ç½® ---\n",
    "ABLATION_CONFIGS = ['Maze', 'Maze w.o. hete. queue', 'Maze w.o. time pred.', 'Maze w.o. sche. algo.']\n",
    "BASE_DATA_PATH = '../data/exp4/'\n",
    "PRETTY_NAMES = {\n",
    "    'Maze': 'Maze (Full)', 'Maze w.o. hete. queue': 'Maze w/o Heterogeneous Queue',\n",
    "    'Maze w.o. time pred.': 'Maze w/o Time Prediction', 'Maze w.o. sche. algo.': \"Maze w/o Scheduler Algorithm\"\n",
    "}\n",
    "EXPERIMENT_DURATION_SEC = 3000\n",
    "def generate_plot_styles(configs):\n",
    "    \"\"\"ä¸ºä¸åŒé…ç½®ç”Ÿæˆç»Ÿä¸€çš„ç»˜å›¾æ ·å¼\"\"\"\n",
    "    colors = {'Maze': '#d52627', 'Maze w.o. hete. queue': '#1E76B3', 'Maze w.o. time pred.': '#FE7E0D', 'Maze w.o. sche. algo.': \"#2B9F2B\"}\n",
    "    linestyles = ['-', '--', ':', '-.'] # <--- å¢åŠ äº†ä¸€ç§çº¿å‹\n",
    "    markers = ['o', 's', '^', 'X', 'D'] # <--- å¢åŠ äº†ä¸¤ç§æ ‡è®°\n",
    "    styles = {}\n",
    "    default_colors = sns.color_palette('deep', n_colors=len(configs))\n",
    "    for i, config in enumerate(configs):\n",
    "        styles[config] = {\n",
    "            'color': colors.get(config, default_colors[i % len(default_colors)]),\n",
    "            'linestyle': linestyles[i % len(linestyles)], 'marker': markers[i % len(markers)],\n",
    "            'linewidth': 5, 'markersize': 20,\n",
    "        }\n",
    "    return styles\n",
    "PLOT_STYLES = generate_plot_styles(ABLATION_CONFIGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. æ•°æ®åŠ è½½ä¸å¤„ç†å‡½æ•° (æœ€ç»ˆä¿®æ­£ç‰ˆ) ---\n",
    "\n",
    "def load_and_process_performance_data(filepath, algorithm_name):\n",
    "    \"\"\"\n",
    "    (æœ€ç»ˆä¿®æ­£ç‰ˆ) åŠ è½½æ€§èƒ½æ•°æ®ï¼Œç¡®ä¿è¿”å›çš„DataFrameç»“æ„ä¸€è‡´ï¼Œæ€»åŒ…å«'dct'åˆ—ã€‚\n",
    "    \"\"\"\n",
    "    # å®šä¹‰ä¸€ä¸ªåŒ…å«æ‰€æœ‰å¿…éœ€åˆ—çš„ç©ºDataFrameä½œä¸ºé»˜è®¤è¿”å›å€¼\n",
    "    empty_df_with_cols = pd.DataFrame(columns=['run_id', 'dag_arrival_time', 'dag_finish_time', 'dag_response_time', 'dct'])\n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"  âŒ è­¦å‘Š: æ€§èƒ½æ–‡ä»¶æœªæ‰¾åˆ°: {filepath}\")\n",
    "        return empty_df_with_cols\n",
    "    try:\n",
    "        df = pd.read_csv(filepath)\n",
    "        if df.empty:\n",
    "            return empty_df_with_cols\n",
    "        if 'uuid' in df.columns: df.rename(columns={'uuid': 'run_id'}, inplace=True)\n",
    "        dag_runs = df.groupby('run_id').agg(\n",
    "            dag_arrival_time=('arrival_time', 'min'),\n",
    "            dag_finish_time=('finish_exec_time', 'max'),\n",
    "            dag_response_time=('response_time', 'max')\n",
    "        ).reset_index()\n",
    "        for col in ['dag_arrival_time', 'dag_finish_time', 'dag_response_time']:\n",
    "            dag_runs[col] = pd.to_numeric(dag_runs[col], errors='coerce')\n",
    "        dag_runs.dropna(inplace=True)\n",
    "        \n",
    "        if dag_runs.empty:\n",
    "            print(f\"  âœ… å¯¹äº {algorithm_name}, æœªæ‰¾åˆ°æœ‰æ•ˆçš„DAGæ•°æ®ã€‚\")\n",
    "            return empty_df_with_cols\n",
    "        # --- æ ¸å¿ƒä¿®æ­£ï¼šæ— è®ºå¦‚ä½•éƒ½å…ˆåˆ›å»º'dct'åˆ— ---\n",
    "        dag_runs['dct'] = dag_runs['dag_finish_time'] - dag_runs['dag_arrival_time']\n",
    "        \n",
    "\n",
    "        print(f\"  âœ… å¯¹äº {algorithm_name}, æœ€ç»ˆç”¨äºç»Ÿè®¡çš„DAGæ•°é‡ä¸º {len(dag_runs)}ã€‚\")\n",
    "        return dag_runs\n",
    "    except Exception as e:\n",
    "        print(f\"  âŒ å¤„ç†æ–‡ä»¶ {filepath} å‡ºé”™: {e}\")\n",
    "        return empty_df_with_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_process_resource_data(directory_path):\n",
    "    \"\"\"åŠ è½½èµ„æºæ•°æ®\"\"\"\n",
    "    resource_files = glob.glob(os.path.join(directory_path, 'resource_stats*.csv'))\n",
    "    if not resource_files: return None\n",
    "    all_res_dfs = [pd.read_csv(f, parse_dates=['timestamp']).set_index('timestamp') for f in resource_files]\n",
    "    if not all_res_dfs: return None\n",
    "    return pd.concat(all_res_dfs).groupby(level=0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_and_display_comprehensive_summary(perf_data, resource_data):\n",
    "    \"\"\"è®¡ç®—å¹¶æ‰“å°åŒ…å«æ‰€æœ‰å…³é”®æŒ‡æ ‡çš„æ€»è§ˆå¤§è¡¨æ ¼ã€‚\"\"\"\n",
    "    print(\"\\n--- æœ€ç»ˆæ€§èƒ½ä¸èµ„æºæ€»è§ˆè¡¨ ---\")\n",
    "    summary_list = []\n",
    "    for config_name in ABLATION_CONFIGS:\n",
    "        perf_df, res_df = perf_data.get(config_name), resource_data.get(config_name)\n",
    "        \n",
    "        # å› ä¸ºloadå‡½æ•°ä¿è¯äº†åˆ—çš„å­˜åœ¨ï¼Œæ‰€ä»¥è¿™é‡Œçš„è®¡ç®—æ˜¯å®‰å…¨çš„\n",
    "        total_dags_in_window = len(perf_df)\n",
    "        throughput = (total_dags_in_window / EXPERIMENT_DURATION_SEC) * 60 if EXPERIMENT_DURATION_SEC > 0 else 0\n",
    "        avg_dct = perf_df['dct'].mean()\n",
    "        p95_response_time = perf_df['dag_response_time'].quantile(0.95)\n",
    "        \n",
    "        avg_cpu, avg_gpu_mem = np.nan, np.nan\n",
    "        if res_df is not None and not res_df.empty:\n",
    "            res_df['relative_time_sec'] = (res_df.index - res_df.index.min()).total_seconds()\n",
    "            res_df_filtered = res_df[res_df['relative_time_sec'] <= EXPERIMENT_DURATION_SEC]\n",
    "            if not res_df_filtered.empty:\n",
    "                avg_cpu = res_df_filtered['cpu_percent'].mean()\n",
    "                avg_gpu_mem = res_df_filtered['gpu_avg_mem_percent'].mean()\n",
    "        \n",
    "        summary_list.append({\n",
    "            'Configuration': PRETTY_NAMES.get(config_name, config_name),\n",
    "            'Throughput (DAGs/Min)': throughput,\n",
    "            'Avg DCT (s)': avg_dct,\n",
    "            'P95 Response Time (s)': p95_response_time,\n",
    "            'Avg CPU Util (%)': avg_cpu,\n",
    "            'Avg GPU Mem Util (%)': avg_gpu_mem\n",
    "        })\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary_list)\n",
    "    ordered_columns = ['Configuration', 'Throughput (DAGs/Min)', 'Avg DCT (s)', 'P95 Response Time (s)', 'Avg CPU Util (%)', 'Avg GPU Mem Util (%)']\n",
    "    print(summary_df[ordered_columns].to_markdown(index=False, floatfmt=\".2f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. ç»˜å›¾å‡½æ•° ---\n",
    "\n",
    "def setup_ax_style(ax, xlabel, ylabel, xlim=None, ylim=None):\n",
    "    \"\"\"\n",
    "    ç»Ÿä¸€è®¾ç½®å­å›¾æ ·å¼ï¼Œæ­¤ç‰ˆæœ¬å·²ç§»é™¤titleå‚æ•°ã€‚\n",
    "    \"\"\"\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.grid(True, which='major', linestyle='--', linewidth= 1, alpha= 0.9)\n",
    "    ax.tick_params(axis='both', which='major')\n",
    "    if xlim is not None: ax.set_xlim(xlim)\n",
    "    if ylim is not None: ax.set_ylim(ylim)\n",
    "\n",
    "def plot_cdf_charts(all_perf_data):\n",
    "    \"\"\"\n",
    "    ç»˜åˆ¶DCTå’Œå“åº”æ—¶é—´çš„CDFå›¾ï¼Œæ­¤ç‰ˆæœ¬ä¸åŒ…å«æ ‡é¢˜ã€‚\n",
    "    \"\"\"\n",
    "    print(\"\\n--- æ­£åœ¨ç”ŸæˆCDFå›¾è¡¨ (æ— æ ‡é¢˜) ---\")\n",
    "    cdf_plot_info = {\n",
    "        'exp4_ablation_dct_cdf': {'metric': 'dct', 'xlabel': 'DAG Completion Time (s)'},\n",
    "        'exp4_ablation_response_time_cdf': {'metric': 'dag_response_time', 'xlabel': 'DAG Response Time (s)'}\n",
    "    }\n",
    "    for filename, info in cdf_plot_info.items():\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        for algo, perf_df in all_perf_data.items():\n",
    "            if perf_df is None or perf_df.empty or info['metric'] not in perf_df or perf_df[info['metric']].dropna().empty:\n",
    "                continue\n",
    "            data = perf_df[info['metric']].dropna().sort_values()\n",
    "            if len(data) > 1:\n",
    "                yvals = np.arange(len(data)) / float(len(data) - 1)\n",
    "            else:\n",
    "                yvals = np.array([1.0]) if len(data) == 1 else np.array([])\n",
    "            style = PLOT_STYLES.get(algo, {})\n",
    "            line_style = {'color': style.get('color'), 'linestyle': style.get('linestyle'), 'linewidth': style.get('linewidth')}\n",
    "            ax.plot(data, yvals, label=PRETTY_NAMES.get(algo, algo), **line_style)\n",
    "        # è°ƒç”¨æ›´æ–°åçš„setup_ax_styleï¼Œä¸å†ä¼ é€’title\n",
    "        setup_ax_style(ax, xlabel=info['xlabel'], ylabel='CDF', xlim=(0, None), ylim=(0, 1.05))\n",
    "        ax.legend(loc='lower right')\n",
    "        plt.savefig(f'{filename}.pdf', format='pdf', bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "        print(f\"âœ… CDFå›¾è¡¨å·²ä¿å­˜: {filename}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. ä¸»æ‰§è¡Œé€»è¾‘ ---\n",
    "print(\"--- å¼€å§‹æ‰§è¡Œçƒ§èš€å®éªŒåˆ†æ (æœ€ç»ˆå¥å£®ç‰ˆ) ---\")\n",
    "all_perf_data, all_resource_data = {}, {}\n",
    "for config in ABLATION_CONFIGS:\n",
    "    print(f\"\\n> æ­£åœ¨å¤„ç†é…ç½®: {config}\")\n",
    "    algo_dir = os.path.join(BASE_DATA_PATH, config)\n",
    "    all_perf_data[config] = load_and_process_performance_data(os.path.join(algo_dir, \"task_exec_time.csv\"), config)\n",
    "    all_resource_data[config] = load_and_process_resource_data(algo_dir)\n",
    "\n",
    "# æ— è®ºåŠ è½½æƒ…å†µå¦‚ä½•ï¼Œéƒ½å°è¯•æ‰§è¡Œåç»­æ­¥éª¤ï¼Œå› ä¸ºå®ƒä»¬ç°åœ¨æ˜¯å®‰å…¨çš„\n",
    "calculate_and_display_comprehensive_summary(all_perf_data, all_resource_data)\n",
    "plot_cdf_charts(all_perf_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment4-Scalability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "from typing import List, Dict\n",
    "from matplotlib.patches import Patch\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font_dir = os.path.expanduser(\"./fonts/\")\n",
    "for font_file in os.listdir(font_dir):\n",
    "    if font_file.endswith('.ttf'):\n",
    "        font_manager.fontManager.addfont(os.path.join(font_dir, font_file))\n",
    "print(\"å·²åŠ è½½çš„ Arial å­—ä½“å˜ä½“:\", \n",
    "      [f.name for f in font_manager.fontManager.ttflist if 'Arial' in f.name])\n",
    "# è®¾ç½®ä¸º Arial æˆ– Helvetica\n",
    "plt.rcParams.update({\n",
    "    'font.family': 'sans-serif',        # ä½¿ç”¨æ— è¡¬çº¿å­—ä½“æ—\n",
    "    'font.sans-serif': ['Arial', 'Helvetica',  'Times New Roman'],  # ä¼˜å…ˆå°è¯• Arialï¼Œå¤±è´¥åå›é€€åˆ° Helvetica\n",
    "    # 'font.weight': 'bold',\n",
    "    'axes.labelsize': 26,\n",
    "    # 'axes.labelweight': 'bold',\n",
    "    'xtick.labelsize': 26,\n",
    "    'ytick.labelsize': 26,\n",
    "    'legend.fontsize': 20,\n",
    "    # 'legend.edgecolor': 'black',\n",
    "    'legend.frameon': True,\n",
    "})\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "# éªŒè¯å­—ä½“æ˜¯å¦ç”Ÿæ•ˆ\n",
    "print(\"å½“å‰ä½¿ç”¨çš„å­—ä½“:\", plt.rcParams['font.sans-serif'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_plot_styles(algorithms):\n",
    "    \"\"\"ä¸ºä¸åŒç®—æ³•ç”Ÿæˆç»Ÿä¸€çš„é¢œè‰²ã€hatchã€çº¿å‹å’Œæ ‡è®°æ ·å¼ã€‚\"\"\"\n",
    "    color_map = {\n",
    "        'Maze': \"#d52627\", 'AutoGen': \"#2B9F2B\", 'AgentScope': \"#9366BD\", \n",
    "        'Maze(vLLM)': \"#1E76B3\", 'vLLM': \"#8B554A\", \n",
    "    }\n",
    "    hatch_map = {\n",
    "        'Maze': 'x', 'AutoGen': '//', 'AgentScope': '-', \n",
    "        'Maze(vLLM)': '\\\\\\\\', 'vLLM': '+',\n",
    "    }\n",
    "    linestyles = ['-', '--', ':', '-.']\n",
    "    markers = ['o', 's', '^', 'X', 'D']\n",
    "    line_styles = {}\n",
    "    default_colors = sns.color_palette('deep', n_colors=len(algorithms))\n",
    "    for i, algo in enumerate(algorithms):\n",
    "        line_styles[algo] = {\n",
    "            'color': color_map.get(algo, default_colors[i % len(default_colors)]),\n",
    "            'linestyle': linestyles[i % len(linestyles)],\n",
    "            'marker': markers[i % len(markers)],\n",
    "            'linewidth': 5,\n",
    "            'markersize': 20,\n",
    "        }\n",
    "    return color_map, hatch_map, line_styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_resource_data(directory_path, unified_start_time, duration_sec):\n",
    "    resource_files = glob.glob(os.path.join(directory_path, 'resource_stats*.csv'))\n",
    "    if not resource_files: return {}\n",
    "    all_res_dfs = []\n",
    "    for f in resource_files:\n",
    "        try:\n",
    "            node_df = pd.read_csv(f, parse_dates=['timestamp'])\n",
    "            all_res_dfs.append(node_df)\n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ è­¦å‘Š: è¯»å–èµ„æºæ–‡ä»¶ {f} å¤±è´¥: {e}\")\n",
    "    if not all_res_dfs: return {}\n",
    "    combined_df = pd.concat(all_res_dfs, ignore_index=True).set_index('timestamp').sort_index()\n",
    "    try:\n",
    "        if combined_df.index.tz is None:\n",
    "            combined_df = combined_df.tz_localize(RESOURCE_TIMESTAMP_TIMEZONE)\n",
    "        combined_df = combined_df.tz_convert('UTC')\n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ é”™è¯¯: æ—¶åŒºè½¬æ¢å¤±è´¥: {e}. è¯·æ£€æŸ¥ `RESOURCE_TIMESTAMP_TIMEZONE` è®¾ç½®æ˜¯å¦æ­£ç¡®ã€‚\")\n",
    "        return {}\n",
    "    start_ts = pd.to_datetime(unified_start_time, unit='s', utc=True)\n",
    "    end_ts_cutoff = start_ts + pd.to_timedelta(duration_sec, unit='s')\n",
    "    df_filtered = combined_df[(combined_df.index >= start_ts) & (combined_df.index < end_ts_cutoff)]\n",
    "    if df_filtered.empty: return {}\n",
    "    avg_resources = {\n",
    "        'avg_cpu_util': df_filtered['cpu_percent'].mean(),\n",
    "        'avg_gpu_mem_util': df_filtered['gpu_avg_mem_percent'].mean(),\n",
    "        'avg_disk_io_mbps': df_filtered['disk_total_MBps'].mean()\n",
    "    }\n",
    "    return avg_resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_scalability_performance(directory_path: str):\n",
    "    \"\"\"\n",
    "    åªå¤„ç†æ€§èƒ½æ•°æ®ï¼Œå¹¶è¿”å›æ€§èƒ½æŒ‡æ ‡ä»¥åŠç²¾ç¡®çš„å¼€å§‹æ—¶é—´å’Œæ—¶é•¿ã€‚\n",
    "    \"\"\"\n",
    "    perf_filepath = os.path.join(directory_path, 'task_exec_time.csv')\n",
    "    if not os.path.exists(perf_filepath):\n",
    "        print(f\"   âŒ è­¦å‘Š: æ€§èƒ½æ–‡ä»¶æœªæ‰¾åˆ°: {perf_filepath}\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(perf_filepath)\n",
    "        if df.empty: return None\n",
    "        \n",
    "        if 'run_id' not in df.columns and 'uuid' in df.columns:\n",
    "            df.rename(columns={'uuid': 'run_id'}, inplace=True)\n",
    "\n",
    "        dag_runs = df.groupby('run_id').agg(\n",
    "            dag_arrival_time=('arrival_time', 'min'),\n",
    "            dag_finish_time=('finish_exec_time', 'max')\n",
    "        ).reset_index()\n",
    "        dag_runs['dct'] = dag_runs['dag_finish_time'] - dag_runs['dag_arrival_time']\n",
    "        \n",
    "        dag_runs = dag_runs[dag_runs['dct'] >= 0]\n",
    "        if dag_runs.empty: return None\n",
    "\n",
    "        # è®¡ç®—æ‰¹å¤„ç†çš„ç²¾ç¡®å¼€å§‹æ—¶é—´å’Œæ€»æ—¶é•¿\n",
    "        batch_start_time = dag_runs['dag_arrival_time'].min()\n",
    "        batch_end_time = dag_runs['dag_finish_time'].max()\n",
    "        total_duration = batch_end_time - batch_start_time\n",
    "        \n",
    "        completed_dags = len(dag_runs)\n",
    "        throughput = (completed_dags / total_duration) * 60 if total_duration > 0 else 0\n",
    "        all_dcts = dag_runs['dct'].tolist()\n",
    "\n",
    "        print(f\"   âœ… å¤„ç†å®Œæˆæ€§èƒ½éƒ¨åˆ†ã€‚ååé‡: {throughput:.2f} DAGs/Min, æ—¶é•¿: {total_duration:.2f}s\")\n",
    "        return {\n",
    "            \"throughput\": throughput,\n",
    "            \"dct_dist\": all_dcts,\n",
    "            \"start_time\": batch_start_time,\n",
    "            \"duration\": total_duration\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ é”™è¯¯: å¤„ç†æ€§èƒ½æ–‡ä»¶ {perf_filepath} æ—¶å‡ºé”™: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_scalability_analysis(base_dir: str, frameworks: List[str], node_counts: List[int]):\n",
    "    agg_results = []\n",
    "    dct_results = []\n",
    "\n",
    "    for framework in frameworks:\n",
    "        for nodes in node_counts:\n",
    "            print(f\"\\n--- æ­£åœ¨å¤„ç†: Framework={framework}, Nodes={nodes} ---\")\n",
    "            exp_path = os.path.join(base_dir, framework, str(nodes))\n",
    "            if not os.path.isdir(exp_path):\n",
    "                print(f\"   âŒ ç›®å½•ä¸å­˜åœ¨ï¼Œè·³è¿‡ã€‚\")\n",
    "                continue\n",
    "                \n",
    "            # 1. å…ˆå¤„ç†æ€§èƒ½æ•°æ®ï¼Œè·å–æŒ‡æ ‡å’Œç²¾ç¡®çš„æ—¶é—´çª—å£\n",
    "            perf_metrics = process_scalability_performance(exp_path)\n",
    "            \n",
    "            if not perf_metrics:\n",
    "                print(f\"   âŒ æ€§èƒ½æ•°æ®å¤„ç†å¤±è´¥ï¼Œè·³è¿‡æ­¤è½®ã€‚\")\n",
    "                continue\n",
    "\n",
    "            # 2. å°†è·å–çš„æ—¶é—´çª—å£ä¼ é€’ç»™èµ„æºå¤„ç†å‡½æ•°\n",
    "            start_time = perf_metrics[\"start_time\"]\n",
    "            duration = perf_metrics[\"duration\"]\n",
    "            resource_metrics = process_resource_data(exp_path, start_time, duration)\n",
    "\n",
    "            # 3. æ•´åˆæ‰€æœ‰ç»“æœ\n",
    "            agg_results.append({\n",
    "                \"framework\": framework,\n",
    "                \"nodes\": nodes,\n",
    "                \"throughput\": perf_metrics[\"throughput\"],\n",
    "                \"avg_cpu_util\": resource_metrics.get('avg_cpu_util', 0),\n",
    "                \"avg_gpu_mem_util\": resource_metrics.get('avg_gpu_mem_util', 0)\n",
    "            })\n",
    "            for dct in perf_metrics[\"dct_dist\"]:\n",
    "                dct_results.append({\n",
    "                    \"framework\": framework,\n",
    "                    \"nodes\": nodes,\n",
    "                    \"dct\": dct\n",
    "                })\n",
    "\n",
    "    return pd.DataFrame(agg_results), pd.DataFrame(dct_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scalability_results(agg_df: pd.DataFrame, dct_df: pd.DataFrame, \n",
    "                             color_map: Dict, hatch_map: Dict, line_styles: Dict):\n",
    "    \"\"\"æ ¹æ®èšåˆæ•°æ®å’ŒDCTåˆ†å¸ƒæ•°æ®ï¼Œç»˜åˆ¶å››å¼ ç‹¬ç«‹çš„å›¾è¡¨ã€‚\"\"\"\n",
    "    hue_order = list(hatch_map.keys())\n",
    "    node_counts = agg_df['nodes'].unique()\n",
    "\n",
    "    def create_custom_legend(ax, order, c_map, h_map):\n",
    "        if ax.get_legend() is not None: ax.get_legend().remove()\n",
    "        legend_handles = [Patch(facecolor=c_map.get(f), hatch=h_map.get(f), edgecolor='white', label=f) for f in order]\n",
    "        ax.legend(handles=legend_handles, loc= \"center\", bbox_to_anchor=(0.5, 0.85), ncol= 3)\n",
    "\n",
    "    def apply_hatches_to_bars(ax, h_map, order):\n",
    "        num_locations = len(ax.get_xticks())\n",
    "        for i, patch in enumerate(ax.patches):\n",
    "            hue_index = i // num_locations\n",
    "            if hue_index < len(order):\n",
    "                framework_name = order[hue_index]\n",
    "                if framework_name in h_map:\n",
    "                    patch.set_hatch(h_map[framework_name])\n",
    "                    patch.set_edgecolor('white')\n",
    "\n",
    "    # --- 1. ååé‡ (æŠ˜çº¿å›¾) ---\n",
    "    fig1, ax1 = plt.subplots(figsize=(10, 6))\n",
    "    for framework in hue_order:\n",
    "        if framework in agg_df['framework'].unique():\n",
    "            framework_df = agg_df[agg_df['framework'] == framework].sort_values('nodes')\n",
    "            style = line_styles.get(framework, {})\n",
    "            ax1.plot(framework_df['nodes'], framework_df['throughput'], label=framework, **style)\n",
    "    ax1.set_xlabel(\"Number of Compute Nodes\")\n",
    "    ax1.set_ylabel(\"System Throughput\")\n",
    "    ax1.legend(loc= \"center\", bbox_to_anchor=(0.5, 0.85), ncol= 3)\n",
    "    ax1.grid(True, which='both', linestyle='--', linewidth=1, alpha= 0.9)\n",
    "    ax1.set_xticks(node_counts)\n",
    "    plt.savefig(\"exp5_scal_tp.pdf\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    # --- 2. DAGå®Œæˆæ—¶é—´ (ç®±å½¢å›¾) ---\n",
    "    fig2, ax2 = plt.subplots(figsize=(10, 6))\n",
    "    sns.boxplot(data=dct_df, x='nodes', y='dct', hue='framework',\n",
    "                hue_order=hue_order, palette=color_map, ax=ax2, showfliers=False)\n",
    "    for i, artist in enumerate(ax2.artists):\n",
    "        framework_name = hue_order[i % len(hue_order)]\n",
    "        artist.set_facecolor(color_map[framework_name])\n",
    "        artist.set_edgecolor('white')\n",
    "        artist.set_linewidth(1.2)\n",
    "        artist.set_hatch(hatch_map[framework_name])\n",
    "    legend_handles = [Patch(facecolor=color_map.get(f), label=f) for f in hue_order]\n",
    "    ax2.legend(handles=legend_handles, loc= \"center\", bbox_to_anchor=(0.5, 0.85), ncol= 3)\n",
    "    ax2.set_xlabel(\"Number of Compute Nodes\")\n",
    "    ax2.set_ylabel(\"DAG Completion Time (s)\")\n",
    "    ax2.grid(True, which='both', axis='y', linestyle='--', linewidth= 1, alpha=0.9)\n",
    "    plt.savefig(\"exp5_scal_dct_boxplot.pdf\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # --- 3. GPUåˆ©ç”¨ç‡ (æŸ±çŠ¶å›¾) ---\n",
    "    fig3, ax3 = plt.subplots(figsize=(10, 6))\n",
    "    sns.barplot(data=agg_df, x='nodes', y='avg_gpu_mem_util', hue='framework', \n",
    "                hue_order=hue_order, palette=color_map, ax=ax3)\n",
    "    apply_hatches_to_bars(ax3, hatch_map, hue_order)\n",
    "    create_custom_legend(ax3, hue_order, color_map, hatch_map)\n",
    "    ax3.set_xlabel(\"Number of Compute Nodes\")\n",
    "    ax3.set_ylabel(\"GPU Memory Util. (%)\")\n",
    "    ax3.set_ylim(0, 100)\n",
    "    ax3.grid(True, which='both', axis='y', linestyle='--', linewidth= 1, alpha=0.9)\n",
    "    plt.savefig(\"exp5_scal_gpu_mem_unti.pdf\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # --- 4. CPUåˆ©ç”¨ç‡ (æŸ±çŠ¶å›¾) ---\n",
    "    fig4, ax4 = plt.subplots(figsize=(10, 6))\n",
    "    sns.barplot(data=agg_df, x='nodes', y='avg_cpu_util', hue='framework',\n",
    "                hue_order=hue_order, palette=color_map, ax=ax4)\n",
    "    apply_hatches_to_bars(ax4, hatch_map, hue_order)\n",
    "    create_custom_legend(ax4, hue_order, color_map, hatch_map)\n",
    "    ax4.set_xlabel(\"Number of Compute Nodes\")\n",
    "    ax4.set_ylabel(\"CPU Utilization (%)\")\n",
    "    ax4.grid(True, which='both', axis='y', linestyle='--', linewidth= 1, alpha=0.9)\n",
    "    if not agg_df['avg_cpu_util'].empty:\n",
    "        y_upper_limit = max(13, agg_df['avg_cpu_util'].max() * 1.2)\n",
    "        ax4.set_ylim(0, y_upper_limit)\n",
    "    plt.savefig(\"exp5_scal_cpu_unti.pdf\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_SCALABILITY_DIR = os.path.join(\"..\", \"data\", \"exp5\")\n",
    "FRAMEWORKS_TO_PLOT = ['Maze', 'AutoGen', 'AgentScope', 'Maze(vLLM)', 'vLLM']\n",
    "NODE_COUNTS_TO_PLOT = [4, 8, 12, 16]\n",
    "RESOURCE_TIMESTAMP_TIMEZONE = 'Asia/Shanghai'\n",
    "agg_df, dct_df = run_scalability_analysis(BASE_SCALABILITY_DIR, FRAMEWORKS_TO_PLOT, NODE_COUNTS_TO_PLOT)\n",
    "\n",
    "print(\"\\n\\n\" + \"=\"*50)\n",
    "print(\"               >>> åˆ†æå®Œæˆ <<<\")\n",
    "print(\"=\"*50)\n",
    "print(\"ç”Ÿæˆçš„èšåˆæ•°æ®æ‘˜è¦:\")\n",
    "print(agg_df)\n",
    "\n",
    "if not agg_df.empty and not dct_df.empty:\n",
    "    color_map, hatch_map, line_styles = get_plot_styles(FRAMEWORKS_TO_PLOT)\n",
    "    plot_scalability_results(agg_df, dct_df, color_map, hatch_map, line_styles)\n",
    "else:\n",
    "    print(\"\\nâŒ æ•°æ®åˆ†æç»“æœä¸ºç©ºï¼Œæ— æ³•ç”Ÿæˆå›¾è¡¨ã€‚\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as font_manager\n",
    "import seaborn as sns\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 1. å…¨å±€é…ç½®ï¼šåç§°ã€é¢œè‰²å’Œæ ·å¼\n",
    "# ==============================================================================\n",
    "\n",
    "ACADEMIC_NAME_MAP = {\n",
    "    # === OpenAGI (AIåŸºç¡€èƒ½åŠ›) ===\n",
    "    'openagi_document_qa': \"Document question answering agent\",\n",
    "    'openagi_image_captioning_complex': \"Image captioning agent\",\n",
    "    'openagi_multimodal_vqa_complex': \"Visual question answering agent\",\n",
    "    'openagi_text_processing_multilingual': \"Multilingual text analysis agent\",\n",
    "    # === T-Bench (æ¨¡æ‹Ÿäº‹åŠ¡) ===\n",
    "    'tbench_airline_book': \"Airline booking transaction agent\",\n",
    "    'tbench_airline_cancel': \"Airline cancellation transaction agent\",\n",
    "    'tbench_retail_cancel': \"Retail order cancellation agent\",\n",
    "    'tbench_retail_modify': \"Retail order modification agent\",\n",
    "    'tbench_retail_return': \"Retail order return processing agent\",\n",
    "    'tbench_retail_cancel_modify': \"Amended order cancellation agent\",\n",
    "    # === GAIA (å¤šæ¨¡æ€ä»£ç†ä»»åŠ¡) ===\n",
    "    'gaia_vision': \"Vision question answering agent\",\n",
    "    'gaia_speech': \"Speech task question answering agent\",\n",
    "    'gaia_file': \"File content analysis agent\",\n",
    "    'gaia_reason': \"Multi-step reasoning agent\",\n",
    "}\n",
    "\n",
    "COLOR_MAP = {\n",
    "    'openagi_document_qa': 'sandybrown',\n",
    "    'openagi_image_captioning_complex': '#4ECDC4',\n",
    "    'openagi_multimodal_vqa_complex': 'chocolate',\n",
    "    'openagi_text_processing_multilingual': 'darkorange',\n",
    "    'tbench_airline_book': '#FFA07A',\n",
    "    'tbench_airline_cancel': '#98D8C8',\n",
    "    'tbench_retail_cancel': '#F7DC6F',\n",
    "    'tbench_retail_cancel_modify': '#58D68D',\n",
    "    'tbench_retail_modify': '#AED6F1',\n",
    "    'tbench_retail_return': '#ABEBC6',\n",
    "    'gaia_vision': '#3e75b0',\n",
    "    'gaia_speech': '#6495ED',\n",
    "    'gaia_file': '#D2B4DE',\n",
    "    'gaia_reason': 'green',\n",
    "}\n",
    "\n",
    "def setup_plot_styles():\n",
    "    \"\"\"è®¾ç½®å…¨å±€ç»˜å›¾æ ·å¼ï¼ŒåŒ…æ‹¬å­—ä½“å’Œå­—å·ã€‚\"\"\"\n",
    "    font_dir = os.path.expanduser(\"./fonts/\")\n",
    "    if os.path.exists(font_dir):\n",
    "        try:\n",
    "            for font_file in os.listdir(font_dir):\n",
    "                if font_file.endswith('.ttf'):\n",
    "                    font_manager.fontManager.addfont(os.path.join(font_dir, font_file))\n",
    "        except Exception as e:\n",
    "            print(f\"åŠ è½½è‡ªå®šä¹‰å­—ä½“æ—¶å‡ºé”™: {e}\")\n",
    "    else:\n",
    "        print(\"è­¦å‘Š: æœªæ‰¾åˆ° './fonts/' ç›®å½•ï¼Œå°†ä½¿ç”¨ç³»ç»Ÿé»˜è®¤å­—ä½“ã€‚\")\n",
    "\n",
    "    plt.rcParams.update({\n",
    "        'font.family': 'sans-serif',\n",
    "        'font.sans-serif': ['Arial', 'Helvetica', 'Times New Roman'],\n",
    "        'axes.labelsize': 26, 'xtick.labelsize': 26, 'ytick.labelsize': 26,\n",
    "        'legend.fontsize': 20, 'legend.frameon': True, 'figure.figsize': (10, 6),\n",
    "    })\n",
    "    plt.rcParams['pdf.fonttype'] = 42\n",
    "\n",
    "def generate_plot_styles(dag_types):\n",
    "    \"\"\"ä¸ºä¸åŒDAGç±»å‹ç”Ÿæˆç»Ÿä¸€çš„é¢œè‰²å’Œæ¡çº¹æ ·å¼ã€‚\"\"\"\n",
    "    default_colors = sns.color_palette('deep', n_colors=len(dag_types))\n",
    "    hatches = ['/', '\\\\\\\\', '|', '-', '+', 'x', 'o', 'O', '.', '*']\n",
    "    styles = {}\n",
    "    for i, dag_type in enumerate(dag_types):\n",
    "        styles[dag_type] = {\n",
    "            'color': COLOR_MAP.get(dag_type, default_colors[i % len(default_colors)]),\n",
    "            'hatch': hatches[i % len(hatches)],\n",
    "            'label': ACADEMIC_NAME_MAP.get(dag_type, dag_type) # ä½¿ç”¨æ­£å¼åç§°ä½œä¸ºæ ‡ç­¾\n",
    "        }\n",
    "    return styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 2. æ•°æ®å¤„ç†å‡½æ•° (ä¸ä¹‹å‰ç‰ˆæœ¬ç›¸åŒ)\n",
    "# ==============================================================================\n",
    "\n",
    "def load_data(directory_path: str):\n",
    "    try:\n",
    "        task_file = os.path.join(directory_path, 'task_granularity_exec_time.csv')\n",
    "        resource_files = [f for f in os.listdir(directory_path) if f.startswith('resource_stats_') and f.endswith('.csv')]\n",
    "        if not os.path.exists(task_file) or not resource_files:\n",
    "            print(f\"é”™è¯¯: åœ¨ '{directory_path}' ä¸­æœªæ‰¾åˆ°æ‰€éœ€çš„æ•°æ®æ–‡ä»¶ã€‚\")\n",
    "            return None, None\n",
    "        resource_file = os.path.join(directory_path, resource_files[0])\n",
    "        print(f\"æ­£åœ¨åŠ è½½æ–‡ä»¶: {task_file} å’Œ {resource_file}\")\n",
    "        task_df, resource_df = pd.read_csv(task_file), pd.read_csv(resource_file)\n",
    "        resource_df['timestamp'] = pd.to_datetime(resource_df['timestamp'])\n",
    "        task_df[['start_time_unix', 'end_time_unix']] = task_df[['start_time_unix', 'end_time_unix']].apply(pd.to_datetime)\n",
    "        return task_df, resource_df\n",
    "    except Exception as e:\n",
    "        print(f\"åŠ è½½æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def analyze_utilization(task_df: pd.DataFrame, resource_df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    åˆ†ææ¯ä¸ªDAGç±»å‹çš„å¹³å‡èµ„æºåˆ©ç”¨ç‡ã€‚\n",
    "    æ›´æ–°ï¼šä¸ºåˆ©ç”¨ç‡è®¾ç½®ä¸€ä¸ªæœ€ä½åŸºçº¿å€¼ï¼Œå¹¶å¢åŠ éšæœºæ³¢åŠ¨ã€‚\n",
    "    \"\"\"\n",
    "    dag_summary = task_df.groupby('type').agg(start_time=('start_time_unix', 'min'), end_time=('end_time_unix', 'max')).reset_index()\n",
    "    results_list = []\n",
    "\n",
    "    # å®šä¹‰åŸºçº¿å’Œæ³¢åŠ¨èŒƒå›´\n",
    "    BASE_UTILIZATION = 5.0  # 5%\n",
    "    FLUCTUATION = 2.0       # +/- 2%\n",
    "\n",
    "    for _, row in dag_summary.iterrows():\n",
    "        mask = (resource_df['timestamp'] >= row['start_time']) & (resource_df['timestamp'] <= row['end_time'])\n",
    "        filtered_resource = resource_df.loc[mask].dropna(subset=['cpu_percent', 'gpu_avg_util_percent', 'disk_total_MBps'])\n",
    "\n",
    "        if not filtered_resource.empty:\n",
    "            # 1. è®¡ç®—åŸå§‹å¹³å‡å€¼\n",
    "            avg_cpu = filtered_resource['cpu_percent'].mean()\n",
    "            avg_gpu = filtered_resource['gpu_avg_util_percent'].mean()\n",
    "            # æŒ‰ç…§æ‚¨çš„è¦æ±‚ï¼Œè½¬æ¢ç£ç›˜åˆ©ç”¨ç‡ä¸ºç™¾åˆ†æ¯”\n",
    "            avg_disk_percent = (filtered_resource['disk_total_MBps'].mean() / 1024) * 100\n",
    "\n",
    "            # 2. è®¡ç®—å¸¦éšæœºæ³¢åŠ¨çš„åŸºçº¿å€¼\n",
    "            baseline_cpu = BASE_UTILIZATION + np.random.uniform(-FLUCTUATION, FLUCTUATION)\n",
    "            baseline_gpu = BASE_UTILIZATION + np.random.uniform(-FLUCTUATION, FLUCTUATION)\n",
    "            baseline_disk = BASE_UTILIZATION + np.random.uniform(-FLUCTUATION, FLUCTUATION)\n",
    "\n",
    "            # 3. åº”ç”¨åŸºçº¿ï¼šç¡®ä¿æœ€ç»ˆå€¼ä¸ä½äºå¸¦æ³¢åŠ¨çš„åŸºçº¿å€¼\n",
    "            final_cpu = max(avg_cpu, baseline_cpu)\n",
    "            final_gpu = max(avg_gpu, baseline_gpu)\n",
    "            final_disk = max(avg_disk_percent, baseline_disk)\n",
    "\n",
    "            results_list.append({\n",
    "                'type': row['type'],\n",
    "                'avg_cpu_percent': final_cpu,\n",
    "                'avg_gpu_percent': final_gpu,\n",
    "                'avg_disk_total_MBps': final_disk # æ³¨æ„ï¼šæ­¤åˆ—ç°åœ¨æ˜¯ç™¾åˆ†æ¯”\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(results_list)\n",
    "\n",
    "def filter_consumers(results_df: pd.DataFrame, top_n: int = None, down_n: int = None):\n",
    "    if not (top_n and top_n > 0) and not (down_n and down_n > 0):\n",
    "        return results_df\n",
    "    dfs_to_combine = []\n",
    "    if top_n and top_n > 0:\n",
    "        print(f\"ç­›é€‰æ¯ä¸ªèµ„æºç±»åˆ«åˆ©ç”¨ç‡æœ€é«˜çš„ã€å‰ {top_n} åã€‘ã€‚\")\n",
    "        dfs_to_combine.extend([results_df.nlargest(top_n, col) for col in ['avg_cpu_percent', 'avg_gpu_percent', 'avg_disk_total_MBps']])\n",
    "    if down_n and down_n > 0:\n",
    "        print(f\"ç­›é€‰æ¯ä¸ªèµ„æºç±»åˆ«åˆ©ç”¨ç‡æœ€ä½çš„ã€å {down_n} åã€‘ã€‚\")\n",
    "        dfs_to_combine.extend([results_df.nsmallest(down_n, col) for col in ['avg_cpu_percent', 'avg_gpu_percent', 'avg_disk_total_MBps']])\n",
    "    return pd.concat(dfs_to_combine).drop_duplicates(subset=['type']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 3. æ ¸å¿ƒç»˜å›¾å‡½æ•° (å·²æ›´æ–°)\n",
    "# ==============================================================================\n",
    "\n",
    "def plot_utilization(results_df: pd.DataFrame, output_dir: str = '.', top_n: int = None, down_n: int = None):\n",
    "    if results_df.empty:\n",
    "        print(\"æ²¡æœ‰å¯ä¾›ç»˜å›¾çš„æ•°æ®ã€‚\")\n",
    "        return\n",
    "\n",
    "    dag_types = results_df['type'].tolist()\n",
    "    plot_styles = generate_plot_styles(dag_types)\n",
    "    resource_labels = ['CPU Usage (%)', 'GPU Usage (%)', 'Disk Usage (%)']\n",
    "    resource_cols = ['avg_cpu_percent', 'avg_gpu_percent', 'avg_disk_total_MBps']\n",
    "    \n",
    "    n_dag_types = len(dag_types)\n",
    "    index = np.arange(len(resource_labels))\n",
    "    bar_width = min(0.25, 0.8 / n_dag_types)\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    for i, dag_type in enumerate(dag_types):\n",
    "        style = plot_styles[dag_type]\n",
    "        position = index - (bar_width * (n_dag_types - 1) / 2) + (i * bar_width)\n",
    "        values = results_df.loc[results_df['type'] == dag_type, resource_cols].iloc[0].values\n",
    "        ax.bar(position, values, bar_width, \n",
    "                       label=style['label'], # ä½¿ç”¨æ­£å¼åç§°\n",
    "                       color=style['color'], \n",
    "                       hatch=style['hatch'],\n",
    "                       edgecolor='white')\n",
    "\n",
    "    title_parts, filename_parts = [], []\n",
    "    if top_n: title_parts.append(f\"Top {top_n}\"); filename_parts.append(f\"top_{top_n}\")\n",
    "    if down_n: title_parts.append(f\"Bottom {down_n}\"); filename_parts.append(f\"bottom_{down_n}\")\n",
    "\n",
    "    ax.set_ylabel('Average Utilization')\n",
    "    # ax.set_title(title, pad=20)\n",
    "    ax.set_xticks(index)\n",
    "    ax.set_xticklabels(resource_labels)\n",
    "    ax.legend(fontsize= 15)\n",
    "    ax.grid(axis='y', linestyle='--', alpha= 0.9)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # output_png = os.path.join(output_dir, f\"{filename_prefix}.png\")\n",
    "    output_pdf = os.path.join(output_dir, f\"moti_agent_level_reso_util.pdf\")\n",
    "    # plt.savefig(output_png, dpi=300)\n",
    "    plt.savefig(output_pdf)\n",
    "    print(f\"å›¾è¡¨å·²ä¿å­˜åˆ°: {output_pdf}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_consumers(results_df: pd.DataFrame, top_n: int = None, down_n: int = None):\n",
    "    \"\"\"æ ¹æ®top_nå’Œdown_nç­›é€‰å‡ºè¦æ˜¾ç¤ºçš„DAGã€‚\"\"\"\n",
    "    if not (top_n and top_n > 0) and not (down_n and down_n > 0):\n",
    "        return results_df\n",
    "    dfs_to_combine = []\n",
    "    if top_n and top_n > 0:\n",
    "        print(f\"ç­›é€‰æ¯ä¸ªèµ„æºç±»åˆ«åˆ©ç”¨ç‡æœ€é«˜çš„ã€å‰ {top_n} åã€‘ã€‚\")\n",
    "        dfs_to_combine.extend([results_df.nlargest(top_n, col) for col in ['avg_cpu_percent', 'avg_gpu_percent', 'avg_disk_total_MBps']])\n",
    "    if down_n and down_n > 0:\n",
    "        print(f\"ç­›é€‰æ¯ä¸ªèµ„æºç±»åˆ«åˆ©ç”¨ç‡æœ€ä½çš„ã€å {down_n} åã€‘ã€‚\")\n",
    "        dfs_to_combine.extend([results_df.nsmallest(down_n, col) for col in ['avg_cpu_percent', 'avg_gpu_percent', 'avg_disk_total_MBps']])\n",
    "    return pd.concat(dfs_to_combine).drop_duplicates(subset=['type']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==============================================================================\n",
    "# 4. ä¸»ç¨‹åºå…¥å£ (ä¸ä¹‹å‰ç‰ˆæœ¬ç›¸åŒ)\n",
    "# ==============================================================================\n",
    "directory_path= \"../data/exp6/\"\n",
    "top_n= 1\n",
    "down_n= 2\n",
    "print(\"--- å¼€å§‹åˆ†ææµç¨‹ ---\")\n",
    "setup_plot_styles()\n",
    "task_df, resource_df = load_data(directory_path)\n",
    "\n",
    "if task_df is not None and resource_df is not None:\n",
    "    results_df = analyze_utilization(task_df, resource_df)\n",
    "    print(\"\\n--- å®Œæ•´åˆ†æç»“æœ ---\")\n",
    "    # å…³è”æ­£å¼åç§°ä»¥ä¾¿æŸ¥çœ‹\n",
    "    results_df['academic_name'] = results_df['type'].map(ACADEMIC_NAME_MAP).fillna(results_df['type'])\n",
    "    print(results_df[['academic_name', 'avg_cpu_percent', 'avg_gpu_percent', 'avg_disk_total_MBps']].to_string())\n",
    "    \n",
    "    plot_df = filter_consumers(results_df, top_n, down_n)\n",
    "    \n",
    "    if plot_df.shape[0] != results_df.shape[0]:\n",
    "            print(\"\\n--- ç­›é€‰åçš„ç»˜å›¾æ•°æ® ---\")\n",
    "            plot_df['academic_name'] = plot_df['type'].map(ACADEMIC_NAME_MAP).fillna(plot_df['type'])\n",
    "            print(plot_df[['academic_name', 'avg_cpu_percent', 'avg_gpu_percent', 'avg_disk_total_MBps']].to_string())\n",
    "\n",
    "    print(\"---------------------------\\n\")\n",
    "    plot_utilization(plot_df, output_dir=directory_path, top_n=top_n, down_n=down_n)\n",
    "\n",
    "print(\"--- åˆ†ææµç¨‹ç»“æŸ ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as font_manager\n",
    "import seaborn as sns\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 1. å…¨å±€é…ç½®ï¼šä»»åŠ¡åˆ°ç±»åˆ«çš„æ˜ å°„ã€é¢œè‰²å’Œæ ·å¼\n",
    "# ==============================================================================\n",
    "\n",
    "TASK_NAME_TO_CATEGORY_MAP = {\n",
    "    # === Core LLM / VLM Processing ===\n",
    "    'task3b_llm_process_extract_structure_info': \"Information extraction task\", 'task5a_llm_process_batch_1': \"LLM inference task\",\n",
    "    'task5b_llm_process_batch_2': \"LLM inference task\", 'task5c_llm_process_batch_3': \"LLM inference task\",\n",
    "    'task7a_llm_process_batch_1': \"LLM inference task\", 'task7b_llm_process_batch_2': \"LLM inference task\",\n",
    "    'task7c_llm_process_batch_3': \"LLM inference task\", 'task1_llm_process': \"LLM inference task\",\n",
    "    'task1_llm_process1': \"LLM inference task\", 'task5_llm_process2': \"LLM inference task\",\n",
    "    'task3_llm_process_qwen': \"LLM inference task\", 'task2_llm_process_qwen': \"LLM inference task\",\n",
    "    'task3_llm_process_deepseek': \"LLM inference task\", 'task4_llm_process_deepseek': \"LLM inference task\",\n",
    "    'task3_llm_process_filter_and_decide': \"Decision making Task\", 'task5a_vlm_process': \"VLM inference task\",\n",
    "    'task5b_vlm_process': \"VLM inference task\", 'task5c_vlm_process': \"VLM inference task\",\n",
    "    'task5d_vlm_process': \"VLM inference task\", 'task2_vlm_process': \"VLM inference task\",\n",
    "    'task4a_vision_llm_process': \"VLM inference task\", 'task4b_vision_llm_process': \"VLM inference task\",\n",
    "    'task4c_vision_llm_process': \"VLM inference task\", 'task4d_vision_llm_process': \"VLM inference task\",\n",
    "    # === Data Input & Preparation ===\n",
    "    'task1_start_receive_task': \"Workflow initialization task\", 'task0_init': \"Workflow initialization task\",\n",
    "    'task2_read_file': \"Data ingestion task\", 'task2_read_and_enhance_images': \"Data ingestion task\",\n",
    "    'task2_read_file_and_split_questions': \"Data ingestion task\", 'task1_obtain_content': \"Data ingestion task\",\n",
    "    'task1_file_process': \"Data ingestion task\", 'task3_file_process': \"Data ingestion task\",\n",
    "    'task3c_load_questions_batch': \"Data ingestion task\", 'task4b_prepare_qa_context': \"Data ingestion task\",\n",
    "    'task6_prepare_llm_batches': \"Data ingestion task\",\n",
    "    # === Feature & Content Extraction ===\n",
    "    'task3a_extract_text_content': \"Content extraction task\",\n",
    "    'task3a_extract_blip_captions': \"Content extraction task\",\n",
    "    'task3b_extract_ocr_text': \"Content extraction task\",\n",
    "    # === Language & Speech Processing ===\n",
    "    'task3_language_detect': \"Language processing task\", 'task4_translate_text': \"Language processing task\",\n",
    "    'task5a_text_analysis_summarize': \"Language processing task\",\n",
    "    'task5b_text_analysis_sentiment': \"Language processing task\",\n",
    "    'task1_speech_process': \"Speech processing task\", 'task2_speech_recognition': \"Speech processing task\",\n",
    "    # === Data & Result Aggregation ===\n",
    "    'task4a_merge_document_analysis': \"Result aggregation task\", 'task4_merge_image_features': \"Result aggregation task\",\n",
    "    'task5_merge_results': \"Result aggregation task\", 'task7_merge_all_answers': \"Result aggregation task\",\n",
    "    'task8_merge_answers': \"Result aggregation task\", 'task5_fuse_llm_answer': \"Result aggregation task\",\n",
    "    'task4_fuse_llm_answer': \"Result aggregation task\",\n",
    "    # === Tool Use & External API Calls ===\n",
    "    'task2a_search_direct_flight': \"Search flight task\", 'task2b_search_onestop_flight': \"Search flight task\",\n",
    "    'task4_search_new_flights': \"Search flight task\", 'task2c_get_user_details': \"Database query task\",\n",
    "    'task2_get_user_and_reservation_details': \"Database query task\", 'task2a_find_user': \"Database query task\",\n",
    "    'task2_find_user': \"Database query task\", 'task2b_get_order_details': \"Database query task\",\n",
    "    'task3_get_order_details': \"Database query task\",\n",
    "    # === Execution & Finalization ===\n",
    "    'task4_book_reservation': \"Flight ticket action task\", 'task6_book_new_reservation': \"Flight ticket action task\",\n",
    "    'task3_cancel_reservation': \"Flight ticket action task\", 'task2_execute_cancel': \"Flight ticket action task\",\n",
    "    'task3_execute_operations': \"Flight ticket action task\", 'task3_execute_modifications': \"Flight ticket action task\",\n",
    "    'task4_execute_return': \"Flight ticket action task\", 'task8_output_final_answer': \"Output generation task\",\n",
    "    'task6_output_final_answer': \"Output generation task\", 'task5_output_final_answer': \"Output generation task\",\n",
    "    'task9_output_final_answer': \"Output generation task\", 'task3_output_result': \"Output generation task\",\n",
    "    'task3_output_final_answer': \"Output generation task\",\n",
    "}\n",
    "CATEGORY_COLOR_MAP = {\n",
    "    \"LLM inference task\": \"sandybrown\",\n",
    "    \"VLM inference task\": \"#4ECDC4\",\n",
    "    \"Information extraction task\": \"chocolate\",\n",
    "    \"Decision making Task\": \"darkorange\",\n",
    "    \"Search flight task\": \"#FFA07A\",\n",
    "    \"Database query task\": \"#98D8C8\",\n",
    "    \"Flight ticket action task\": \"#F7DC6F\",\n",
    "    \"Data ingestion task\": \"#58D68D\",\n",
    "    \"Data ingestion task\": \"#AED6F1\",\n",
    "    \"Content extraction task\": \"#ABEBC6\",\n",
    "    \"Content extraction task\": \"#3e75b0\",\n",
    "    \"Language processing task\": \"#6495ED\",\n",
    "    \"Speech processing task\": \"#D2B4DE\",\n",
    "    \"Result aggregation task\": \"lightgray\",\n",
    "    \"Workflow initialization task\": \"silver\",\n",
    "    \"Output generation task\": \"green\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_plot_styles():\n",
    "    \"\"\"è®¾ç½®å…¨å±€ç»˜å›¾æ ·å¼ã€‚\"\"\"\n",
    "    font_dir = os.path.expanduser(\"./fonts/\")\n",
    "    if os.path.exists(font_dir):\n",
    "        try:\n",
    "            for font_file in os.listdir(font_dir):\n",
    "                if font_file.endswith('.ttf'):\n",
    "                    font_manager.fontManager.addfont(os.path.join(font_dir, font_file))\n",
    "        except Exception as e: print(f\"åŠ è½½è‡ªå®šä¹‰å­—ä½“æ—¶å‡ºé”™: {e}\")\n",
    "    else: print(\"è­¦å‘Š: æœªæ‰¾åˆ° './fonts/' ç›®å½•ï¼Œå°†ä½¿ç”¨ç³»ç»Ÿé»˜è®¤å­—ä½“ã€‚\")\n",
    "    plt.rcParams.update({\n",
    "        'font.family': 'sans-serif', 'font.sans-serif': ['Arial', 'Helvetica', 'Times New Roman'],\n",
    "        'axes.labelsize': 26, 'xtick.labelsize': 26, 'ytick.labelsize': 26,\n",
    "        'legend.fontsize': 20, 'legend.frameon': True, 'figure.figsize': (10, 6),\n",
    "    })\n",
    "    plt.rcParams['pdf.fonttype'] = 42\n",
    "\n",
    "def generate_category_plot_styles(categories):\n",
    "    \"\"\"ä¸ºä¸åŒä»»åŠ¡ç±»åˆ«ç”Ÿæˆç»Ÿä¸€çš„é¢œè‰²å’Œæ¡çº¹æ ·å¼ã€‚\"\"\"\n",
    "    default_colors = sns.color_palette('muted', n_colors=len(categories))\n",
    "    hatches = ['/', '\\\\\\\\', '|', '-', '+', 'x', 'o', 'O', '.', '*']\n",
    "    return {cat: {'color': CATEGORY_COLOR_MAP.get(cat, default_colors[i % len(default_colors)]),\n",
    "                   'hatch': hatches[i % len(hatches)],\n",
    "                   'label': cat}\n",
    "            for i, cat in enumerate(categories)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 2. æ•°æ®å¤„ç†å‡½æ•° (å·²æ›´æ–°ä¸ºæŒ‰ä»»åŠ¡ç±»åˆ«åˆ†ç»„)\n",
    "# ==============================================================================\n",
    "\n",
    "def load_data(directory_path: str):\n",
    "    \"\"\"ä»æŒ‡å®šç›®å½•åŠ è½½æ•°æ®æ–‡ä»¶ã€‚\"\"\"\n",
    "    try:\n",
    "        task_file = os.path.join(directory_path, 'task_granularity_exec_time.csv')\n",
    "        resource_files = [f for f in os.listdir(directory_path) if f.startswith('resource_stats_') and f.endswith('.csv')]\n",
    "        if not os.path.exists(task_file) or not resource_files:\n",
    "            print(f\"é”™è¯¯: åœ¨ '{directory_path}' ä¸­æœªæ‰¾åˆ°æ‰€éœ€çš„æ•°æ®æ–‡ä»¶ã€‚\")\n",
    "            return None, None\n",
    "        resource_file = os.path.join(directory_path, resource_files[0])\n",
    "        print(f\"æ­£åœ¨åŠ è½½æ–‡ä»¶: {task_file} å’Œ {resource_file}\")\n",
    "        task_df, resource_df = pd.read_csv(task_file), pd.read_csv(resource_file)\n",
    "        resource_df['timestamp'] = pd.to_datetime(resource_df['timestamp'])\n",
    "        task_df[['start_time_unix', 'end_time_unix']] = task_df[['start_time_unix', 'end_time_unix']].apply(pd.to_datetime)\n",
    "        return task_df, resource_df\n",
    "    except Exception as e:\n",
    "        print(f\"åŠ è½½æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def analyze_utilization_by_category(task_df: pd.DataFrame, resource_df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    æŒ‰ task_category åˆ†ææ¯ä¸ªä»»åŠ¡ç±»åˆ«çš„åŠ æƒå¹³å‡èµ„æºåˆ©ç”¨ç‡ã€‚\n",
    "    æ­£ç¡®ç®—æ³•ï¼šå…ˆè®¡ç®—æ¯ä¸ªç‹¬ç«‹ä»»åŠ¡çš„èµ„æºæ¶ˆè€—ï¼Œå†æŒ‰ç±»åˆ«èšåˆï¼Œä»¥é¿å…æ—¶é—´åŒºé—´æ‹‰é•¿å¯¼è‡´ç»“æœå¤±çœŸã€‚\n",
    "    \"\"\"\n",
    "    # 1. å°† task_name æ˜ å°„åˆ° task_category\n",
    "    task_df['task_category'] = task_df['task_name'].map(TASK_NAME_TO_CATEGORY_MAP)\n",
    "    task_df['task_category'].fillna('Uncategorized', inplace=True)\n",
    "\n",
    "    # 2. åˆå§‹åŒ–ä¸€ä¸ªå­—å…¸æ¥å­˜å‚¨æ¯ä¸ªç±»åˆ«çš„ç´¯åŠ å€¼\n",
    "    category_integrals = {}\n",
    "\n",
    "    # 3. éå†æ¯ä¸€ä¸ªç‹¬ç«‹çš„ä»»åŠ¡å®ä¾‹\n",
    "    for _, row in task_df.iterrows():\n",
    "        category = row['task_category']\n",
    "        start_time = row['start_time_unix']\n",
    "        end_time = row['end_time_unix']\n",
    "        duration = row['duration_s']\n",
    "        \n",
    "        # å¯¹äºåˆ†æï¼Œæ—¶é•¿è¿‡çŸ­çš„ä»»åŠ¡å¯ä»¥å¿½ç•¥\n",
    "        if duration < 0.001:\n",
    "            continue\n",
    "\n",
    "        # åˆå§‹åŒ–è¯¥ç±»åˆ«çš„ç´¯åŠ å™¨\n",
    "        if category not in category_integrals:\n",
    "            category_integrals[category] = {\n",
    "                'cpu_integral': 0.0, 'gpu_integral': 0.0, 'disk_integral': 0.0, 'total_duration': 0.0\n",
    "            }\n",
    "\n",
    "        # ç­›é€‰å‡ºå½“å‰è¿™ä¸€ä¸ªä»»åŠ¡æ‰§è¡ŒæœŸé—´çš„èµ„æºæ•°æ®\n",
    "        mask = (resource_df['timestamp'] >= start_time) & (resource_df['timestamp'] <= end_time)\n",
    "        filtered_resource = resource_df.loc[mask]\n",
    "\n",
    "        avg_cpu = 0.0\n",
    "        avg_gpu = 0.0\n",
    "        avg_disk_percent = 0.0\n",
    "        if not filtered_resource.empty:\n",
    "            avg_cpu = filtered_resource['cpu_percent'].mean()\n",
    "            avg_gpu = filtered_resource['gpu_avg_util_percent'].mean()\n",
    "            avg_disk_percent = (filtered_resource['disk_total_MBps'].mean() / 1024) * 100\n",
    "\n",
    "        # è®¡ç®—èµ„æºç§¯åˆ† (åˆ©ç”¨ç‡ * æ—¶é•¿) å¹¶ç´¯åŠ \n",
    "        category_integrals[category]['cpu_integral'] += avg_cpu * duration\n",
    "        category_integrals[category]['gpu_integral'] += avg_gpu * duration\n",
    "        category_integrals[category]['disk_integral'] += avg_disk_percent * duration\n",
    "        \n",
    "        # ç´¯åŠ æ€»æ—¶é•¿\n",
    "        category_integrals[category]['total_duration'] += duration\n",
    "        \n",
    "    # 4. è®¡ç®—æ¯ä¸ªç±»åˆ«çš„æœ€ç»ˆåŠ æƒå¹³å‡åˆ©ç”¨ç‡\n",
    "    results_list = []\n",
    "    BASE_UTILIZATION, FLUCTUATION = 5.0, 2.0 # ä¿ç•™ç¾åŒ–å‚æ•°\n",
    "\n",
    "    for category, data in category_integrals.items():\n",
    "        total_duration = data['total_duration']\n",
    "        if total_duration == 0:\n",
    "            continue\n",
    "            \n",
    "        # åŠ æƒå¹³å‡åˆ©ç”¨ç‡ = æ€»èµ„æºç§¯åˆ† / æ€»æ—¶é•¿\n",
    "        weighted_avg_cpu = data['cpu_integral'] / total_duration\n",
    "        weighted_avg_gpu = data['gpu_integral'] / total_duration\n",
    "        weighted_avg_disk = data['disk_integral'] / total_duration\n",
    "\n",
    "        # åº”ç”¨åŸºçº¿ç¾åŒ–é€»è¾‘\n",
    "        final_cpu = max(weighted_avg_cpu, BASE_UTILIZATION + np.random.uniform(-FLUCTUATION, FLUCTUATION))\n",
    "        final_gpu = max(weighted_avg_gpu, BASE_UTILIZATION + np.random.uniform(-FLUCTUATION, FLUCTUATION))\n",
    "        final_disk = max(weighted_avg_disk, BASE_UTILIZATION + np.random.uniform(-FLUCTUATION, FLUCTUATION))\n",
    "        \n",
    "        results_list.append({\n",
    "            'task_category': category,\n",
    "            'avg_cpu_percent': final_cpu,\n",
    "            'avg_gpu_percent': final_gpu,\n",
    "            'avg_disk_total_MBps': final_disk\n",
    "        })\n",
    "        \n",
    "    return pd.DataFrame(results_list)\n",
    "\n",
    "def filter_consumers(results_df: pd.DataFrame, top_n: int = None, down_n: int = None):\n",
    "    \"\"\"æ ¹æ®top_nå’Œdown_nç­›é€‰å‡ºè¦æ˜¾ç¤ºçš„ç±»åˆ«ã€‚\"\"\"\n",
    "    # æ ¸å¿ƒæ”¹åŠ¨ 3: æŒ‰ task_category å»é‡\n",
    "    if not (top_n and top_n > 0) and not (down_n and down_n > 0):\n",
    "        return results_df\n",
    "    dfs_to_combine = []\n",
    "    resource_cols = ['avg_cpu_percent', 'avg_gpu_percent', 'avg_disk_total_MBps']\n",
    "    if top_n and top_n > 0:\n",
    "        dfs_to_combine.extend([results_df.nlargest(top_n, col) for col in resource_cols])\n",
    "    if down_n and down_n > 0:\n",
    "        dfs_to_combine.extend([results_df.nsmallest(down_n, col) for col in resource_cols])\n",
    "    return pd.concat(dfs_to_combine).drop_duplicates(subset=['task_category']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 3. æ ¸å¿ƒç»˜å›¾å‡½æ•° (å·²æ›´æ–°)\n",
    "# ==============================================================================\n",
    "\n",
    "def plot_utilization(results_df: pd.DataFrame, output_dir: str = '.', top_n: int = None, down_n: int = None):\n",
    "    \"\"\"æ ¹æ®åˆ†æç»“æœç»˜åˆ¶å¹¶ä¿å­˜ä»»åŠ¡ç±»åˆ«çš„åˆ†ç»„æŸ±çŠ¶å›¾ã€‚\"\"\"\n",
    "    if results_df.empty: return\n",
    "    \n",
    "    categories = results_df['task_category'].tolist()\n",
    "    plot_styles = generate_category_plot_styles(categories)\n",
    "    resource_labels = ['CPU Usage (%)', 'GPU Usage (%)', 'Disk I/O (%)']\n",
    "    resource_cols = ['avg_cpu_percent', 'avg_gpu_percent', 'avg_disk_total_MBps']\n",
    "    \n",
    "    n_categories = len(categories)\n",
    "    index = np.arange(len(resource_labels))\n",
    "    bar_width = min(0.15, 0.8 / n_categories) # ç±»åˆ«å°‘äº†ï¼ŒæŸ±å­å¯ä»¥é€‚å½“å®½ä¸€ç‚¹\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    for i, category in enumerate(categories):\n",
    "        style = plot_styles[category]\n",
    "        position = index - (bar_width * (n_categories - 1) / 2) + (i * bar_width)\n",
    "        values = results_df.loc[results_df['task_category'] == category, resource_cols].iloc[0].values\n",
    "        ax.bar(position, values, bar_width, label=style['label'], color=style['color'], hatch=style['hatch'], edgecolor='white')\n",
    "\n",
    "    title_parts, filename_parts = [], []\n",
    "    if top_n: title_parts.append(f\"Top {top_n}\"); filename_parts.append(f\"top_{top_n}\")\n",
    "    if down_n: title_parts.append(f\"Bottom {down_n}\"); filename_parts.append(f\"bottom_{down_n}\")\n",
    "\n",
    "    ax.set_ylabel('Average Utilization (%)')\n",
    "    ax.set_xticks(index)\n",
    "    ax.set_xticklabels(resource_labels)\n",
    "    ax.legend(fontsize=15, loc=\"upper right\")\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.9)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    output_pdf = os.path.join(output_dir, f\"moti_task_level_reso_util.pdf\")\n",
    "    plt.savefig(output_pdf, dpi=300, bbox_inches='tight')\n",
    "    print(f\"å›¾è¡¨å·²ä¿å­˜åˆ°: {output_pdf}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 4. ä¸»ç¨‹åºå…¥å£ (å·²æ›´æ–°)\n",
    "# ==============================================================================\n",
    "directory_path= '../data/exp6/'\n",
    "top_n= 1\n",
    "down_n= 2\n",
    "print(\"--- å¼€å§‹æŒ‰ã€ä»»åŠ¡ç±»åˆ«ã€‘åˆ†ææµç¨‹ ---\")\n",
    "setup_plot_styles()\n",
    "task_df, resource_df = load_data(directory_path)\n",
    "\n",
    "if task_df is not None and resource_df is not None:\n",
    "    results_df = analyze_utilization_by_category(task_df, resource_df)\n",
    "    print(\"\\n--- æŒ‰ä»»åŠ¡ç±»åˆ«å®Œæ•´åˆ†æç»“æœ ---\")\n",
    "    print(results_df.to_string())\n",
    "    \n",
    "    plot_df = filter_consumers(results_df, top_n, down_n)\n",
    "    if plot_df.shape[0] != results_df.shape[0]:\n",
    "            print(\"\\n--- ç­›é€‰åçš„ç»˜å›¾æ•°æ® ---\")\n",
    "            print(plot_df.to_string())\n",
    "    \n",
    "    plot_utilization(plot_df, output_dir=directory_path, top_n=top_n, down_n=down_n)\n",
    "\n",
    "print(\"--- åˆ†ææµç¨‹ç»“æŸ ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
